2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:20,320:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'S'')
  warnings.warn(

2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:18,247:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'S'')
  warnings.warn(

2024-05-28 14:20:53,618:INFO:PyCaret ClassificationExperiment
2024-05-28 14:20:53,618:INFO:Logging name: clf-default-name
2024-05-28 14:20:53,618:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:20:53,618:INFO:version 3.3.1
2024-05-28 14:20:53,618:INFO:Initializing setup()
2024-05-28 14:20:53,619:INFO:self.USI: 12d8
2024-05-28 14:20:53,619:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:20:53,619:INFO:Checking environment
2024-05-28 14:20:53,619:INFO:python_version: 3.11.9
2024-05-28 14:20:53,619:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:20:53,620:INFO:machine: AMD64
2024-05-28 14:20:53,632:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:20:53,651:INFO:Memory: svmem(total=8469606400, available=1824501760, percent=78.5, used=6645104640, free=1824501760)
2024-05-28 14:20:53,651:INFO:Physical Core: 2
2024-05-28 14:20:53,651:INFO:Logical Core: 4
2024-05-28 14:20:53,651:INFO:Checking libraries
2024-05-28 14:20:53,651:INFO:System:
2024-05-28 14:20:53,651:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:20:53,652:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:20:53,652:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:20:53,652:INFO:PyCaret required dependencies:
2024-05-28 14:20:53,881:INFO:                 pip: 24.0
2024-05-28 14:20:53,881:INFO:          setuptools: 70.0.0
2024-05-28 14:20:53,881:INFO:             pycaret: 3.3.1
2024-05-28 14:20:53,881:INFO:             IPython: 8.24.0
2024-05-28 14:20:53,881:INFO:          ipywidgets: 8.1.2
2024-05-28 14:20:53,881:INFO:                tqdm: 4.66.4
2024-05-28 14:20:53,881:INFO:               numpy: 1.26.4
2024-05-28 14:20:53,881:INFO:              pandas: 2.1.4
2024-05-28 14:20:53,881:INFO:              jinja2: 3.1.4
2024-05-28 14:20:53,881:INFO:               scipy: 1.11.4
2024-05-28 14:20:53,881:INFO:              joblib: 1.3.2
2024-05-28 14:20:53,881:INFO:             sklearn: 1.4.2
2024-05-28 14:20:53,881:INFO:                pyod: 1.1.3
2024-05-28 14:20:53,881:INFO:            imblearn: 0.12.2
2024-05-28 14:20:53,881:INFO:   category_encoders: 2.6.3
2024-05-28 14:20:53,881:INFO:            lightgbm: 4.3.0
2024-05-28 14:20:53,881:INFO:               numba: 0.58.1
2024-05-28 14:20:53,881:INFO:            requests: 2.32.2
2024-05-28 14:20:53,881:INFO:          matplotlib: 3.7.5
2024-05-28 14:20:53,881:INFO:          scikitplot: 0.3.7
2024-05-28 14:20:53,881:INFO:         yellowbrick: 1.5
2024-05-28 14:20:53,881:INFO:              plotly: 5.22.0
2024-05-28 14:20:53,881:INFO:    plotly-resampler: Not installed
2024-05-28 14:20:53,881:INFO:             kaleido: 0.2.1
2024-05-28 14:20:53,897:INFO:           schemdraw: 0.15
2024-05-28 14:20:53,897:INFO:         statsmodels: 0.14.2
2024-05-28 14:20:53,897:INFO:              sktime: 0.26.0
2024-05-28 14:20:53,897:INFO:               tbats: 1.1.3
2024-05-28 14:20:53,898:INFO:            pmdarima: 2.0.4
2024-05-28 14:20:53,898:INFO:              psutil: 5.9.8
2024-05-28 14:20:53,898:INFO:          markupsafe: 2.1.5
2024-05-28 14:20:53,898:INFO:             pickle5: Not installed
2024-05-28 14:20:53,898:INFO:         cloudpickle: 3.0.0
2024-05-28 14:20:53,898:INFO:         deprecation: 2.1.0
2024-05-28 14:20:53,898:INFO:              xxhash: 3.4.1
2024-05-28 14:20:53,898:INFO:           wurlitzer: 3.1.0
2024-05-28 14:20:53,898:INFO:PyCaret optional dependencies:
2024-05-28 14:20:53,998:INFO:                shap: Not installed
2024-05-28 14:20:53,998:INFO:           interpret: Not installed
2024-05-28 14:20:53,998:INFO:                umap: 0.5.5
2024-05-28 14:20:53,998:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:20:53,998:INFO:  explainerdashboard: Not installed
2024-05-28 14:20:53,998:INFO:             autoviz: Not installed
2024-05-28 14:20:53,998:INFO:           fairlearn: Not installed
2024-05-28 14:20:53,998:INFO:          deepchecks: Not installed
2024-05-28 14:20:53,998:INFO:             xgboost: 2.0.3
2024-05-28 14:20:53,998:INFO:            catboost: 1.2.5
2024-05-28 14:20:53,998:INFO:              kmodes: 0.12.2
2024-05-28 14:20:53,998:INFO:             mlxtend: 0.23.1
2024-05-28 14:20:53,998:INFO:       statsforecast: Not installed
2024-05-28 14:20:53,998:INFO:        tune_sklearn: Not installed
2024-05-28 14:20:53,998:INFO:                 ray: Not installed
2024-05-28 14:20:53,998:INFO:            hyperopt: Not installed
2024-05-28 14:20:53,998:INFO:              optuna: Not installed
2024-05-28 14:20:53,998:INFO:               skopt: Not installed
2024-05-28 14:20:53,998:INFO:              mlflow: 2.13.0
2024-05-28 14:20:53,998:INFO:              gradio: Not installed
2024-05-28 14:20:53,998:INFO:             fastapi: Not installed
2024-05-28 14:20:53,998:INFO:             uvicorn: Not installed
2024-05-28 14:20:53,998:INFO:              m2cgen: Not installed
2024-05-28 14:20:53,998:INFO:           evidently: Not installed
2024-05-28 14:20:53,998:INFO:               fugue: Not installed
2024-05-28 14:20:53,998:INFO:           streamlit: 1.35.0
2024-05-28 14:20:53,998:INFO:             prophet: Not installed
2024-05-28 14:20:53,998:INFO:None
2024-05-28 14:20:53,998:INFO:Set up data.
2024-05-28 14:20:54,021:INFO:Set up folding strategy.
2024-05-28 14:20:54,021:INFO:Set up train/test split.
2024-05-28 14:20:54,032:INFO:Set up index.
2024-05-28 14:20:54,032:INFO:Assigning column types.
2024-05-28 14:20:54,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:20:54,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,165:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,165:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,431:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,448:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:20:54,498:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,532:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,532:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,581:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,614:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,631:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,631:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:20:54,714:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,714:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,814:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,814:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,814:INFO:Preparing preprocessing pipeline...
2024-05-28 14:20:54,830:INFO:Set up simple imputation.
2024-05-28 14:20:54,830:INFO:Set up encoding of ordinal features.
2024-05-28 14:20:54,830:INFO:Set up encoding of categorical features.
2024-05-28 14:20:54,830:INFO:Set up imbalanced handling.
2024-05-28 14:20:55,030:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:20:55,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:20:55,064:INFO:Creating final display dataframe.
2024-05-28 14:20:55,914:INFO:Setup _display_container:                     Description             Value
0                    Session id              7313
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              12d8
2024-05-28 14:20:56,043:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:56,046:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:56,173:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:56,176:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:56,179:INFO:setup() successfully completed in 2.58s...............
2024-05-28 14:20:56,187:INFO:Initializing compare_models()
2024-05-28 14:20:56,187:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:20:56,187:INFO:Checking exceptions
2024-05-28 14:20:56,197:INFO:Preparing display monitor
2024-05-28 14:20:56,197:INFO:Initializing Logistic Regression
2024-05-28 14:20:56,197:INFO:Total runtime is 0.0 minutes
2024-05-28 14:20:56,197:INFO:SubProcess create_model() called ==================================
2024-05-28 14:20:56,197:INFO:Initializing create_model()
2024-05-28 14:20:56,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:20:56,206:INFO:Checking exceptions
2024-05-28 14:20:56,207:INFO:Importing libraries
2024-05-28 14:20:56,207:INFO:Copying training dataset
2024-05-28 14:20:56,219:INFO:Defining folds
2024-05-28 14:20:56,219:INFO:Declaring metric variables
2024-05-28 14:20:56,220:INFO:Importing untrained model
2024-05-28 14:20:56,221:INFO:Logistic Regression Imported successfully
2024-05-28 14:20:56,222:INFO:Starting cross validation
2024-05-28 14:20:56,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:08,331:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,351:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,536:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,903:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,059:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,269:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,588:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,636:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,652:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,752:INFO:Calculating mean and std
2024-05-28 14:21:09,752:INFO:Creating metrics dataframe
2024-05-28 14:21:09,752:INFO:Uploading results into container
2024-05-28 14:21:09,752:INFO:Uploading model into container now
2024-05-28 14:21:09,752:INFO:_master_model_container: 1
2024-05-28 14:21:09,752:INFO:_display_container: 2
2024-05-28 14:21:09,752:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:21:09,752:INFO:create_model() successfully completed......................................
2024-05-28 14:21:10,008:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:10,008:INFO:Creating metrics dataframe
2024-05-28 14:21:10,013:INFO:Initializing K Neighbors Classifier
2024-05-28 14:21:10,013:INFO:Total runtime is 0.23027323484420775 minutes
2024-05-28 14:21:10,014:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:10,014:INFO:Initializing create_model()
2024-05-28 14:21:10,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:10,015:INFO:Checking exceptions
2024-05-28 14:21:10,015:INFO:Importing libraries
2024-05-28 14:21:10,015:INFO:Copying training dataset
2024-05-28 14:21:10,025:INFO:Defining folds
2024-05-28 14:21:10,025:INFO:Declaring metric variables
2024-05-28 14:21:10,026:INFO:Importing untrained model
2024-05-28 14:21:10,027:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:21:10,027:INFO:Starting cross validation
2024-05-28 14:21:10,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:10,501:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,509:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,586:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,940:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,943:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,946:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,954:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,248:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,257:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,288:INFO:Calculating mean and std
2024-05-28 14:21:11,290:INFO:Creating metrics dataframe
2024-05-28 14:21:11,293:INFO:Uploading results into container
2024-05-28 14:21:11,294:INFO:Uploading model into container now
2024-05-28 14:21:11,295:INFO:_master_model_container: 2
2024-05-28 14:21:11,295:INFO:_display_container: 2
2024-05-28 14:21:11,296:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:21:11,296:INFO:create_model() successfully completed......................................
2024-05-28 14:21:11,500:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:11,500:INFO:Creating metrics dataframe
2024-05-28 14:21:11,517:INFO:Initializing Naive Bayes
2024-05-28 14:21:11,517:INFO:Total runtime is 0.2553425033887227 minutes
2024-05-28 14:21:11,517:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:11,517:INFO:Initializing create_model()
2024-05-28 14:21:11,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:11,517:INFO:Checking exceptions
2024-05-28 14:21:11,517:INFO:Importing libraries
2024-05-28 14:21:11,517:INFO:Copying training dataset
2024-05-28 14:21:11,517:INFO:Defining folds
2024-05-28 14:21:11,517:INFO:Declaring metric variables
2024-05-28 14:21:11,517:INFO:Importing untrained model
2024-05-28 14:21:11,517:INFO:Naive Bayes Imported successfully
2024-05-28 14:21:11,517:INFO:Starting cross validation
2024-05-28 14:21:11,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:11,853:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,864:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,899:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,943:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,186:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,192:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,227:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,305:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,531:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,562:INFO:Calculating mean and std
2024-05-28 14:21:12,562:INFO:Creating metrics dataframe
2024-05-28 14:21:12,567:INFO:Uploading results into container
2024-05-28 14:21:12,567:INFO:Uploading model into container now
2024-05-28 14:21:12,567:INFO:_master_model_container: 3
2024-05-28 14:21:12,567:INFO:_display_container: 2
2024-05-28 14:21:12,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:21:12,567:INFO:create_model() successfully completed......................................
2024-05-28 14:21:12,815:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:12,816:INFO:Creating metrics dataframe
2024-05-28 14:21:12,819:INFO:Initializing Decision Tree Classifier
2024-05-28 14:21:12,819:INFO:Total runtime is 0.2770451704661051 minutes
2024-05-28 14:21:12,819:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:12,820:INFO:Initializing create_model()
2024-05-28 14:21:12,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:12,820:INFO:Checking exceptions
2024-05-28 14:21:12,820:INFO:Importing libraries
2024-05-28 14:21:12,820:INFO:Copying training dataset
2024-05-28 14:21:12,826:INFO:Defining folds
2024-05-28 14:21:12,826:INFO:Declaring metric variables
2024-05-28 14:21:12,827:INFO:Importing untrained model
2024-05-28 14:21:12,827:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:21:12,828:INFO:Starting cross validation
2024-05-28 14:21:12,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:13,155:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,172:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,182:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,193:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,200:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,207:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,207:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,537:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,537:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,819:INFO:Calculating mean and std
2024-05-28 14:21:13,820:INFO:Creating metrics dataframe
2024-05-28 14:21:13,822:INFO:Uploading results into container
2024-05-28 14:21:13,823:INFO:Uploading model into container now
2024-05-28 14:21:13,823:INFO:_master_model_container: 4
2024-05-28 14:21:13,823:INFO:_display_container: 2
2024-05-28 14:21:13,824:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7313, splitter='best')
2024-05-28 14:21:13,824:INFO:create_model() successfully completed......................................
2024-05-28 14:21:13,995:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:13,995:INFO:Creating metrics dataframe
2024-05-28 14:21:14,001:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:21:14,001:INFO:Total runtime is 0.2967338760693868 minutes
2024-05-28 14:21:14,001:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:14,001:INFO:Initializing create_model()
2024-05-28 14:21:14,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:14,002:INFO:Checking exceptions
2024-05-28 14:21:14,002:INFO:Importing libraries
2024-05-28 14:21:14,002:INFO:Copying training dataset
2024-05-28 14:21:14,008:INFO:Defining folds
2024-05-28 14:21:14,008:INFO:Declaring metric variables
2024-05-28 14:21:14,008:INFO:Importing untrained model
2024-05-28 14:21:14,009:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:21:14,009:INFO:Starting cross validation
2024-05-28 14:21:14,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:14,764:INFO:Calculating mean and std
2024-05-28 14:21:14,765:INFO:Creating metrics dataframe
2024-05-28 14:21:14,768:INFO:Uploading results into container
2024-05-28 14:21:14,769:INFO:Uploading model into container now
2024-05-28 14:21:14,769:INFO:_master_model_container: 5
2024-05-28 14:21:14,769:INFO:_display_container: 2
2024-05-28 14:21:14,770:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:21:14,770:INFO:create_model() successfully completed......................................
2024-05-28 14:21:14,954:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:14,955:INFO:Creating metrics dataframe
2024-05-28 14:21:14,960:INFO:Initializing Ridge Classifier
2024-05-28 14:21:14,960:INFO:Total runtime is 0.31272000074386597 minutes
2024-05-28 14:21:14,960:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:14,961:INFO:Initializing create_model()
2024-05-28 14:21:14,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:14,961:INFO:Checking exceptions
2024-05-28 14:21:14,961:INFO:Importing libraries
2024-05-28 14:21:14,961:INFO:Copying training dataset
2024-05-28 14:21:14,971:INFO:Defining folds
2024-05-28 14:21:14,971:INFO:Declaring metric variables
2024-05-28 14:21:14,971:INFO:Importing untrained model
2024-05-28 14:21:14,972:INFO:Ridge Classifier Imported successfully
2024-05-28 14:21:14,972:INFO:Starting cross validation
2024-05-28 14:21:14,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:15,859:INFO:Calculating mean and std
2024-05-28 14:21:15,859:INFO:Creating metrics dataframe
2024-05-28 14:21:15,865:INFO:Uploading results into container
2024-05-28 14:21:15,866:INFO:Uploading model into container now
2024-05-28 14:21:15,867:INFO:_master_model_container: 6
2024-05-28 14:21:15,867:INFO:_display_container: 2
2024-05-28 14:21:15,868:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7313, solver='auto',
                tol=0.0001)
2024-05-28 14:21:15,868:INFO:create_model() successfully completed......................................
2024-05-28 14:21:16,070:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:16,070:INFO:Creating metrics dataframe
2024-05-28 14:21:16,073:INFO:Initializing Random Forest Classifier
2024-05-28 14:21:16,074:INFO:Total runtime is 0.33129642804463705 minutes
2024-05-28 14:21:16,074:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:16,074:INFO:Initializing create_model()
2024-05-28 14:21:16,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:16,075:INFO:Checking exceptions
2024-05-28 14:21:16,075:INFO:Importing libraries
2024-05-28 14:21:16,075:INFO:Copying training dataset
2024-05-28 14:21:16,080:INFO:Defining folds
2024-05-28 14:21:16,080:INFO:Declaring metric variables
2024-05-28 14:21:16,081:INFO:Importing untrained model
2024-05-28 14:21:16,082:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:21:16,082:INFO:Starting cross validation
2024-05-28 14:21:16,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:16,741:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:16,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,767:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:16,769:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,824:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,834:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,532:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,545:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,570:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,729:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,733:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,763:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,363:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:18,376:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,403:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:18,415:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,433:INFO:Calculating mean and std
2024-05-28 14:21:18,435:INFO:Creating metrics dataframe
2024-05-28 14:21:18,437:INFO:Uploading results into container
2024-05-28 14:21:18,438:INFO:Uploading model into container now
2024-05-28 14:21:18,439:INFO:_master_model_container: 7
2024-05-28 14:21:18,439:INFO:_display_container: 2
2024-05-28 14:21:18,439:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7313, verbose=0,
                       warm_start=False)
2024-05-28 14:21:18,440:INFO:create_model() successfully completed......................................
2024-05-28 14:21:18,728:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:18,728:INFO:Creating metrics dataframe
2024-05-28 14:21:18,728:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:21:18,728:INFO:Total runtime is 0.375517737865448 minutes
2024-05-28 14:21:18,728:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:18,743:INFO:Initializing create_model()
2024-05-28 14:21:18,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:18,745:INFO:Checking exceptions
2024-05-28 14:21:18,745:INFO:Importing libraries
2024-05-28 14:21:18,745:INFO:Copying training dataset
2024-05-28 14:21:18,745:INFO:Defining folds
2024-05-28 14:21:18,745:INFO:Declaring metric variables
2024-05-28 14:21:18,761:INFO:Importing untrained model
2024-05-28 14:21:18,762:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:21:18,763:INFO:Starting cross validation
2024-05-28 14:21:18,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:19,028:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,068:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,120:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,134:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,194:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,371:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,411:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,467:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,477:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,486:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,670:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,671:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,747:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,768:INFO:Calculating mean and std
2024-05-28 14:21:19,770:INFO:Creating metrics dataframe
2024-05-28 14:21:19,773:INFO:Uploading results into container
2024-05-28 14:21:19,774:INFO:Uploading model into container now
2024-05-28 14:21:19,774:INFO:_master_model_container: 8
2024-05-28 14:21:19,774:INFO:_display_container: 2
2024-05-28 14:21:19,775:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:21:19,775:INFO:create_model() successfully completed......................................
2024-05-28 14:21:19,971:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:19,972:INFO:Creating metrics dataframe
2024-05-28 14:21:19,975:INFO:Initializing Ada Boost Classifier
2024-05-28 14:21:19,975:INFO:Total runtime is 0.39630001386006675 minutes
2024-05-28 14:21:19,975:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:19,975:INFO:Initializing create_model()
2024-05-28 14:21:19,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:19,976:INFO:Checking exceptions
2024-05-28 14:21:19,976:INFO:Importing libraries
2024-05-28 14:21:19,976:INFO:Copying training dataset
2024-05-28 14:21:19,981:INFO:Defining folds
2024-05-28 14:21:19,982:INFO:Declaring metric variables
2024-05-28 14:21:19,982:INFO:Importing untrained model
2024-05-28 14:21:19,982:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:21:19,982:INFO:Starting cross validation
2024-05-28 14:21:19,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:20,174:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,177:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,196:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,256:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,259:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,284:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,431:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,431:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,445:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,473:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,546:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,579:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,711:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,793:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,797:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,818:INFO:Calculating mean and std
2024-05-28 14:21:20,819:INFO:Creating metrics dataframe
2024-05-28 14:21:20,821:INFO:Uploading results into container
2024-05-28 14:21:20,822:INFO:Uploading model into container now
2024-05-28 14:21:20,822:INFO:_master_model_container: 9
2024-05-28 14:21:20,823:INFO:_display_container: 2
2024-05-28 14:21:20,823:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7313)
2024-05-28 14:21:20,823:INFO:create_model() successfully completed......................................
2024-05-28 14:21:20,999:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:20,999:INFO:Creating metrics dataframe
2024-05-28 14:21:21,004:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:21:21,005:INFO:Total runtime is 0.41347586313883467 minutes
2024-05-28 14:21:21,005:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:21,006:INFO:Initializing create_model()
2024-05-28 14:21:21,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:21,006:INFO:Checking exceptions
2024-05-28 14:21:21,006:INFO:Importing libraries
2024-05-28 14:21:21,006:INFO:Copying training dataset
2024-05-28 14:21:21,014:INFO:Defining folds
2024-05-28 14:21:21,014:INFO:Declaring metric variables
2024-05-28 14:21:21,014:INFO:Importing untrained model
2024-05-28 14:21:21,015:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:21:21,016:INFO:Starting cross validation
2024-05-28 14:21:21,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:21,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,574:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,577:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,597:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,023:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,030:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,358:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,358:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,367:INFO:Calculating mean and std
2024-05-28 14:21:22,367:INFO:Creating metrics dataframe
2024-05-28 14:21:22,367:INFO:Uploading results into container
2024-05-28 14:21:22,367:INFO:Uploading model into container now
2024-05-28 14:21:22,367:INFO:_master_model_container: 10
2024-05-28 14:21:22,367:INFO:_display_container: 2
2024-05-28 14:21:22,367:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:21:22,367:INFO:create_model() successfully completed......................................
2024-05-28 14:21:22,541:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:22,541:INFO:Creating metrics dataframe
2024-05-28 14:21:22,544:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:21:22,544:INFO:Total runtime is 0.43912605047225955 minutes
2024-05-28 14:21:22,545:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:22,545:INFO:Initializing create_model()
2024-05-28 14:21:22,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:22,545:INFO:Checking exceptions
2024-05-28 14:21:22,545:INFO:Importing libraries
2024-05-28 14:21:22,545:INFO:Copying training dataset
2024-05-28 14:21:22,551:INFO:Defining folds
2024-05-28 14:21:22,551:INFO:Declaring metric variables
2024-05-28 14:21:22,551:INFO:Importing untrained model
2024-05-28 14:21:22,551:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:21:22,552:INFO:Starting cross validation
2024-05-28 14:21:22,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:22,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,831:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,865:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,162:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,174:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,181:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,541:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,581:INFO:Calculating mean and std
2024-05-28 14:21:23,581:INFO:Creating metrics dataframe
2024-05-28 14:21:23,581:INFO:Uploading results into container
2024-05-28 14:21:23,581:INFO:Uploading model into container now
2024-05-28 14:21:23,581:INFO:_master_model_container: 11
2024-05-28 14:21:23,581:INFO:_display_container: 2
2024-05-28 14:21:23,581:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:21:23,581:INFO:create_model() successfully completed......................................
2024-05-28 14:21:23,771:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:23,771:INFO:Creating metrics dataframe
2024-05-28 14:21:23,775:INFO:Initializing Extra Trees Classifier
2024-05-28 14:21:23,775:INFO:Total runtime is 0.45964737733205163 minutes
2024-05-28 14:21:23,775:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:23,775:INFO:Initializing create_model()
2024-05-28 14:21:23,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:23,775:INFO:Checking exceptions
2024-05-28 14:21:23,775:INFO:Importing libraries
2024-05-28 14:21:23,775:INFO:Copying training dataset
2024-05-28 14:21:23,781:INFO:Defining folds
2024-05-28 14:21:23,781:INFO:Declaring metric variables
2024-05-28 14:21:23,781:INFO:Importing untrained model
2024-05-28 14:21:23,782:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:21:23,782:INFO:Starting cross validation
2024-05-28 14:21:23,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:24,400:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,404:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,554:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,197:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,214:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,417:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,442:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,792:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,840:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,861:INFO:Calculating mean and std
2024-05-28 14:21:25,862:INFO:Creating metrics dataframe
2024-05-28 14:21:25,864:INFO:Uploading results into container
2024-05-28 14:21:25,865:INFO:Uploading model into container now
2024-05-28 14:21:25,865:INFO:_master_model_container: 12
2024-05-28 14:21:25,865:INFO:_display_container: 2
2024-05-28 14:21:25,866:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7313, verbose=0,
                     warm_start=False)
2024-05-28 14:21:25,866:INFO:create_model() successfully completed......................................
2024-05-28 14:21:26,037:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:26,037:INFO:Creating metrics dataframe
2024-05-28 14:21:26,042:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:21:26,042:INFO:Total runtime is 0.49743057092030846 minutes
2024-05-28 14:21:26,042:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:26,042:INFO:Initializing create_model()
2024-05-28 14:21:26,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:26,042:INFO:Checking exceptions
2024-05-28 14:21:26,042:INFO:Importing libraries
2024-05-28 14:21:26,043:INFO:Copying training dataset
2024-05-28 14:21:26,049:INFO:Defining folds
2024-05-28 14:21:26,049:INFO:Declaring metric variables
2024-05-28 14:21:26,049:INFO:Importing untrained model
2024-05-28 14:21:26,050:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:21:26,051:INFO:Starting cross validation
2024-05-28 14:21:26,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:26,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,522:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,884:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,905:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,915:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,915:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,925:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,948:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,957:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,146:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:27,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:27,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,198:INFO:Calculating mean and std
2024-05-28 14:21:27,198:INFO:Creating metrics dataframe
2024-05-28 14:21:27,198:INFO:Uploading results into container
2024-05-28 14:21:27,198:INFO:Uploading model into container now
2024-05-28 14:21:27,198:INFO:_master_model_container: 13
2024-05-28 14:21:27,198:INFO:_display_container: 2
2024-05-28 14:21:27,205:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:21:27,206:INFO:create_model() successfully completed......................................
2024-05-28 14:21:27,389:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:27,389:INFO:Creating metrics dataframe
2024-05-28 14:21:27,394:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:21:27,394:INFO:Total runtime is 0.5199484070142111 minutes
2024-05-28 14:21:27,395:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:27,395:INFO:Initializing create_model()
2024-05-28 14:21:27,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:27,396:INFO:Checking exceptions
2024-05-28 14:21:27,396:INFO:Importing libraries
2024-05-28 14:21:27,396:INFO:Copying training dataset
2024-05-28 14:21:27,403:INFO:Defining folds
2024-05-28 14:21:27,403:INFO:Declaring metric variables
2024-05-28 14:21:27,403:INFO:Importing untrained model
2024-05-28 14:21:27,404:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:21:27,405:INFO:Starting cross validation
2024-05-28 14:21:27,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:28,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,017:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,017:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,312:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,322:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,534:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,541:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,550:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,563:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,829:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,847:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,015:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:29,021:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:29,025:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,050:INFO:Calculating mean and std
2024-05-28 14:21:29,052:INFO:Creating metrics dataframe
2024-05-28 14:21:29,056:INFO:Uploading results into container
2024-05-28 14:21:29,056:INFO:Uploading model into container now
2024-05-28 14:21:29,057:INFO:_master_model_container: 14
2024-05-28 14:21:29,057:INFO:_display_container: 2
2024-05-28 14:21:29,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:21:29,058:INFO:create_model() successfully completed......................................
2024-05-28 14:21:29,285:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:29,285:INFO:Creating metrics dataframe
2024-05-28 14:21:29,285:INFO:Initializing CatBoost Classifier
2024-05-28 14:21:29,285:INFO:Total runtime is 0.5514812151590983 minutes
2024-05-28 14:21:29,285:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:29,285:INFO:Initializing create_model()
2024-05-28 14:21:29,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:29,285:INFO:Checking exceptions
2024-05-28 14:21:29,285:INFO:Importing libraries
2024-05-28 14:21:29,285:INFO:Copying training dataset
2024-05-28 14:21:29,302:INFO:Defining folds
2024-05-28 14:21:29,303:INFO:Declaring metric variables
2024-05-28 14:21:29,303:INFO:Importing untrained model
2024-05-28 14:21:29,303:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:21:29,303:INFO:Starting cross validation
2024-05-28 14:21:29,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:38,394:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,395:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:38,601:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,612:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:38,696:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:04,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:04,679:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:04,895:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:04,908:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:05,390:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:05,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:05,631:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:05,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:11,435:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:11,442:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:11,464:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 5220, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 2400, in _fit
    self._train(
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 1780, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4833, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4882, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-28 14:22:11,464:INFO:Calculating mean and std
2024-05-28 14:22:11,468:INFO:Creating metrics dataframe
2024-05-28 14:22:11,468:INFO:Uploading results into container
2024-05-28 14:22:11,468:INFO:Uploading model into container now
2024-05-28 14:22:11,468:INFO:_master_model_container: 15
2024-05-28 14:22:11,468:INFO:_display_container: 2
2024-05-28 14:22:11,468:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BC3ECE550>
2024-05-28 14:22:11,468:INFO:create_model() successfully completed......................................
2024-05-28 14:22:11,718:INFO:SubProcess create_model() end ==================================
2024-05-28 14:22:11,718:INFO:Creating metrics dataframe
2024-05-28 14:22:11,718:INFO:Initializing Dummy Classifier
2024-05-28 14:22:11,718:INFO:Total runtime is 1.2586904684702556 minutes
2024-05-28 14:22:11,718:INFO:SubProcess create_model() called ==================================
2024-05-28 14:22:11,718:INFO:Initializing create_model()
2024-05-28 14:22:11,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:22:11,718:INFO:Checking exceptions
2024-05-28 14:22:11,718:INFO:Importing libraries
2024-05-28 14:22:11,718:INFO:Copying training dataset
2024-05-28 14:22:11,748:INFO:Defining folds
2024-05-28 14:22:11,748:INFO:Declaring metric variables
2024-05-28 14:22:11,749:INFO:Importing untrained model
2024-05-28 14:22:11,751:INFO:Dummy Classifier Imported successfully
2024-05-28 14:22:11,752:INFO:Starting cross validation
2024-05-28 14:22:11,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:22:12,112:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,116:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,118:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,133:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,145:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,161:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,528:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,551:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,559:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,568:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,573:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,951:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,958:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,970:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,976:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:13,000:INFO:Calculating mean and std
2024-05-28 14:22:13,000:INFO:Creating metrics dataframe
2024-05-28 14:22:13,000:INFO:Uploading results into container
2024-05-28 14:22:13,000:INFO:Uploading model into container now
2024-05-28 14:22:13,000:INFO:_master_model_container: 16
2024-05-28 14:22:13,000:INFO:_display_container: 2
2024-05-28 14:22:13,000:INFO:DummyClassifier(constant=None, random_state=7313, strategy='prior')
2024-05-28 14:22:13,000:INFO:create_model() successfully completed......................................
2024-05-28 14:22:13,250:INFO:SubProcess create_model() end ==================================
2024-05-28 14:22:13,250:INFO:Creating metrics dataframe
2024-05-28 14:22:13,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:22:13,267:INFO:Initializing create_model()
2024-05-28 14:22:13,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:22:13,267:INFO:Checking exceptions
2024-05-28 14:22:13,267:INFO:Importing libraries
2024-05-28 14:22:13,267:INFO:Copying training dataset
2024-05-28 14:22:13,290:INFO:Defining folds
2024-05-28 14:22:13,290:INFO:Declaring metric variables
2024-05-28 14:22:13,290:INFO:Importing untrained model
2024-05-28 14:22:13,291:INFO:Declaring custom model
2024-05-28 14:22:13,291:INFO:Logistic Regression Imported successfully
2024-05-28 14:22:13,294:INFO:Cross validation set to False
2024-05-28 14:22:13,295:INFO:Fitting Model
2024-05-28 14:22:13,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:22:13,950:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:22:13,950:INFO:create_model() successfully completed......................................
2024-05-28 14:22:14,249:INFO:_master_model_container: 16
2024-05-28 14:22:14,249:INFO:_display_container: 2
2024-05-28 14:22:14,265:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:22:14,266:INFO:compare_models() successfully completed......................................
2024-05-28 14:22:14,349:INFO:Initializing save_model()
2024-05-28 14:22:14,349:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:22:14,349:INFO:Adding model into prep_pipe
2024-05-28 14:22:14,390:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:22:14,457:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7313,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:22:14,458:INFO:save_model() successfully completed......................................
2024-05-28 14:23:56,227:INFO:PyCaret ClassificationExperiment
2024-05-28 14:23:56,228:INFO:Logging name: clf-default-name
2024-05-28 14:23:56,228:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:23:56,228:INFO:version 3.3.1
2024-05-28 14:23:56,228:INFO:Initializing setup()
2024-05-28 14:23:56,228:INFO:self.USI: 20f8
2024-05-28 14:23:56,230:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:23:56,230:INFO:Checking environment
2024-05-28 14:23:56,231:INFO:python_version: 3.11.9
2024-05-28 14:23:56,232:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:23:56,232:INFO:machine: AMD64
2024-05-28 14:23:56,232:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:23:56,232:INFO:Memory: svmem(total=8469606400, available=1309298688, percent=84.5, used=7160307712, free=1309298688)
2024-05-28 14:23:56,232:INFO:Physical Core: 2
2024-05-28 14:23:56,232:INFO:Logical Core: 4
2024-05-28 14:23:56,232:INFO:Checking libraries
2024-05-28 14:23:56,232:INFO:System:
2024-05-28 14:23:56,232:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:23:56,232:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:23:56,232:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:23:56,232:INFO:PyCaret required dependencies:
2024-05-28 14:23:56,232:INFO:                 pip: 24.0
2024-05-28 14:23:56,232:INFO:          setuptools: 70.0.0
2024-05-28 14:23:56,232:INFO:             pycaret: 3.3.1
2024-05-28 14:23:56,232:INFO:             IPython: 8.24.0
2024-05-28 14:23:56,232:INFO:          ipywidgets: 8.1.2
2024-05-28 14:23:56,232:INFO:                tqdm: 4.66.4
2024-05-28 14:23:56,232:INFO:               numpy: 1.26.4
2024-05-28 14:23:56,232:INFO:              pandas: 2.1.4
2024-05-28 14:23:56,232:INFO:              jinja2: 3.1.4
2024-05-28 14:23:56,232:INFO:               scipy: 1.11.4
2024-05-28 14:23:56,232:INFO:              joblib: 1.3.2
2024-05-28 14:23:56,232:INFO:             sklearn: 1.4.2
2024-05-28 14:23:56,232:INFO:                pyod: 1.1.3
2024-05-28 14:23:56,232:INFO:            imblearn: 0.12.2
2024-05-28 14:23:56,232:INFO:   category_encoders: 2.6.3
2024-05-28 14:23:56,232:INFO:            lightgbm: 4.3.0
2024-05-28 14:23:56,232:INFO:               numba: 0.58.1
2024-05-28 14:23:56,232:INFO:            requests: 2.32.2
2024-05-28 14:23:56,232:INFO:          matplotlib: 3.7.5
2024-05-28 14:23:56,232:INFO:          scikitplot: 0.3.7
2024-05-28 14:23:56,232:INFO:         yellowbrick: 1.5
2024-05-28 14:23:56,232:INFO:              plotly: 5.22.0
2024-05-28 14:23:56,232:INFO:    plotly-resampler: Not installed
2024-05-28 14:23:56,232:INFO:             kaleido: 0.2.1
2024-05-28 14:23:56,232:INFO:           schemdraw: 0.15
2024-05-28 14:23:56,232:INFO:         statsmodels: 0.14.2
2024-05-28 14:23:56,232:INFO:              sktime: 0.26.0
2024-05-28 14:23:56,232:INFO:               tbats: 1.1.3
2024-05-28 14:23:56,232:INFO:            pmdarima: 2.0.4
2024-05-28 14:23:56,232:INFO:              psutil: 5.9.8
2024-05-28 14:23:56,232:INFO:          markupsafe: 2.1.5
2024-05-28 14:23:56,232:INFO:             pickle5: Not installed
2024-05-28 14:23:56,232:INFO:         cloudpickle: 3.0.0
2024-05-28 14:23:56,232:INFO:         deprecation: 2.1.0
2024-05-28 14:23:56,232:INFO:              xxhash: 3.4.1
2024-05-28 14:23:56,232:INFO:           wurlitzer: 3.1.0
2024-05-28 14:23:56,232:INFO:PyCaret optional dependencies:
2024-05-28 14:23:56,232:INFO:                shap: Not installed
2024-05-28 14:23:56,232:INFO:           interpret: Not installed
2024-05-28 14:23:56,232:INFO:                umap: 0.5.5
2024-05-28 14:23:56,232:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:23:56,232:INFO:  explainerdashboard: Not installed
2024-05-28 14:23:56,232:INFO:             autoviz: Not installed
2024-05-28 14:23:56,232:INFO:           fairlearn: Not installed
2024-05-28 14:23:56,232:INFO:          deepchecks: Not installed
2024-05-28 14:23:56,232:INFO:             xgboost: 2.0.3
2024-05-28 14:23:56,232:INFO:            catboost: 1.2.5
2024-05-28 14:23:56,232:INFO:              kmodes: 0.12.2
2024-05-28 14:23:56,232:INFO:             mlxtend: 0.23.1
2024-05-28 14:23:56,232:INFO:       statsforecast: Not installed
2024-05-28 14:23:56,247:INFO:        tune_sklearn: Not installed
2024-05-28 14:23:56,247:INFO:                 ray: Not installed
2024-05-28 14:23:56,247:INFO:            hyperopt: Not installed
2024-05-28 14:23:56,248:INFO:              optuna: Not installed
2024-05-28 14:23:56,249:INFO:               skopt: Not installed
2024-05-28 14:23:56,249:INFO:              mlflow: 2.13.0
2024-05-28 14:23:56,249:INFO:              gradio: Not installed
2024-05-28 14:23:56,249:INFO:             fastapi: Not installed
2024-05-28 14:23:56,249:INFO:             uvicorn: Not installed
2024-05-28 14:23:56,249:INFO:              m2cgen: Not installed
2024-05-28 14:23:56,249:INFO:           evidently: Not installed
2024-05-28 14:23:56,250:INFO:               fugue: Not installed
2024-05-28 14:23:56,250:INFO:           streamlit: 1.35.0
2024-05-28 14:23:56,250:INFO:             prophet: Not installed
2024-05-28 14:23:56,250:INFO:None
2024-05-28 14:23:56,250:INFO:Set up data.
2024-05-28 14:23:56,271:INFO:Set up folding strategy.
2024-05-28 14:23:56,272:INFO:Set up train/test split.
2024-05-28 14:23:56,282:INFO:Set up index.
2024-05-28 14:23:56,282:INFO:Assigning column types.
2024-05-28 14:23:56,301:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:23:56,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,548:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,565:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,742:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,746:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,748:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:23:56,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,891:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,895:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:57,031:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,031:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:23:57,182:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,182:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,366:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,366:INFO:Preparing preprocessing pipeline...
2024-05-28 14:23:57,366:INFO:Set up simple imputation.
2024-05-28 14:23:57,366:INFO:Set up encoding of ordinal features.
2024-05-28 14:23:57,383:INFO:Set up encoding of categorical features.
2024-05-28 14:23:57,383:INFO:Set up imbalanced handling.
2024-05-28 14:23:57,814:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:23:57,881:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:23:57,881:INFO:Creating final display dataframe.
2024-05-28 14:23:59,374:INFO:Setup _display_container:                     Description             Value
0                    Session id               436
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              20f8
2024-05-28 14:23:59,530:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:59,530:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:59,679:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:59,679:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:59,696:INFO:setup() successfully completed in 3.47s...............
2024-05-28 14:23:59,702:INFO:Initializing compare_models()
2024-05-28 14:23:59,702:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:23:59,702:INFO:Checking exceptions
2024-05-28 14:23:59,710:INFO:Preparing display monitor
2024-05-28 14:23:59,719:INFO:Initializing Logistic Regression
2024-05-28 14:23:59,720:INFO:Total runtime is 1.6645590464274088e-05 minutes
2024-05-28 14:23:59,721:INFO:SubProcess create_model() called ==================================
2024-05-28 14:23:59,722:INFO:Initializing create_model()
2024-05-28 14:23:59,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:23:59,722:INFO:Checking exceptions
2024-05-28 14:23:59,722:INFO:Importing libraries
2024-05-28 14:23:59,722:INFO:Copying training dataset
2024-05-28 14:23:59,738:INFO:Defining folds
2024-05-28 14:23:59,738:INFO:Declaring metric variables
2024-05-28 14:23:59,739:INFO:Importing untrained model
2024-05-28 14:23:59,739:INFO:Logistic Regression Imported successfully
2024-05-28 14:23:59,740:INFO:Starting cross validation
2024-05-28 14:23:59,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:00,415:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,491:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,512:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,551:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,744:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,745:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,841:INFO:Calculating mean and std
2024-05-28 14:24:01,841:INFO:Creating metrics dataframe
2024-05-28 14:24:01,847:INFO:Uploading results into container
2024-05-28 14:24:01,848:INFO:Uploading model into container now
2024-05-28 14:24:01,849:INFO:_master_model_container: 1
2024-05-28 14:24:01,849:INFO:_display_container: 2
2024-05-28 14:24:01,850:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:24:01,850:INFO:create_model() successfully completed......................................
2024-05-28 14:24:01,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:02,077:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:02,077:INFO:Creating metrics dataframe
2024-05-28 14:24:02,077:INFO:Initializing K Neighbors Classifier
2024-05-28 14:24:02,077:INFO:Total runtime is 0.03929454485575359 minutes
2024-05-28 14:24:02,077:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:02,093:INFO:Initializing create_model()
2024-05-28 14:24:02,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:02,093:INFO:Checking exceptions
2024-05-28 14:24:02,093:INFO:Importing libraries
2024-05-28 14:24:02,093:INFO:Copying training dataset
2024-05-28 14:24:02,100:INFO:Defining folds
2024-05-28 14:24:02,101:INFO:Declaring metric variables
2024-05-28 14:24:02,101:INFO:Importing untrained model
2024-05-28 14:24:02,101:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:24:02,102:INFO:Starting cross validation
2024-05-28 14:24:02,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:02,505:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,514:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,846:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,935:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,969:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,235:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,266:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,284:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,308:INFO:Calculating mean and std
2024-05-28 14:24:03,310:INFO:Creating metrics dataframe
2024-05-28 14:24:03,310:INFO:Uploading results into container
2024-05-28 14:24:03,310:INFO:Uploading model into container now
2024-05-28 14:24:03,310:INFO:_master_model_container: 2
2024-05-28 14:24:03,310:INFO:_display_container: 2
2024-05-28 14:24:03,310:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:24:03,310:INFO:create_model() successfully completed......................................
2024-05-28 14:24:03,521:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:03,521:INFO:Creating metrics dataframe
2024-05-28 14:24:03,526:INFO:Initializing Naive Bayes
2024-05-28 14:24:03,526:INFO:Total runtime is 0.06344113349914551 minutes
2024-05-28 14:24:03,526:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:03,526:INFO:Initializing create_model()
2024-05-28 14:24:03,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:03,526:INFO:Checking exceptions
2024-05-28 14:24:03,526:INFO:Importing libraries
2024-05-28 14:24:03,526:INFO:Copying training dataset
2024-05-28 14:24:03,526:INFO:Defining folds
2024-05-28 14:24:03,526:INFO:Declaring metric variables
2024-05-28 14:24:03,526:INFO:Importing untrained model
2024-05-28 14:24:03,526:INFO:Naive Bayes Imported successfully
2024-05-28 14:24:03,526:INFO:Starting cross validation
2024-05-28 14:24:03,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:03,845:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,845:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,871:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,902:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,219:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,242:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,490:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,512:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,543:INFO:Calculating mean and std
2024-05-28 14:24:04,544:INFO:Creating metrics dataframe
2024-05-28 14:24:04,548:INFO:Uploading results into container
2024-05-28 14:24:04,549:INFO:Uploading model into container now
2024-05-28 14:24:04,550:INFO:_master_model_container: 3
2024-05-28 14:24:04,550:INFO:_display_container: 2
2024-05-28 14:24:04,550:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:24:04,551:INFO:create_model() successfully completed......................................
2024-05-28 14:24:04,756:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:04,757:INFO:Creating metrics dataframe
2024-05-28 14:24:04,758:INFO:Initializing Decision Tree Classifier
2024-05-28 14:24:04,758:INFO:Total runtime is 0.0839883844057719 minutes
2024-05-28 14:24:04,758:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:04,758:INFO:Initializing create_model()
2024-05-28 14:24:04,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:04,758:INFO:Checking exceptions
2024-05-28 14:24:04,758:INFO:Importing libraries
2024-05-28 14:24:04,758:INFO:Copying training dataset
2024-05-28 14:24:04,758:INFO:Defining folds
2024-05-28 14:24:04,758:INFO:Declaring metric variables
2024-05-28 14:24:04,758:INFO:Importing untrained model
2024-05-28 14:24:04,758:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:24:04,758:INFO:Starting cross validation
2024-05-28 14:24:04,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:05,164:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,185:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,185:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,196:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,217:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,613:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,618:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,626:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,636:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,644:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,662:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,926:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,935:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,940:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,951:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,967:INFO:Calculating mean and std
2024-05-28 14:24:05,967:INFO:Creating metrics dataframe
2024-05-28 14:24:05,967:INFO:Uploading results into container
2024-05-28 14:24:05,967:INFO:Uploading model into container now
2024-05-28 14:24:05,967:INFO:_master_model_container: 4
2024-05-28 14:24:05,967:INFO:_display_container: 2
2024-05-28 14:24:05,973:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=436, splitter='best')
2024-05-28 14:24:05,973:INFO:create_model() successfully completed......................................
2024-05-28 14:24:06,185:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:06,185:INFO:Creating metrics dataframe
2024-05-28 14:24:06,191:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:24:06,191:INFO:Total runtime is 0.10786227385203045 minutes
2024-05-28 14:24:06,191:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:06,191:INFO:Initializing create_model()
2024-05-28 14:24:06,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:06,191:INFO:Checking exceptions
2024-05-28 14:24:06,191:INFO:Importing libraries
2024-05-28 14:24:06,191:INFO:Copying training dataset
2024-05-28 14:24:06,191:INFO:Defining folds
2024-05-28 14:24:06,191:INFO:Declaring metric variables
2024-05-28 14:24:06,191:INFO:Importing untrained model
2024-05-28 14:24:06,191:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:24:06,191:INFO:Starting cross validation
2024-05-28 14:24:06,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:06,984:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:07,020:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:07,297:INFO:Calculating mean and std
2024-05-28 14:24:07,299:INFO:Creating metrics dataframe
2024-05-28 14:24:07,303:INFO:Uploading results into container
2024-05-28 14:24:07,304:INFO:Uploading model into container now
2024-05-28 14:24:07,306:INFO:_master_model_container: 5
2024-05-28 14:24:07,306:INFO:_display_container: 2
2024-05-28 14:24:07,307:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=436, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:24:07,307:INFO:create_model() successfully completed......................................
2024-05-28 14:24:07,506:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:07,506:INFO:Creating metrics dataframe
2024-05-28 14:24:07,506:INFO:Initializing Ridge Classifier
2024-05-28 14:24:07,506:INFO:Total runtime is 0.1297842303911845 minutes
2024-05-28 14:24:07,506:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:07,506:INFO:Initializing create_model()
2024-05-28 14:24:07,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:07,506:INFO:Checking exceptions
2024-05-28 14:24:07,506:INFO:Importing libraries
2024-05-28 14:24:07,506:INFO:Copying training dataset
2024-05-28 14:24:07,533:INFO:Defining folds
2024-05-28 14:24:07,533:INFO:Declaring metric variables
2024-05-28 14:24:07,534:INFO:Importing untrained model
2024-05-28 14:24:07,534:INFO:Ridge Classifier Imported successfully
2024-05-28 14:24:07,535:INFO:Starting cross validation
2024-05-28 14:24:07,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:08,778:INFO:Calculating mean and std
2024-05-28 14:24:08,780:INFO:Creating metrics dataframe
2024-05-28 14:24:08,784:INFO:Uploading results into container
2024-05-28 14:24:08,785:INFO:Uploading model into container now
2024-05-28 14:24:08,786:INFO:_master_model_container: 6
2024-05-28 14:24:08,786:INFO:_display_container: 2
2024-05-28 14:24:08,786:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=436, solver='auto',
                tol=0.0001)
2024-05-28 14:24:08,787:INFO:create_model() successfully completed......................................
2024-05-28 14:24:09,006:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:09,006:INFO:Creating metrics dataframe
2024-05-28 14:24:09,023:INFO:Initializing Random Forest Classifier
2024-05-28 14:24:09,023:INFO:Total runtime is 0.1550586263338725 minutes
2024-05-28 14:24:09,023:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:09,023:INFO:Initializing create_model()
2024-05-28 14:24:09,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:09,023:INFO:Checking exceptions
2024-05-28 14:24:09,023:INFO:Importing libraries
2024-05-28 14:24:09,023:INFO:Copying training dataset
2024-05-28 14:24:09,023:INFO:Defining folds
2024-05-28 14:24:09,023:INFO:Declaring metric variables
2024-05-28 14:24:09,023:INFO:Importing untrained model
2024-05-28 14:24:09,039:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:24:09,040:INFO:Starting cross validation
2024-05-28 14:24:09,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:10,063:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,152:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,238:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,240:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,249:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,813:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,823:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:11,497:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:11,516:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:11,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:11,883:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,140:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,150:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,665:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,668:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,678:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,699:INFO:Calculating mean and std
2024-05-28 14:24:12,701:INFO:Creating metrics dataframe
2024-05-28 14:24:12,705:INFO:Uploading results into container
2024-05-28 14:24:12,706:INFO:Uploading model into container now
2024-05-28 14:24:12,707:INFO:_master_model_container: 7
2024-05-28 14:24:12,707:INFO:_display_container: 2
2024-05-28 14:24:12,708:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=436, verbose=0,
                       warm_start=False)
2024-05-28 14:24:12,709:INFO:create_model() successfully completed......................................
2024-05-28 14:24:12,969:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:12,969:INFO:Creating metrics dataframe
2024-05-28 14:24:12,975:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:24:12,975:INFO:Total runtime is 0.22093560695648196 minutes
2024-05-28 14:24:12,976:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:12,976:INFO:Initializing create_model()
2024-05-28 14:24:12,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:12,977:INFO:Checking exceptions
2024-05-28 14:24:12,977:INFO:Importing libraries
2024-05-28 14:24:12,977:INFO:Copying training dataset
2024-05-28 14:24:12,987:INFO:Defining folds
2024-05-28 14:24:12,988:INFO:Declaring metric variables
2024-05-28 14:24:12,988:INFO:Importing untrained model
2024-05-28 14:24:12,989:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:24:12,989:INFO:Starting cross validation
2024-05-28 14:24:12,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:13,345:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,355:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,355:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,375:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,449:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,717:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,737:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,746:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,024:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,040:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,123:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,166:INFO:Calculating mean and std
2024-05-28 14:24:14,168:INFO:Creating metrics dataframe
2024-05-28 14:24:14,171:INFO:Uploading results into container
2024-05-28 14:24:14,172:INFO:Uploading model into container now
2024-05-28 14:24:14,173:INFO:_master_model_container: 8
2024-05-28 14:24:14,173:INFO:_display_container: 2
2024-05-28 14:24:14,174:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:24:14,174:INFO:create_model() successfully completed......................................
2024-05-28 14:24:14,398:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:14,398:INFO:Creating metrics dataframe
2024-05-28 14:24:14,414:INFO:Initializing Ada Boost Classifier
2024-05-28 14:24:14,414:INFO:Total runtime is 0.24492205381393434 minutes
2024-05-28 14:24:14,418:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:14,419:INFO:Initializing create_model()
2024-05-28 14:24:14,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:14,419:INFO:Checking exceptions
2024-05-28 14:24:14,419:INFO:Importing libraries
2024-05-28 14:24:14,420:INFO:Copying training dataset
2024-05-28 14:24:14,426:INFO:Defining folds
2024-05-28 14:24:14,426:INFO:Declaring metric variables
2024-05-28 14:24:14,427:INFO:Importing untrained model
2024-05-28 14:24:14,428:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:24:14,428:INFO:Starting cross validation
2024-05-28 14:24:14,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:14,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,677:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,704:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,750:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,757:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,767:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,797:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,960:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,963:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,982:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,989:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,045:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,057:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,073:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,206:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,206:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,287:INFO:Calculating mean and std
2024-05-28 14:24:15,287:INFO:Creating metrics dataframe
2024-05-28 14:24:15,287:INFO:Uploading results into container
2024-05-28 14:24:15,287:INFO:Uploading model into container now
2024-05-28 14:24:15,287:INFO:_master_model_container: 9
2024-05-28 14:24:15,287:INFO:_display_container: 2
2024-05-28 14:24:15,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=436)
2024-05-28 14:24:15,287:INFO:create_model() successfully completed......................................
2024-05-28 14:24:15,458:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:15,458:INFO:Creating metrics dataframe
2024-05-28 14:24:15,474:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:24:15,474:INFO:Total runtime is 0.26258054574330647 minutes
2024-05-28 14:24:15,474:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:15,474:INFO:Initializing create_model()
2024-05-28 14:24:15,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:15,474:INFO:Checking exceptions
2024-05-28 14:24:15,474:INFO:Importing libraries
2024-05-28 14:24:15,474:INFO:Copying training dataset
2024-05-28 14:24:15,474:INFO:Defining folds
2024-05-28 14:24:15,474:INFO:Declaring metric variables
2024-05-28 14:24:15,474:INFO:Importing untrained model
2024-05-28 14:24:15,474:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:24:15,474:INFO:Starting cross validation
2024-05-28 14:24:15,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:16,135:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,020:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,084:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,116:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:23,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:23,856:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:25,122:INFO:Calculating mean and std
2024-05-28 14:24:25,162:INFO:Creating metrics dataframe
2024-05-28 14:24:25,465:INFO:Uploading results into container
2024-05-28 14:24:25,471:INFO:Uploading model into container now
2024-05-28 14:24:25,480:INFO:_master_model_container: 10
2024-05-28 14:24:25,481:INFO:_display_container: 2
2024-05-28 14:24:25,487:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=436, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:24:25,490:INFO:create_model() successfully completed......................................
2024-05-28 14:24:28,479:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:28,482:INFO:Creating metrics dataframe
2024-05-28 14:24:28,668:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:24:28,671:INFO:Total runtime is 0.482520318031311 minutes
2024-05-28 14:24:28,727:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:28,733:INFO:Initializing create_model()
2024-05-28 14:24:28,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:28,738:INFO:Checking exceptions
2024-05-28 14:24:28,740:INFO:Importing libraries
2024-05-28 14:24:28,742:INFO:Copying training dataset
2024-05-28 14:24:29,076:INFO:Defining folds
2024-05-28 14:24:29,080:INFO:Declaring metric variables
2024-05-28 14:24:29,084:INFO:Importing untrained model
2024-05-28 14:24:29,089:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:24:29,096:INFO:Starting cross validation
2024-05-28 14:24:29,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:35,141:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,164:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,604:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,642:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,677:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,725:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:37,909:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:37,972:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:38,010:INFO:Calculating mean and std
2024-05-28 14:24:38,066:INFO:Creating metrics dataframe
2024-05-28 14:24:38,072:INFO:Uploading results into container
2024-05-28 14:24:38,075:INFO:Uploading model into container now
2024-05-28 14:24:38,076:INFO:_master_model_container: 11
2024-05-28 14:24:38,077:INFO:_display_container: 2
2024-05-28 14:24:38,078:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:24:38,078:INFO:create_model() successfully completed......................................
2024-05-28 14:24:38,581:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:38,581:INFO:Creating metrics dataframe
2024-05-28 14:24:38,598:INFO:Initializing Extra Trees Classifier
2024-05-28 14:24:38,598:INFO:Total runtime is 0.6479743560155232 minutes
2024-05-28 14:24:38,599:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:38,601:INFO:Initializing create_model()
2024-05-28 14:24:38,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:38,601:INFO:Checking exceptions
2024-05-28 14:24:38,602:INFO:Importing libraries
2024-05-28 14:24:38,602:INFO:Copying training dataset
2024-05-28 14:24:38,642:INFO:Defining folds
2024-05-28 14:24:38,642:INFO:Declaring metric variables
2024-05-28 14:24:38,643:INFO:Importing untrained model
2024-05-28 14:24:38,645:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:24:38,646:INFO:Starting cross validation
2024-05-28 14:24:38,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:40,990:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:40,995:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:41,010:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:41,249:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,806:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,832:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,860:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:42,867:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,871:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:42,891:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:43,434:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,897:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,910:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:43,928:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,971:INFO:Calculating mean and std
2024-05-28 14:24:43,974:INFO:Creating metrics dataframe
2024-05-28 14:24:43,979:INFO:Uploading results into container
2024-05-28 14:24:43,981:INFO:Uploading model into container now
2024-05-28 14:24:43,982:INFO:_master_model_container: 12
2024-05-28 14:24:43,982:INFO:_display_container: 2
2024-05-28 14:24:43,984:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=436, verbose=0,
                     warm_start=False)
2024-05-28 14:24:43,984:INFO:create_model() successfully completed......................................
2024-05-28 14:24:44,276:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:44,276:INFO:Creating metrics dataframe
2024-05-28 14:24:44,292:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:24:44,292:INFO:Total runtime is 0.7428793827692667 minutes
2024-05-28 14:24:44,293:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:44,294:INFO:Initializing create_model()
2024-05-28 14:24:44,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:44,294:INFO:Checking exceptions
2024-05-28 14:24:44,294:INFO:Importing libraries
2024-05-28 14:24:44,295:INFO:Copying training dataset
2024-05-28 14:24:44,313:INFO:Defining folds
2024-05-28 14:24:44,313:INFO:Declaring metric variables
2024-05-28 14:24:44,314:INFO:Importing untrained model
2024-05-28 14:24:44,316:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:24:44,317:INFO:Starting cross validation
2024-05-28 14:24:44,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:44,923:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,926:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,952:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,964:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,983:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,583:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,604:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,622:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,645:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,661:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:46,169:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,194:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:46,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,235:INFO:Calculating mean and std
2024-05-28 14:24:46,237:INFO:Creating metrics dataframe
2024-05-28 14:24:46,244:INFO:Uploading results into container
2024-05-28 14:24:46,246:INFO:Uploading model into container now
2024-05-28 14:24:46,247:INFO:_master_model_container: 13
2024-05-28 14:24:46,247:INFO:_display_container: 2
2024-05-28 14:24:46,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:24:46,250:INFO:create_model() successfully completed......................................
2024-05-28 14:24:46,559:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:46,560:INFO:Creating metrics dataframe
2024-05-28 14:24:46,569:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:24:46,570:INFO:Total runtime is 0.7808470646540323 minutes
2024-05-28 14:24:46,570:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:46,571:INFO:Initializing create_model()
2024-05-28 14:24:46,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:46,572:INFO:Checking exceptions
2024-05-28 14:24:46,572:INFO:Importing libraries
2024-05-28 14:24:46,573:INFO:Copying training dataset
2024-05-28 14:24:46,592:INFO:Defining folds
2024-05-28 14:24:46,592:INFO:Declaring metric variables
2024-05-28 14:24:46,593:INFO:Importing untrained model
2024-05-28 14:24:46,594:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:24:46,595:INFO:Starting cross validation
2024-05-28 14:24:46,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:47,820:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,827:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,835:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:47,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:47,857:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:48,399:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:48,421:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:48,974:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,050:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,064:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,089:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,112:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,662:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,678:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,958:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,977:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:50,005:INFO:Calculating mean and std
2024-05-28 14:24:50,005:INFO:Creating metrics dataframe
2024-05-28 14:24:50,005:INFO:Uploading results into container
2024-05-28 14:24:50,005:INFO:Uploading model into container now
2024-05-28 14:24:50,005:INFO:_master_model_container: 14
2024-05-28 14:24:50,005:INFO:_display_container: 2
2024-05-28 14:24:50,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=436, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:24:50,005:INFO:create_model() successfully completed......................................
2024-05-28 14:24:50,287:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:50,287:INFO:Creating metrics dataframe
2024-05-28 14:24:50,310:INFO:Initializing CatBoost Classifier
2024-05-28 14:24:50,310:INFO:Total runtime is 0.8431777556737263 minutes
2024-05-28 14:24:50,310:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:50,311:INFO:Initializing create_model()
2024-05-28 14:24:50,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:50,311:INFO:Checking exceptions
2024-05-28 14:24:50,311:INFO:Importing libraries
2024-05-28 14:24:50,312:INFO:Copying training dataset
2024-05-28 14:24:50,321:INFO:Defining folds
2024-05-28 14:24:50,321:INFO:Declaring metric variables
2024-05-28 14:24:50,321:INFO:Importing untrained model
2024-05-28 14:24:50,321:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:24:50,321:INFO:Starting cross validation
2024-05-28 14:24:50,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:59,467:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,495:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,596:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,620:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,664:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,700:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,930:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,930:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,543:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,640:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,773:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,792:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,949:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,957:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,669:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:14,685:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,689:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:14,702:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,716:INFO:Calculating mean and std
2024-05-28 14:25:14,719:INFO:Creating metrics dataframe
2024-05-28 14:25:14,724:INFO:Uploading results into container
2024-05-28 14:25:14,726:INFO:Uploading model into container now
2024-05-28 14:25:14,727:INFO:_master_model_container: 15
2024-05-28 14:25:14,727:INFO:_display_container: 2
2024-05-28 14:25:14,728:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCC201B90>
2024-05-28 14:25:14,728:INFO:create_model() successfully completed......................................
2024-05-28 14:25:14,985:INFO:SubProcess create_model() end ==================================
2024-05-28 14:25:14,985:INFO:Creating metrics dataframe
2024-05-28 14:25:15,003:INFO:Initializing Dummy Classifier
2024-05-28 14:25:15,004:INFO:Total runtime is 1.2547542572021484 minutes
2024-05-28 14:25:15,004:INFO:SubProcess create_model() called ==================================
2024-05-28 14:25:15,005:INFO:Initializing create_model()
2024-05-28 14:25:15,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:25:15,005:INFO:Checking exceptions
2024-05-28 14:25:15,005:INFO:Importing libraries
2024-05-28 14:25:15,005:INFO:Copying training dataset
2024-05-28 14:25:15,017:INFO:Defining folds
2024-05-28 14:25:15,017:INFO:Declaring metric variables
2024-05-28 14:25:15,018:INFO:Importing untrained model
2024-05-28 14:25:15,018:INFO:Dummy Classifier Imported successfully
2024-05-28 14:25:15,019:INFO:Starting cross validation
2024-05-28 14:25:15,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:25:15,384:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,390:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,430:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,436:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,700:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,709:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,710:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,714:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,721:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,738:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,764:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,994:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:16,008:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:16,012:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:16,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:16,047:INFO:Calculating mean and std
2024-05-28 14:25:16,049:INFO:Creating metrics dataframe
2024-05-28 14:25:16,054:INFO:Uploading results into container
2024-05-28 14:25:16,055:INFO:Uploading model into container now
2024-05-28 14:25:16,056:INFO:_master_model_container: 16
2024-05-28 14:25:16,056:INFO:_display_container: 2
2024-05-28 14:25:16,056:INFO:DummyClassifier(constant=None, random_state=436, strategy='prior')
2024-05-28 14:25:16,056:INFO:create_model() successfully completed......................................
2024-05-28 14:25:16,317:INFO:SubProcess create_model() end ==================================
2024-05-28 14:25:16,317:INFO:Creating metrics dataframe
2024-05-28 14:25:16,317:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:25:16,334:INFO:Initializing create_model()
2024-05-28 14:25:16,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:25:16,335:INFO:Checking exceptions
2024-05-28 14:25:16,336:INFO:Importing libraries
2024-05-28 14:25:16,337:INFO:Copying training dataset
2024-05-28 14:25:16,349:INFO:Defining folds
2024-05-28 14:25:16,350:INFO:Declaring metric variables
2024-05-28 14:25:16,350:INFO:Importing untrained model
2024-05-28 14:25:16,350:INFO:Declaring custom model
2024-05-28 14:25:16,352:INFO:Logistic Regression Imported successfully
2024-05-28 14:25:16,356:INFO:Cross validation set to False
2024-05-28 14:25:16,356:INFO:Fitting Model
2024-05-28 14:25:17,049:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:25:17,049:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:25:17,049:INFO:create_model() successfully completed......................................
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,353:INFO:_master_model_container: 16
2024-05-28 14:25:17,353:INFO:_display_container: 2
2024-05-28 14:25:17,354:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:25:17,355:INFO:compare_models() successfully completed......................................
2024-05-28 14:25:17,449:INFO:Initializing save_model()
2024-05-28 14:25:17,449:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:25:17,449:INFO:Adding model into prep_pipe
2024-05-28 14:25:17,499:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:25:17,599:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=436,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:25:17,599:INFO:save_model() successfully completed......................................
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:37,362:INFO:PyCaret ClassificationExperiment
2024-05-28 14:26:37,435:INFO:Logging name: clf-default-name
2024-05-28 14:26:37,440:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:26:37,442:INFO:version 3.3.1
2024-05-28 14:26:37,443:INFO:Initializing setup()
2024-05-28 14:26:37,444:INFO:self.USI: 7a3f
2024-05-28 14:26:37,445:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:26:37,446:INFO:Checking environment
2024-05-28 14:26:37,447:INFO:python_version: 3.11.9
2024-05-28 14:26:37,450:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:26:37,452:INFO:machine: AMD64
2024-05-28 14:26:37,453:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:26:37,569:INFO:Memory: svmem(total=8469606400, available=1492000768, percent=82.4, used=6977605632, free=1492000768)
2024-05-28 14:26:37,570:INFO:Physical Core: 2
2024-05-28 14:26:37,571:INFO:Logical Core: 4
2024-05-28 14:26:37,628:INFO:Checking libraries
2024-05-28 14:26:37,630:INFO:System:
2024-05-28 14:26:37,631:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:26:37,632:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:26:37,634:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:26:37,635:INFO:PyCaret required dependencies:
2024-05-28 14:26:37,638:INFO:                 pip: 24.0
2024-05-28 14:26:37,639:INFO:          setuptools: 70.0.0
2024-05-28 14:26:37,640:INFO:             pycaret: 3.3.1
2024-05-28 14:26:37,641:INFO:             IPython: 8.24.0
2024-05-28 14:26:37,642:INFO:          ipywidgets: 8.1.2
2024-05-28 14:26:37,643:INFO:                tqdm: 4.66.4
2024-05-28 14:26:37,644:INFO:               numpy: 1.26.4
2024-05-28 14:26:37,645:INFO:              pandas: 2.1.4
2024-05-28 14:26:37,646:INFO:              jinja2: 3.1.4
2024-05-28 14:26:37,647:INFO:               scipy: 1.11.4
2024-05-28 14:26:37,648:INFO:              joblib: 1.3.2
2024-05-28 14:26:37,654:INFO:             sklearn: 1.4.2
2024-05-28 14:26:37,693:INFO:                pyod: 1.1.3
2024-05-28 14:26:37,695:INFO:            imblearn: 0.12.2
2024-05-28 14:26:37,696:INFO:   category_encoders: 2.6.3
2024-05-28 14:26:37,697:INFO:            lightgbm: 4.3.0
2024-05-28 14:26:37,702:INFO:               numba: 0.58.1
2024-05-28 14:26:37,704:INFO:            requests: 2.32.2
2024-05-28 14:26:37,705:INFO:          matplotlib: 3.7.5
2024-05-28 14:26:37,706:INFO:          scikitplot: 0.3.7
2024-05-28 14:26:37,707:INFO:         yellowbrick: 1.5
2024-05-28 14:26:37,707:INFO:              plotly: 5.22.0
2024-05-28 14:26:37,859:INFO:    plotly-resampler: Not installed
2024-05-28 14:26:37,860:INFO:             kaleido: 0.2.1
2024-05-28 14:26:37,861:INFO:           schemdraw: 0.15
2024-05-28 14:26:37,862:INFO:         statsmodels: 0.14.2
2024-05-28 14:26:37,863:INFO:              sktime: 0.26.0
2024-05-28 14:26:37,864:INFO:               tbats: 1.1.3
2024-05-28 14:26:37,875:INFO:            pmdarima: 2.0.4
2024-05-28 14:26:37,876:INFO:              psutil: 5.9.8
2024-05-28 14:26:37,877:INFO:          markupsafe: 2.1.5
2024-05-28 14:26:37,879:INFO:             pickle5: Not installed
2024-05-28 14:26:37,880:INFO:         cloudpickle: 3.0.0
2024-05-28 14:26:37,880:INFO:         deprecation: 2.1.0
2024-05-28 14:26:37,883:INFO:              xxhash: 3.4.1
2024-05-28 14:26:37,884:INFO:           wurlitzer: 3.1.0
2024-05-28 14:26:37,885:INFO:PyCaret optional dependencies:
2024-05-28 14:26:37,889:INFO:                shap: Not installed
2024-05-28 14:26:37,890:INFO:           interpret: Not installed
2024-05-28 14:26:37,893:INFO:                umap: 0.5.5
2024-05-28 14:26:37,894:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:26:37,895:INFO:  explainerdashboard: Not installed
2024-05-28 14:26:37,897:INFO:             autoviz: Not installed
2024-05-28 14:26:37,901:INFO:           fairlearn: Not installed
2024-05-28 14:26:37,903:INFO:          deepchecks: Not installed
2024-05-28 14:26:37,904:INFO:             xgboost: 2.0.3
2024-05-28 14:26:37,906:INFO:            catboost: 1.2.5
2024-05-28 14:26:37,907:INFO:              kmodes: 0.12.2
2024-05-28 14:26:38,117:INFO:             mlxtend: 0.23.1
2024-05-28 14:26:38,119:INFO:       statsforecast: Not installed
2024-05-28 14:26:38,120:INFO:        tune_sklearn: Not installed
2024-05-28 14:26:38,121:INFO:                 ray: Not installed
2024-05-28 14:26:38,122:INFO:            hyperopt: Not installed
2024-05-28 14:26:38,123:INFO:              optuna: Not installed
2024-05-28 14:26:38,124:INFO:               skopt: Not installed
2024-05-28 14:26:38,125:INFO:              mlflow: 2.13.0
2024-05-28 14:26:38,126:INFO:              gradio: Not installed
2024-05-28 14:26:38,127:INFO:             fastapi: Not installed
2024-05-28 14:26:38,128:INFO:             uvicorn: Not installed
2024-05-28 14:26:38,129:INFO:              m2cgen: Not installed
2024-05-28 14:26:38,129:INFO:           evidently: Not installed
2024-05-28 14:26:38,130:INFO:               fugue: Not installed
2024-05-28 14:26:38,133:INFO:           streamlit: 1.35.0
2024-05-28 14:26:38,134:INFO:             prophet: Not installed
2024-05-28 14:26:38,136:INFO:None
2024-05-28 14:26:38,137:INFO:Set up data.
2024-05-28 14:26:38,811:INFO:Set up folding strategy.
2024-05-28 14:26:38,817:INFO:Set up train/test split.
2024-05-28 14:26:39,407:INFO:Set up index.
2024-05-28 14:26:39,411:INFO:Assigning column types.
2024-05-28 14:26:40,045:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:26:43,556:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:26:43,566:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:44,163:INFO:PyCaret ClassificationExperiment
2024-05-28 14:26:44,183:INFO:Logging name: clf-default-name
2024-05-28 14:26:44,223:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:26:44,223:INFO:version 3.3.1
2024-05-28 14:26:44,223:INFO:Initializing setup()
2024-05-28 14:26:44,231:INFO:self.USI: 4b5c
2024-05-28 14:26:44,247:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:26:44,272:INFO:Checking environment
2024-05-28 14:26:44,272:INFO:python_version: 3.11.9
2024-05-28 14:26:44,272:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:26:44,273:INFO:machine: AMD64
2024-05-28 14:26:44,273:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:26:44,282:INFO:Memory: svmem(total=8469606400, available=1492877312, percent=82.4, used=6976729088, free=1492877312)
2024-05-28 14:26:44,282:INFO:Physical Core: 2
2024-05-28 14:26:44,282:INFO:Logical Core: 4
2024-05-28 14:26:44,283:INFO:Checking libraries
2024-05-28 14:26:44,283:INFO:System:
2024-05-28 14:26:44,283:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:26:44,284:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:26:44,284:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:26:44,284:INFO:PyCaret required dependencies:
2024-05-28 14:26:44,285:INFO:                 pip: 24.0
2024-05-28 14:26:44,285:INFO:          setuptools: 70.0.0
2024-05-28 14:26:44,285:INFO:             pycaret: 3.3.1
2024-05-28 14:26:44,286:INFO:             IPython: 8.24.0
2024-05-28 14:26:44,286:INFO:          ipywidgets: 8.1.2
2024-05-28 14:26:44,286:INFO:                tqdm: 4.66.4
2024-05-28 14:26:44,287:INFO:               numpy: 1.26.4
2024-05-28 14:26:44,287:INFO:              pandas: 2.1.4
2024-05-28 14:26:44,287:INFO:              jinja2: 3.1.4
2024-05-28 14:26:44,287:INFO:               scipy: 1.11.4
2024-05-28 14:26:44,288:INFO:              joblib: 1.3.2
2024-05-28 14:26:44,288:INFO:             sklearn: 1.4.2
2024-05-28 14:26:44,288:INFO:                pyod: 1.1.3
2024-05-28 14:26:44,288:INFO:            imblearn: 0.12.2
2024-05-28 14:26:44,289:INFO:   category_encoders: 2.6.3
2024-05-28 14:26:44,289:INFO:            lightgbm: 4.3.0
2024-05-28 14:26:44,289:INFO:               numba: 0.58.1
2024-05-28 14:26:44,310:INFO:            requests: 2.32.2
2024-05-28 14:26:44,339:INFO:          matplotlib: 3.7.5
2024-05-28 14:26:44,357:INFO:          scikitplot: 0.3.7
2024-05-28 14:26:44,388:INFO:         yellowbrick: 1.5
2024-05-28 14:26:44,389:INFO:              plotly: 5.22.0
2024-05-28 14:26:44,389:INFO:    plotly-resampler: Not installed
2024-05-28 14:26:44,390:INFO:             kaleido: 0.2.1
2024-05-28 14:26:44,390:INFO:           schemdraw: 0.15
2024-05-28 14:26:44,391:INFO:         statsmodels: 0.14.2
2024-05-28 14:26:44,391:INFO:              sktime: 0.26.0
2024-05-28 14:26:44,391:INFO:               tbats: 1.1.3
2024-05-28 14:26:44,391:INFO:            pmdarima: 2.0.4
2024-05-28 14:26:44,392:INFO:              psutil: 5.9.8
2024-05-28 14:26:44,392:INFO:          markupsafe: 2.1.5
2024-05-28 14:26:44,392:INFO:             pickle5: Not installed
2024-05-28 14:26:44,392:INFO:         cloudpickle: 3.0.0
2024-05-28 14:26:44,393:INFO:         deprecation: 2.1.0
2024-05-28 14:26:44,394:INFO:              xxhash: 3.4.1
2024-05-28 14:26:44,394:INFO:           wurlitzer: 3.1.0
2024-05-28 14:26:44,394:INFO:PyCaret optional dependencies:
2024-05-28 14:26:44,395:INFO:                shap: Not installed
2024-05-28 14:26:44,395:INFO:           interpret: Not installed
2024-05-28 14:26:44,395:INFO:                umap: 0.5.5
2024-05-28 14:26:44,395:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:26:44,396:INFO:  explainerdashboard: Not installed
2024-05-28 14:26:44,396:INFO:             autoviz: Not installed
2024-05-28 14:26:44,396:INFO:           fairlearn: Not installed
2024-05-28 14:26:44,396:INFO:          deepchecks: Not installed
2024-05-28 14:26:44,397:INFO:             xgboost: 2.0.3
2024-05-28 14:26:44,397:INFO:            catboost: 1.2.5
2024-05-28 14:26:44,397:INFO:              kmodes: 0.12.2
2024-05-28 14:26:44,397:INFO:             mlxtend: 0.23.1
2024-05-28 14:26:44,409:INFO:       statsforecast: Not installed
2024-05-28 14:26:44,409:INFO:        tune_sklearn: Not installed
2024-05-28 14:26:44,410:INFO:                 ray: Not installed
2024-05-28 14:26:44,410:INFO:            hyperopt: Not installed
2024-05-28 14:26:44,411:INFO:              optuna: Not installed
2024-05-28 14:26:44,411:INFO:               skopt: Not installed
2024-05-28 14:26:44,411:INFO:              mlflow: 2.13.0
2024-05-28 14:26:44,411:INFO:              gradio: Not installed
2024-05-28 14:26:44,412:INFO:             fastapi: Not installed
2024-05-28 14:26:44,412:INFO:             uvicorn: Not installed
2024-05-28 14:26:44,412:INFO:              m2cgen: Not installed
2024-05-28 14:26:44,412:INFO:           evidently: Not installed
2024-05-28 14:26:44,413:INFO:               fugue: Not installed
2024-05-28 14:26:44,413:INFO:           streamlit: 1.35.0
2024-05-28 14:26:44,413:INFO:             prophet: Not installed
2024-05-28 14:26:44,413:INFO:None
2024-05-28 14:26:44,414:INFO:Set up data.
2024-05-28 14:26:44,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:26:44,622:INFO:Set up folding strategy.
2024-05-28 14:26:44,624:INFO:Set up train/test split.
2024-05-28 14:26:44,638:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:44,791:INFO:Set up index.
2024-05-28 14:26:44,793:INFO:Assigning column types.
2024-05-28 14:26:44,831:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:26:45,300:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:45,400:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:45,402:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:26:46,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:46,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:26:46,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:46,767:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:46,840:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:47,171:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:47,204:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:47,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:47,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:26:47,911:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:48,016:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:48,063:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:48,097:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:26:48,381:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:48,411:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:48,520:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:26:49,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:49,212:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:49,234:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:49,493:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:49,534:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:49,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:26:49,876:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:49,889:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:49,956:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:49,956:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:49,956:INFO:Preparing preprocessing pipeline...
2024-05-28 14:26:49,956:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:26:49,956:INFO:Set up simple imputation.
2024-05-28 14:26:50,034:INFO:Set up encoding of ordinal features.
2024-05-28 14:26:50,090:INFO:Set up encoding of categorical features.
2024-05-28 14:26:50,091:INFO:Set up imbalanced handling.
2024-05-28 14:26:50,698:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:50,714:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:51,209:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:51,219:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:51,223:INFO:Preparing preprocessing pipeline...
2024-05-28 14:26:51,238:INFO:Set up simple imputation.
2024-05-28 14:26:51,254:INFO:Set up encoding of ordinal features.
2024-05-28 14:26:51,254:INFO:Set up encoding of categorical features.
2024-05-28 14:26:51,254:INFO:Set up imbalanced handling.
2024-05-28 14:26:51,950:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:26:52,076:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:26:52,076:INFO:Creating final display dataframe.
2024-05-28 14:26:52,446:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:26:52,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:26:52,485:INFO:Creating final display dataframe.
2024-05-28 14:26:54,905:INFO:Setup _display_container:                     Description             Value
0                    Session id              5399
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              7a3f
2024-05-28 14:26:55,063:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:55,063:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:55,172:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:55,188:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:55,204:INFO:setup() successfully completed in 17.98s...............
2024-05-28 14:26:55,654:INFO:Setup _display_container:                     Description             Value
0                    Session id              1729
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              4b5c
2024-05-28 14:26:55,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:55,780:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:55,889:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:26:55,889:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:26:55,889:INFO:setup() successfully completed in 12.56s...............
2024-05-28 14:26:55,905:INFO:Initializing compare_models()
2024-05-28 14:26:55,905:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:26:55,905:INFO:Checking exceptions
2024-05-28 14:26:55,905:INFO:Preparing display monitor
2024-05-28 14:26:55,905:INFO:Initializing Logistic Regression
2024-05-28 14:26:55,905:INFO:Total runtime is 0.0 minutes
2024-05-28 14:26:55,905:INFO:SubProcess create_model() called ==================================
2024-05-28 14:26:55,905:INFO:Initializing create_model()
2024-05-28 14:26:55,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:26:55,905:INFO:Checking exceptions
2024-05-28 14:26:55,905:INFO:Importing libraries
2024-05-28 14:26:55,905:INFO:Copying training dataset
2024-05-28 14:26:55,926:INFO:Defining folds
2024-05-28 14:26:55,926:INFO:Declaring metric variables
2024-05-28 14:26:55,927:INFO:Importing untrained model
2024-05-28 14:26:55,927:INFO:Logistic Regression Imported successfully
2024-05-28 14:26:55,928:INFO:Starting cross validation
2024-05-28 14:26:55,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:26:56,567:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:56,577:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:56,712:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:56,725:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:57,859:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:57,859:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:57,890:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:58,003:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:58,675:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:58,706:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:26:58,777:INFO:Calculating mean and std
2024-05-28 14:26:58,777:INFO:Creating metrics dataframe
2024-05-28 14:26:58,777:INFO:Uploading results into container
2024-05-28 14:26:58,777:INFO:Uploading model into container now
2024-05-28 14:26:58,777:INFO:_master_model_container: 1
2024-05-28 14:26:58,777:INFO:_display_container: 2
2024-05-28 14:26:58,777:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:26:58,777:INFO:create_model() successfully completed......................................
2024-05-28 14:26:58,971:INFO:SubProcess create_model() end ==================================
2024-05-28 14:26:58,971:INFO:Creating metrics dataframe
2024-05-28 14:26:58,971:INFO:Initializing K Neighbors Classifier
2024-05-28 14:26:58,971:INFO:Total runtime is 0.051107545693715416 minutes
2024-05-28 14:26:58,971:INFO:SubProcess create_model() called ==================================
2024-05-28 14:26:58,971:INFO:Initializing create_model()
2024-05-28 14:26:58,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:26:58,971:INFO:Checking exceptions
2024-05-28 14:26:58,971:INFO:Importing libraries
2024-05-28 14:26:58,971:INFO:Copying training dataset
2024-05-28 14:26:58,987:INFO:Defining folds
2024-05-28 14:26:58,987:INFO:Declaring metric variables
2024-05-28 14:26:58,987:INFO:Importing untrained model
2024-05-28 14:26:58,987:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:26:58,987:INFO:Starting cross validation
2024-05-28 14:26:58,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:26:59,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:26:59,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:26:59,580:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:26:59,590:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,035:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,069:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,150:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,154:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,368:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,375:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:00,406:INFO:Calculating mean and std
2024-05-28 14:27:00,406:INFO:Creating metrics dataframe
2024-05-28 14:27:00,406:INFO:Uploading results into container
2024-05-28 14:27:00,406:INFO:Uploading model into container now
2024-05-28 14:27:00,406:INFO:_master_model_container: 2
2024-05-28 14:27:00,406:INFO:_display_container: 2
2024-05-28 14:27:00,406:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:27:00,406:INFO:create_model() successfully completed......................................
2024-05-28 14:27:00,608:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:00,608:INFO:Creating metrics dataframe
2024-05-28 14:27:00,614:INFO:Initializing Naive Bayes
2024-05-28 14:27:00,614:INFO:Total runtime is 0.07847910722096761 minutes
2024-05-28 14:27:00,614:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:00,615:INFO:Initializing create_model()
2024-05-28 14:27:00,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:00,615:INFO:Checking exceptions
2024-05-28 14:27:00,615:INFO:Importing libraries
2024-05-28 14:27:00,615:INFO:Copying training dataset
2024-05-28 14:27:00,623:INFO:Defining folds
2024-05-28 14:27:00,623:INFO:Declaring metric variables
2024-05-28 14:27:00,624:INFO:Importing untrained model
2024-05-28 14:27:00,625:INFO:Naive Bayes Imported successfully
2024-05-28 14:27:00,625:INFO:Starting cross validation
2024-05-28 14:27:00,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:01,108:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,124:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,150:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,199:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,453:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,470:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,504:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,582:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,907:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,917:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:01,947:INFO:Calculating mean and std
2024-05-28 14:27:01,947:INFO:Creating metrics dataframe
2024-05-28 14:27:01,947:INFO:Uploading results into container
2024-05-28 14:27:01,947:INFO:Uploading model into container now
2024-05-28 14:27:01,947:INFO:_master_model_container: 3
2024-05-28 14:27:01,947:INFO:_display_container: 2
2024-05-28 14:27:01,947:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:27:01,947:INFO:create_model() successfully completed......................................
2024-05-28 14:27:02,142:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:02,157:INFO:Creating metrics dataframe
2024-05-28 14:27:02,157:INFO:Initializing Decision Tree Classifier
2024-05-28 14:27:02,157:INFO:Total runtime is 0.10421017408370972 minutes
2024-05-28 14:27:02,157:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:02,157:INFO:Initializing create_model()
2024-05-28 14:27:02,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:02,157:INFO:Checking exceptions
2024-05-28 14:27:02,157:INFO:Importing libraries
2024-05-28 14:27:02,157:INFO:Copying training dataset
2024-05-28 14:27:02,173:INFO:Defining folds
2024-05-28 14:27:02,173:INFO:Declaring metric variables
2024-05-28 14:27:02,173:INFO:Importing untrained model
2024-05-28 14:27:02,173:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:27:02,173:INFO:Starting cross validation
2024-05-28 14:27:02,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:02,651:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:02,661:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:02,671:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:02,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:02,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:02,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:02,704:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:02,717:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,212:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,245:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,269:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,285:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,503:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,505:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:03,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,519:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:03,540:INFO:Calculating mean and std
2024-05-28 14:27:03,540:INFO:Creating metrics dataframe
2024-05-28 14:27:03,546:INFO:Uploading results into container
2024-05-28 14:27:03,546:INFO:Uploading model into container now
2024-05-28 14:27:03,546:INFO:_master_model_container: 4
2024-05-28 14:27:03,546:INFO:_display_container: 2
2024-05-28 14:27:03,546:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1729, splitter='best')
2024-05-28 14:27:03,546:INFO:create_model() successfully completed......................................
2024-05-28 14:27:03,772:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:03,772:INFO:Creating metrics dataframe
2024-05-28 14:27:03,783:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:27:03,783:INFO:Total runtime is 0.13130993445714315 minutes
2024-05-28 14:27:03,783:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:03,784:INFO:Initializing create_model()
2024-05-28 14:27:03,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:03,784:INFO:Checking exceptions
2024-05-28 14:27:03,784:INFO:Importing libraries
2024-05-28 14:27:03,784:INFO:Copying training dataset
2024-05-28 14:27:03,787:INFO:Defining folds
2024-05-28 14:27:03,787:INFO:Declaring metric variables
2024-05-28 14:27:03,787:INFO:Importing untrained model
2024-05-28 14:27:03,796:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:27:03,797:INFO:Starting cross validation
2024-05-28 14:27:03,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:04,945:INFO:Calculating mean and std
2024-05-28 14:27:04,946:INFO:Creating metrics dataframe
2024-05-28 14:27:04,949:INFO:Uploading results into container
2024-05-28 14:27:04,950:INFO:Uploading model into container now
2024-05-28 14:27:04,950:INFO:_master_model_container: 5
2024-05-28 14:27:04,950:INFO:_display_container: 2
2024-05-28 14:27:04,951:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1729, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:27:04,951:INFO:create_model() successfully completed......................................
2024-05-28 14:27:05,138:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:05,138:INFO:Creating metrics dataframe
2024-05-28 14:27:05,138:INFO:Initializing Ridge Classifier
2024-05-28 14:27:05,138:INFO:Total runtime is 0.15389192501703897 minutes
2024-05-28 14:27:05,138:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:05,138:INFO:Initializing create_model()
2024-05-28 14:27:05,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:05,138:INFO:Checking exceptions
2024-05-28 14:27:05,138:INFO:Importing libraries
2024-05-28 14:27:05,138:INFO:Copying training dataset
2024-05-28 14:27:05,154:INFO:Defining folds
2024-05-28 14:27:05,154:INFO:Declaring metric variables
2024-05-28 14:27:05,154:INFO:Importing untrained model
2024-05-28 14:27:05,154:INFO:Ridge Classifier Imported successfully
2024-05-28 14:27:05,154:INFO:Starting cross validation
2024-05-28 14:27:05,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:06,047:INFO:Calculating mean and std
2024-05-28 14:27:06,047:INFO:Creating metrics dataframe
2024-05-28 14:27:06,047:INFO:Uploading results into container
2024-05-28 14:27:06,047:INFO:Uploading model into container now
2024-05-28 14:27:06,047:INFO:_master_model_container: 6
2024-05-28 14:27:06,047:INFO:_display_container: 2
2024-05-28 14:27:06,047:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1729, solver='auto',
                tol=0.0001)
2024-05-28 14:27:06,047:INFO:create_model() successfully completed......................................
2024-05-28 14:27:06,211:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:06,211:INFO:Creating metrics dataframe
2024-05-28 14:27:06,226:INFO:Initializing Random Forest Classifier
2024-05-28 14:27:06,226:INFO:Total runtime is 0.17202624877293904 minutes
2024-05-28 14:27:06,226:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:06,226:INFO:Initializing create_model()
2024-05-28 14:27:06,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:06,226:INFO:Checking exceptions
2024-05-28 14:27:06,226:INFO:Importing libraries
2024-05-28 14:27:06,226:INFO:Copying training dataset
2024-05-28 14:27:06,226:INFO:Defining folds
2024-05-28 14:27:06,226:INFO:Declaring metric variables
2024-05-28 14:27:06,226:INFO:Importing untrained model
2024-05-28 14:27:06,226:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:27:06,226:INFO:Starting cross validation
2024-05-28 14:27:06,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:06,908:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:06,913:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:06,919:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:06,920:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:06,923:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:07,521:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:07,532:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:08,177:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:08,180:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:08,195:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:08,198:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:08,231:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:08,250:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:08,799:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:08,830:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,034:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:09,041:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,053:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:09,061:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,074:INFO:Calculating mean and std
2024-05-28 14:27:09,075:INFO:Creating metrics dataframe
2024-05-28 14:27:09,078:INFO:Uploading results into container
2024-05-28 14:27:09,078:INFO:Uploading model into container now
2024-05-28 14:27:09,079:INFO:_master_model_container: 7
2024-05-28 14:27:09,079:INFO:_display_container: 2
2024-05-28 14:27:09,080:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1729, verbose=0,
                       warm_start=False)
2024-05-28 14:27:09,080:INFO:create_model() successfully completed......................................
2024-05-28 14:27:09,299:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:09,299:INFO:Creating metrics dataframe
2024-05-28 14:27:09,303:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:27:09,303:INFO:Total runtime is 0.22329620917638143 minutes
2024-05-28 14:27:09,303:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:09,303:INFO:Initializing create_model()
2024-05-28 14:27:09,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:09,304:INFO:Checking exceptions
2024-05-28 14:27:09,304:INFO:Importing libraries
2024-05-28 14:27:09,304:INFO:Copying training dataset
2024-05-28 14:27:09,311:INFO:Defining folds
2024-05-28 14:27:09,311:INFO:Declaring metric variables
2024-05-28 14:27:09,312:INFO:Importing untrained model
2024-05-28 14:27:09,312:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:27:09,312:INFO:Starting cross validation
2024-05-28 14:27:09,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:09,585:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:09,596:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:09,614:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:09,640:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:09,703:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,713:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,731:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:09,957:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:09,992:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:10,004:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:10,008:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:10,098:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:10,244:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:10,257:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:27:10,302:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:10,323:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:10,356:INFO:Calculating mean and std
2024-05-28 14:27:10,356:INFO:Creating metrics dataframe
2024-05-28 14:27:10,356:INFO:Uploading results into container
2024-05-28 14:27:10,356:INFO:Uploading model into container now
2024-05-28 14:27:10,356:INFO:_master_model_container: 8
2024-05-28 14:27:10,356:INFO:_display_container: 2
2024-05-28 14:27:10,356:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:27:10,356:INFO:create_model() successfully completed......................................
2024-05-28 14:27:10,601:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:10,602:INFO:Creating metrics dataframe
2024-05-28 14:27:10,607:INFO:Initializing Ada Boost Classifier
2024-05-28 14:27:10,607:INFO:Total runtime is 0.24503392775853475 minutes
2024-05-28 14:27:10,608:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:10,608:INFO:Initializing create_model()
2024-05-28 14:27:10,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:10,608:INFO:Checking exceptions
2024-05-28 14:27:10,608:INFO:Importing libraries
2024-05-28 14:27:10,608:INFO:Copying training dataset
2024-05-28 14:27:10,608:INFO:Defining folds
2024-05-28 14:27:10,608:INFO:Declaring metric variables
2024-05-28 14:27:10,608:INFO:Importing untrained model
2024-05-28 14:27:10,608:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:27:10,608:INFO:Starting cross validation
2024-05-28 14:27:10,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:10,874:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:10,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:10,885:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:10,906:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:10,980:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:10,980:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:10,990:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,017:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,197:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,214:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,221:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,258:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,292:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,306:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,321:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,352:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,488:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,492:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:27:11,565:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,576:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:11,606:INFO:Calculating mean and std
2024-05-28 14:27:11,607:INFO:Creating metrics dataframe
2024-05-28 14:27:11,611:INFO:Uploading results into container
2024-05-28 14:27:11,612:INFO:Uploading model into container now
2024-05-28 14:27:11,613:INFO:_master_model_container: 9
2024-05-28 14:27:11,613:INFO:_display_container: 2
2024-05-28 14:27:11,614:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1729)
2024-05-28 14:27:11,614:INFO:create_model() successfully completed......................................
2024-05-28 14:27:11,822:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:11,823:INFO:Creating metrics dataframe
2024-05-28 14:27:11,823:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:27:11,823:INFO:Total runtime is 0.26529413064320884 minutes
2024-05-28 14:27:11,823:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:11,823:INFO:Initializing create_model()
2024-05-28 14:27:11,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:11,823:INFO:Checking exceptions
2024-05-28 14:27:11,823:INFO:Importing libraries
2024-05-28 14:27:11,823:INFO:Copying training dataset
2024-05-28 14:27:11,823:INFO:Defining folds
2024-05-28 14:27:11,823:INFO:Declaring metric variables
2024-05-28 14:27:11,823:INFO:Importing untrained model
2024-05-28 14:27:11,823:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:27:11,823:INFO:Starting cross validation
2024-05-28 14:27:11,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:12,434:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:12,455:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:12,476:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:12,481:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:12,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:12,994:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:13,016:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:13,048:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:13,461:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:13,468:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:13,478:INFO:Calculating mean and std
2024-05-28 14:27:13,479:INFO:Creating metrics dataframe
2024-05-28 14:27:13,481:INFO:Uploading results into container
2024-05-28 14:27:13,482:INFO:Uploading model into container now
2024-05-28 14:27:13,483:INFO:_master_model_container: 10
2024-05-28 14:27:13,483:INFO:_display_container: 2
2024-05-28 14:27:13,484:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1729, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:27:13,484:INFO:create_model() successfully completed......................................
2024-05-28 14:27:13,675:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:13,675:INFO:Creating metrics dataframe
2024-05-28 14:27:13,678:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:27:13,679:INFO:Total runtime is 0.29621841510136926 minutes
2024-05-28 14:27:13,679:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:13,679:INFO:Initializing create_model()
2024-05-28 14:27:13,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:13,679:INFO:Checking exceptions
2024-05-28 14:27:13,679:INFO:Importing libraries
2024-05-28 14:27:13,679:INFO:Copying training dataset
2024-05-28 14:27:13,686:INFO:Defining folds
2024-05-28 14:27:13,686:INFO:Declaring metric variables
2024-05-28 14:27:13,687:INFO:Importing untrained model
2024-05-28 14:27:13,687:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:27:13,687:INFO:Starting cross validation
2024-05-28 14:27:13,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:14,018:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,021:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,060:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,378:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,388:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,412:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,414:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,659:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,682:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:14,694:INFO:Calculating mean and std
2024-05-28 14:27:14,694:INFO:Creating metrics dataframe
2024-05-28 14:27:14,694:INFO:Uploading results into container
2024-05-28 14:27:14,694:INFO:Uploading model into container now
2024-05-28 14:27:14,694:INFO:_master_model_container: 11
2024-05-28 14:27:14,694:INFO:_display_container: 2
2024-05-28 14:27:14,694:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:27:14,694:INFO:create_model() successfully completed......................................
2024-05-28 14:27:14,885:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:14,885:INFO:Creating metrics dataframe
2024-05-28 14:27:14,885:INFO:Initializing Extra Trees Classifier
2024-05-28 14:27:14,885:INFO:Total runtime is 0.3163433909416199 minutes
2024-05-28 14:27:14,885:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:14,885:INFO:Initializing create_model()
2024-05-28 14:27:14,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:14,885:INFO:Checking exceptions
2024-05-28 14:27:14,885:INFO:Importing libraries
2024-05-28 14:27:14,885:INFO:Copying training dataset
2024-05-28 14:27:14,885:INFO:Defining folds
2024-05-28 14:27:14,885:INFO:Declaring metric variables
2024-05-28 14:27:14,885:INFO:Importing untrained model
2024-05-28 14:27:14,885:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:27:14,885:INFO:Starting cross validation
2024-05-28 14:27:14,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:15,603:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:15,609:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:15,770:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:15,815:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:16,443:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:16,618:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:16,721:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:16,749:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:17,251:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:17,337:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:17,368:INFO:Calculating mean and std
2024-05-28 14:27:17,368:INFO:Creating metrics dataframe
2024-05-28 14:27:17,368:INFO:Uploading results into container
2024-05-28 14:27:17,368:INFO:Uploading model into container now
2024-05-28 14:27:17,368:INFO:_master_model_container: 12
2024-05-28 14:27:17,368:INFO:_display_container: 2
2024-05-28 14:27:17,368:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1729, verbose=0,
                     warm_start=False)
2024-05-28 14:27:17,368:INFO:create_model() successfully completed......................................
2024-05-28 14:27:17,588:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:17,588:INFO:Creating metrics dataframe
2024-05-28 14:27:17,591:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:27:17,592:INFO:Total runtime is 0.3614482839902242 minutes
2024-05-28 14:27:17,592:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:17,592:INFO:Initializing create_model()
2024-05-28 14:27:17,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:17,592:INFO:Checking exceptions
2024-05-28 14:27:17,592:INFO:Importing libraries
2024-05-28 14:27:17,592:INFO:Copying training dataset
2024-05-28 14:27:17,598:INFO:Defining folds
2024-05-28 14:27:17,599:INFO:Declaring metric variables
2024-05-28 14:27:17,599:INFO:Importing untrained model
2024-05-28 14:27:17,601:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:27:17,601:INFO:Starting cross validation
2024-05-28 14:27:17,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:18,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,046:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,062:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,400:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,400:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,416:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,418:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,420:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,698:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:18,710:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,710:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:18,732:INFO:Calculating mean and std
2024-05-28 14:27:18,733:INFO:Creating metrics dataframe
2024-05-28 14:27:18,736:INFO:Uploading results into container
2024-05-28 14:27:18,737:INFO:Uploading model into container now
2024-05-28 14:27:18,738:INFO:_master_model_container: 13
2024-05-28 14:27:18,738:INFO:_display_container: 2
2024-05-28 14:27:18,740:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:27:18,740:INFO:create_model() successfully completed......................................
2024-05-28 14:27:18,932:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:18,932:INFO:Creating metrics dataframe
2024-05-28 14:27:18,932:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:27:18,948:INFO:Total runtime is 0.38404664993286136 minutes
2024-05-28 14:27:18,948:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:18,948:INFO:Initializing create_model()
2024-05-28 14:27:18,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:18,949:INFO:Checking exceptions
2024-05-28 14:27:18,949:INFO:Importing libraries
2024-05-28 14:27:18,949:INFO:Copying training dataset
2024-05-28 14:27:18,954:INFO:Defining folds
2024-05-28 14:27:18,954:INFO:Declaring metric variables
2024-05-28 14:27:18,955:INFO:Importing untrained model
2024-05-28 14:27:18,955:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:27:18,956:INFO:Starting cross validation
2024-05-28 14:27:18,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:19,466:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:19,466:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:19,466:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:19,476:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:19,483:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:19,484:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:19,493:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:19,504:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,158:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,165:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,168:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,168:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,232:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,347:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,357:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,626:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,638:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,641:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:20,648:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:20,668:INFO:Calculating mean and std
2024-05-28 14:27:20,668:INFO:Creating metrics dataframe
2024-05-28 14:27:20,668:INFO:Uploading results into container
2024-05-28 14:27:20,668:INFO:Uploading model into container now
2024-05-28 14:27:20,668:INFO:_master_model_container: 14
2024-05-28 14:27:20,668:INFO:_display_container: 2
2024-05-28 14:27:20,668:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1729, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:27:20,668:INFO:create_model() successfully completed......................................
2024-05-28 14:27:20,865:INFO:SubProcess create_model() end ==================================
2024-05-28 14:27:20,865:INFO:Creating metrics dataframe
2024-05-28 14:27:20,865:INFO:Initializing CatBoost Classifier
2024-05-28 14:27:20,865:INFO:Total runtime is 0.4160014311472575 minutes
2024-05-28 14:27:20,865:INFO:SubProcess create_model() called ==================================
2024-05-28 14:27:20,865:INFO:Initializing create_model()
2024-05-28 14:27:20,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:27:20,865:INFO:Checking exceptions
2024-05-28 14:27:20,865:INFO:Importing libraries
2024-05-28 14:27:20,865:INFO:Copying training dataset
2024-05-28 14:27:20,865:INFO:Defining folds
2024-05-28 14:27:20,865:INFO:Declaring metric variables
2024-05-28 14:27:20,865:INFO:Importing untrained model
2024-05-28 14:27:20,865:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:27:20,865:INFO:Starting cross validation
2024-05-28 14:27:20,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:27:29,787:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:29,808:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:29,864:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:29,880:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:30,088:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:30,101:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:30,349:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:30,414:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:38,973:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:38,978:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:38,983:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:38,989:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:39,350:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:39,377:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:27:39,569:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:27:39,584:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:11,883:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:11,891:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:12,041:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:12,064:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:12,092:INFO:Calculating mean and std
2024-05-28 14:28:12,095:INFO:Creating metrics dataframe
2024-05-28 14:28:12,103:INFO:Uploading results into container
2024-05-28 14:28:12,107:INFO:Uploading model into container now
2024-05-28 14:28:12,109:INFO:_master_model_container: 15
2024-05-28 14:28:12,109:INFO:_display_container: 2
2024-05-28 14:28:12,109:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCA235D10>
2024-05-28 14:28:12,110:INFO:create_model() successfully completed......................................
2024-05-28 14:28:12,481:INFO:SubProcess create_model() end ==================================
2024-05-28 14:28:12,482:INFO:Creating metrics dataframe
2024-05-28 14:28:12,495:INFO:Initializing Dummy Classifier
2024-05-28 14:28:12,496:INFO:Total runtime is 1.2765237291653952 minutes
2024-05-28 14:28:12,496:INFO:SubProcess create_model() called ==================================
2024-05-28 14:28:12,497:INFO:Initializing create_model()
2024-05-28 14:28:12,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBAE6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:28:12,499:INFO:Checking exceptions
2024-05-28 14:28:12,499:INFO:Importing libraries
2024-05-28 14:28:12,499:INFO:Copying training dataset
2024-05-28 14:28:12,512:INFO:Defining folds
2024-05-28 14:28:12,513:INFO:Declaring metric variables
2024-05-28 14:28:12,515:INFO:Importing untrained model
2024-05-28 14:28:12,516:INFO:Dummy Classifier Imported successfully
2024-05-28 14:28:12,516:INFO:Starting cross validation
2024-05-28 14:28:12,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:28:13,313:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:13,321:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:13,330:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:13,334:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:13,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:13,409:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:13,409:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:13,469:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:14,299:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:14,328:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:14,372:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:14,372:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:14,394:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:14,408:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:14,413:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:14,448:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:15,010:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:15,030:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:15,044:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:28:15,065:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:28:15,111:INFO:Calculating mean and std
2024-05-28 14:28:15,116:INFO:Creating metrics dataframe
2024-05-28 14:28:15,127:INFO:Uploading results into container
2024-05-28 14:28:15,128:INFO:Uploading model into container now
2024-05-28 14:28:15,130:INFO:_master_model_container: 16
2024-05-28 14:28:15,130:INFO:_display_container: 2
2024-05-28 14:28:15,130:INFO:DummyClassifier(constant=None, random_state=1729, strategy='prior')
2024-05-28 14:28:15,131:INFO:create_model() successfully completed......................................
2024-05-28 14:28:15,492:INFO:SubProcess create_model() end ==================================
2024-05-28 14:28:15,492:INFO:Creating metrics dataframe
2024-05-28 14:28:15,501:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:28:15,506:INFO:Initializing create_model()
2024-05-28 14:28:15,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:28:15,507:INFO:Checking exceptions
2024-05-28 14:28:15,508:INFO:Importing libraries
2024-05-28 14:28:15,508:INFO:Copying training dataset
2024-05-28 14:28:15,519:INFO:Defining folds
2024-05-28 14:28:15,520:INFO:Declaring metric variables
2024-05-28 14:28:15,521:INFO:Importing untrained model
2024-05-28 14:28:15,521:INFO:Declaring custom model
2024-05-28 14:28:15,523:INFO:Logistic Regression Imported successfully
2024-05-28 14:28:15,527:INFO:Cross validation set to False
2024-05-28 14:28:15,527:INFO:Fitting Model
2024-05-28 14:28:16,313:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:28:16,315:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:28:16,315:INFO:create_model() successfully completed......................................
2024-05-28 14:28:16,668:INFO:_master_model_container: 16
2024-05-28 14:28:16,669:INFO:_display_container: 2
2024-05-28 14:28:16,670:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:28:16,670:INFO:compare_models() successfully completed......................................
2024-05-28 14:28:16,832:INFO:Initializing save_model()
2024-05-28 14:28:16,832:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:28:16,832:INFO:Adding model into prep_pipe
2024-05-28 14:28:16,879:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:28:17,049:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1729,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:28:17,049:INFO:save_model() successfully completed......................................
2024-05-28 14:28:17,326:INFO:Initializing plot_model()
2024-05-28 14:28:17,327:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-28 14:28:17,327:INFO:Checking exceptions
2024-05-28 14:28:17,331:INFO:Preloading libraries
2024-05-28 14:28:17,331:INFO:Copying training dataset
2024-05-28 14:28:17,331:INFO:Plot type: auc
2024-05-28 14:28:17,996:INFO:Fitting Model
2024-05-28 14:28:18,003:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-05-28 14:28:18,004:INFO:Scoring test/hold-out set
2024-05-28 14:28:18,098:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-05-28 14:28:18,174:INFO:Visual Rendered Successfully
2024-05-28 14:28:18,389:INFO:plot_model() successfully completed......................................
2024-05-28 14:28:18,390:INFO:Initializing plot_model()
2024-05-28 14:28:18,390:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-28 14:28:18,390:INFO:Checking exceptions
2024-05-28 14:28:18,393:INFO:Preloading libraries
2024-05-28 14:28:18,394:INFO:Copying training dataset
2024-05-28 14:28:18,394:INFO:Plot type: confusion_matrix
2024-05-28 14:28:18,616:INFO:Fitting Model
2024-05-28 14:28:18,617:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-05-28 14:28:18,618:INFO:Scoring test/hold-out set
2024-05-28 14:28:18,686:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-05-28 14:28:18,722:INFO:Visual Rendered Successfully
2024-05-28 14:28:18,939:INFO:plot_model() successfully completed......................................
2024-05-28 14:28:18,940:INFO:Initializing plot_model()
2024-05-28 14:28:18,940:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA235A50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-28 14:28:18,941:INFO:Checking exceptions
2024-05-28 14:28:18,945:INFO:Preloading libraries
2024-05-28 14:28:18,945:INFO:Copying training dataset
2024-05-28 14:28:18,946:INFO:Plot type: feature
2024-05-28 14:28:19,133:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-05-28 14:28:19,133:INFO:Visual Rendered Successfully
2024-05-28 14:28:19,386:INFO:plot_model() successfully completed......................................
2024-05-28 14:30:18,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:30:18,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:30:18,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:30:18,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:30:29,809:INFO:PyCaret ClassificationExperiment
2024-05-28 14:30:29,809:INFO:Logging name: clf-default-name
2024-05-28 14:30:29,809:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:30:29,809:INFO:version 3.3.1
2024-05-28 14:30:29,809:INFO:Initializing setup()
2024-05-28 14:30:29,809:INFO:self.USI: c192
2024-05-28 14:30:29,809:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:30:29,809:INFO:Checking environment
2024-05-28 14:30:29,809:INFO:python_version: 3.11.9
2024-05-28 14:30:29,809:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:30:29,809:INFO:machine: AMD64
2024-05-28 14:30:29,809:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:30:29,809:INFO:Memory: svmem(total=8469606400, available=1560948736, percent=81.6, used=6908657664, free=1560948736)
2024-05-28 14:30:29,809:INFO:Physical Core: 2
2024-05-28 14:30:29,809:INFO:Logical Core: 4
2024-05-28 14:30:29,809:INFO:Checking libraries
2024-05-28 14:30:29,825:INFO:System:
2024-05-28 14:30:29,826:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:30:29,826:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:30:29,826:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:30:29,826:INFO:PyCaret required dependencies:
2024-05-28 14:30:29,827:INFO:                 pip: 24.0
2024-05-28 14:30:29,827:INFO:          setuptools: 70.0.0
2024-05-28 14:30:29,827:INFO:             pycaret: 3.3.1
2024-05-28 14:30:29,827:INFO:             IPython: 8.24.0
2024-05-28 14:30:29,827:INFO:          ipywidgets: 8.1.2
2024-05-28 14:30:29,827:INFO:                tqdm: 4.66.4
2024-05-28 14:30:29,827:INFO:               numpy: 1.26.4
2024-05-28 14:30:29,828:INFO:              pandas: 2.1.4
2024-05-28 14:30:29,828:INFO:              jinja2: 3.1.4
2024-05-28 14:30:29,828:INFO:               scipy: 1.11.4
2024-05-28 14:30:29,828:INFO:              joblib: 1.3.2
2024-05-28 14:30:29,828:INFO:             sklearn: 1.4.2
2024-05-28 14:30:29,828:INFO:                pyod: 1.1.3
2024-05-28 14:30:29,828:INFO:            imblearn: 0.12.2
2024-05-28 14:30:29,829:INFO:   category_encoders: 2.6.3
2024-05-28 14:30:29,829:INFO:            lightgbm: 4.3.0
2024-05-28 14:30:29,829:INFO:               numba: 0.58.1
2024-05-28 14:30:29,829:INFO:            requests: 2.32.2
2024-05-28 14:30:29,829:INFO:          matplotlib: 3.7.5
2024-05-28 14:30:29,829:INFO:          scikitplot: 0.3.7
2024-05-28 14:30:29,829:INFO:         yellowbrick: 1.5
2024-05-28 14:30:29,829:INFO:              plotly: 5.22.0
2024-05-28 14:30:29,830:INFO:    plotly-resampler: Not installed
2024-05-28 14:30:29,830:INFO:             kaleido: 0.2.1
2024-05-28 14:30:29,830:INFO:           schemdraw: 0.15
2024-05-28 14:30:29,830:INFO:         statsmodels: 0.14.2
2024-05-28 14:30:29,830:INFO:              sktime: 0.26.0
2024-05-28 14:30:29,830:INFO:               tbats: 1.1.3
2024-05-28 14:30:29,830:INFO:            pmdarima: 2.0.4
2024-05-28 14:30:29,830:INFO:              psutil: 5.9.8
2024-05-28 14:30:29,831:INFO:          markupsafe: 2.1.5
2024-05-28 14:30:29,831:INFO:             pickle5: Not installed
2024-05-28 14:30:29,831:INFO:         cloudpickle: 3.0.0
2024-05-28 14:30:29,831:INFO:         deprecation: 2.1.0
2024-05-28 14:30:29,831:INFO:              xxhash: 3.4.1
2024-05-28 14:30:29,831:INFO:           wurlitzer: 3.1.0
2024-05-28 14:30:29,831:INFO:PyCaret optional dependencies:
2024-05-28 14:30:29,832:INFO:                shap: Not installed
2024-05-28 14:30:29,832:INFO:           interpret: Not installed
2024-05-28 14:30:29,832:INFO:                umap: 0.5.5
2024-05-28 14:30:29,834:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:30:29,834:INFO:  explainerdashboard: Not installed
2024-05-28 14:30:29,834:INFO:             autoviz: Not installed
2024-05-28 14:30:29,834:INFO:           fairlearn: Not installed
2024-05-28 14:30:29,834:INFO:          deepchecks: Not installed
2024-05-28 14:30:29,834:INFO:             xgboost: 2.0.3
2024-05-28 14:30:29,834:INFO:            catboost: 1.2.5
2024-05-28 14:30:29,835:INFO:              kmodes: 0.12.2
2024-05-28 14:30:29,835:INFO:             mlxtend: 0.23.1
2024-05-28 14:30:29,835:INFO:       statsforecast: Not installed
2024-05-28 14:30:29,835:INFO:        tune_sklearn: Not installed
2024-05-28 14:30:29,835:INFO:                 ray: Not installed
2024-05-28 14:30:29,835:INFO:            hyperopt: Not installed
2024-05-28 14:30:29,835:INFO:              optuna: Not installed
2024-05-28 14:30:29,835:INFO:               skopt: Not installed
2024-05-28 14:30:29,835:INFO:              mlflow: 2.13.0
2024-05-28 14:30:29,836:INFO:              gradio: Not installed
2024-05-28 14:30:29,836:INFO:             fastapi: Not installed
2024-05-28 14:30:29,836:INFO:             uvicorn: Not installed
2024-05-28 14:30:29,836:INFO:              m2cgen: Not installed
2024-05-28 14:30:29,836:INFO:           evidently: Not installed
2024-05-28 14:30:29,836:INFO:               fugue: Not installed
2024-05-28 14:30:29,836:INFO:           streamlit: 1.35.0
2024-05-28 14:30:29,836:INFO:             prophet: Not installed
2024-05-28 14:30:29,836:INFO:None
2024-05-28 14:30:29,836:INFO:Set up data.
2024-05-28 14:30:29,858:INFO:Set up folding strategy.
2024-05-28 14:30:29,858:INFO:Set up train/test split.
2024-05-28 14:30:29,879:INFO:Set up index.
2024-05-28 14:30:29,879:INFO:Assigning column types.
2024-05-28 14:30:29,889:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:30:30,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,005:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,057:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,062:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,125:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,161:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,165:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,166:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:30:30,208:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,260:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,263:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:30:30,352:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,355:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,357:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:30:30,450:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,453:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,559:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:30,559:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:30,559:INFO:Preparing preprocessing pipeline...
2024-05-28 14:30:30,559:INFO:Set up simple imputation.
2024-05-28 14:30:30,581:INFO:Set up encoding of ordinal features.
2024-05-28 14:30:30,583:INFO:Set up encoding of categorical features.
2024-05-28 14:30:30,583:INFO:Set up imbalanced handling.
2024-05-28 14:30:30,808:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:30:30,865:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:30:30,865:INFO:Creating final display dataframe.
2024-05-28 14:30:31,744:INFO:Setup _display_container:                     Description             Value
0                    Session id              2065
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              c192
2024-05-28 14:30:31,865:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:31,871:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:31,974:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:30:31,977:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:30:31,979:INFO:setup() successfully completed in 2.19s...............
2024-05-28 14:30:31,985:INFO:Initializing compare_models()
2024-05-28 14:30:31,985:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:30:31,985:INFO:Checking exceptions
2024-05-28 14:30:31,993:INFO:Preparing display monitor
2024-05-28 14:30:31,997:INFO:Initializing Logistic Regression
2024-05-28 14:30:31,997:INFO:Total runtime is 0.0 minutes
2024-05-28 14:30:31,998:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:31,998:INFO:Initializing create_model()
2024-05-28 14:30:31,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:31,998:INFO:Checking exceptions
2024-05-28 14:30:31,999:INFO:Importing libraries
2024-05-28 14:30:31,999:INFO:Copying training dataset
2024-05-28 14:30:32,011:INFO:Defining folds
2024-05-28 14:30:32,011:INFO:Declaring metric variables
2024-05-28 14:30:32,011:INFO:Importing untrained model
2024-05-28 14:30:32,012:INFO:Logistic Regression Imported successfully
2024-05-28 14:30:32,013:INFO:Starting cross validation
2024-05-28 14:30:32,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:32,660:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:32,667:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:32,707:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:32,716:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,291:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,311:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,365:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,840:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,869:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:30:33,961:INFO:Calculating mean and std
2024-05-28 14:30:33,962:INFO:Creating metrics dataframe
2024-05-28 14:30:33,966:INFO:Uploading results into container
2024-05-28 14:30:33,966:INFO:Uploading model into container now
2024-05-28 14:30:33,967:INFO:_master_model_container: 1
2024-05-28 14:30:33,967:INFO:_display_container: 2
2024-05-28 14:30:33,968:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2065, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:30:33,968:INFO:create_model() successfully completed......................................
2024-05-28 14:30:34,161:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:34,161:INFO:Creating metrics dataframe
2024-05-28 14:30:34,164:INFO:Initializing K Neighbors Classifier
2024-05-28 14:30:34,164:INFO:Total runtime is 0.03611449797948201 minutes
2024-05-28 14:30:34,164:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:34,165:INFO:Initializing create_model()
2024-05-28 14:30:34,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:34,165:INFO:Checking exceptions
2024-05-28 14:30:34,165:INFO:Importing libraries
2024-05-28 14:30:34,165:INFO:Copying training dataset
2024-05-28 14:30:34,170:INFO:Defining folds
2024-05-28 14:30:34,170:INFO:Declaring metric variables
2024-05-28 14:30:34,172:INFO:Importing untrained model
2024-05-28 14:30:34,172:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:30:34,172:INFO:Starting cross validation
2024-05-28 14:30:34,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:34,511:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,511:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,511:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,891:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,963:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,968:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:34,972:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,239:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,288:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,288:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,318:INFO:Calculating mean and std
2024-05-28 14:30:35,318:INFO:Creating metrics dataframe
2024-05-28 14:30:35,322:INFO:Uploading results into container
2024-05-28 14:30:35,322:INFO:Uploading model into container now
2024-05-28 14:30:35,322:INFO:_master_model_container: 2
2024-05-28 14:30:35,322:INFO:_display_container: 2
2024-05-28 14:30:35,322:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:30:35,322:INFO:create_model() successfully completed......................................
2024-05-28 14:30:35,488:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:35,488:INFO:Creating metrics dataframe
2024-05-28 14:30:35,488:INFO:Initializing Naive Bayes
2024-05-28 14:30:35,488:INFO:Total runtime is 0.0581820011138916 minutes
2024-05-28 14:30:35,488:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:35,488:INFO:Initializing create_model()
2024-05-28 14:30:35,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:35,488:INFO:Checking exceptions
2024-05-28 14:30:35,488:INFO:Importing libraries
2024-05-28 14:30:35,488:INFO:Copying training dataset
2024-05-28 14:30:35,506:INFO:Defining folds
2024-05-28 14:30:35,506:INFO:Declaring metric variables
2024-05-28 14:30:35,506:INFO:Importing untrained model
2024-05-28 14:30:35,506:INFO:Naive Bayes Imported successfully
2024-05-28 14:30:35,506:INFO:Starting cross validation
2024-05-28 14:30:35,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:35,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,851:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,858:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:35,886:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,106:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,145:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,149:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,157:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,393:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,421:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,442:INFO:Calculating mean and std
2024-05-28 14:30:36,443:INFO:Creating metrics dataframe
2024-05-28 14:30:36,445:INFO:Uploading results into container
2024-05-28 14:30:36,446:INFO:Uploading model into container now
2024-05-28 14:30:36,446:INFO:_master_model_container: 3
2024-05-28 14:30:36,446:INFO:_display_container: 2
2024-05-28 14:30:36,447:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:30:36,447:INFO:create_model() successfully completed......................................
2024-05-28 14:30:36,604:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:36,604:INFO:Creating metrics dataframe
2024-05-28 14:30:36,604:INFO:Initializing Decision Tree Classifier
2024-05-28 14:30:36,604:INFO:Total runtime is 0.0767746647198995 minutes
2024-05-28 14:30:36,604:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:36,604:INFO:Initializing create_model()
2024-05-28 14:30:36,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:36,604:INFO:Checking exceptions
2024-05-28 14:30:36,604:INFO:Importing libraries
2024-05-28 14:30:36,604:INFO:Copying training dataset
2024-05-28 14:30:36,623:INFO:Defining folds
2024-05-28 14:30:36,623:INFO:Declaring metric variables
2024-05-28 14:30:36,623:INFO:Importing untrained model
2024-05-28 14:30:36,624:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:30:36,624:INFO:Starting cross validation
2024-05-28 14:30:36,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:36,946:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,971:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,971:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:36,975:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:36,979:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,011:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,022:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,337:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,346:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,381:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,395:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,398:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,582:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,592:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,592:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:37,600:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:37,613:INFO:Calculating mean and std
2024-05-28 14:30:37,613:INFO:Creating metrics dataframe
2024-05-28 14:30:37,613:INFO:Uploading results into container
2024-05-28 14:30:37,613:INFO:Uploading model into container now
2024-05-28 14:30:37,613:INFO:_master_model_container: 4
2024-05-28 14:30:37,613:INFO:_display_container: 2
2024-05-28 14:30:37,613:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2065, splitter='best')
2024-05-28 14:30:37,613:INFO:create_model() successfully completed......................................
2024-05-28 14:30:37,795:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:37,795:INFO:Creating metrics dataframe
2024-05-28 14:30:37,799:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:30:37,799:INFO:Total runtime is 0.09669805367787679 minutes
2024-05-28 14:30:37,799:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:37,799:INFO:Initializing create_model()
2024-05-28 14:30:37,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:37,800:INFO:Checking exceptions
2024-05-28 14:30:37,800:INFO:Importing libraries
2024-05-28 14:30:37,800:INFO:Copying training dataset
2024-05-28 14:30:37,803:INFO:Defining folds
2024-05-28 14:30:37,803:INFO:Declaring metric variables
2024-05-28 14:30:37,803:INFO:Importing untrained model
2024-05-28 14:30:37,803:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:30:37,803:INFO:Starting cross validation
2024-05-28 14:30:37,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:38,821:INFO:Calculating mean and std
2024-05-28 14:30:38,823:INFO:Creating metrics dataframe
2024-05-28 14:30:38,825:INFO:Uploading results into container
2024-05-28 14:30:38,826:INFO:Uploading model into container now
2024-05-28 14:30:38,827:INFO:_master_model_container: 5
2024-05-28 14:30:38,827:INFO:_display_container: 2
2024-05-28 14:30:38,827:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2065, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:30:38,827:INFO:create_model() successfully completed......................................
2024-05-28 14:30:39,036:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:39,036:INFO:Creating metrics dataframe
2024-05-28 14:30:39,040:INFO:Initializing Ridge Classifier
2024-05-28 14:30:39,041:INFO:Total runtime is 0.11737151145935058 minutes
2024-05-28 14:30:39,041:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:39,041:INFO:Initializing create_model()
2024-05-28 14:30:39,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:39,041:INFO:Checking exceptions
2024-05-28 14:30:39,042:INFO:Importing libraries
2024-05-28 14:30:39,042:INFO:Copying training dataset
2024-05-28 14:30:39,047:INFO:Defining folds
2024-05-28 14:30:39,047:INFO:Declaring metric variables
2024-05-28 14:30:39,047:INFO:Importing untrained model
2024-05-28 14:30:39,048:INFO:Ridge Classifier Imported successfully
2024-05-28 14:30:39,048:INFO:Starting cross validation
2024-05-28 14:30:39,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:40,354:INFO:Calculating mean and std
2024-05-28 14:30:40,367:INFO:Creating metrics dataframe
2024-05-28 14:30:40,367:INFO:Uploading results into container
2024-05-28 14:30:40,367:INFO:Uploading model into container now
2024-05-28 14:30:40,367:INFO:_master_model_container: 6
2024-05-28 14:30:40,367:INFO:_display_container: 2
2024-05-28 14:30:40,367:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2065, solver='auto',
                tol=0.0001)
2024-05-28 14:30:40,367:INFO:create_model() successfully completed......................................
2024-05-28 14:30:40,650:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:40,650:INFO:Creating metrics dataframe
2024-05-28 14:30:40,650:INFO:Initializing Random Forest Classifier
2024-05-28 14:30:40,650:INFO:Total runtime is 0.1442180355389913 minutes
2024-05-28 14:30:40,650:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:40,650:INFO:Initializing create_model()
2024-05-28 14:30:40,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:40,650:INFO:Checking exceptions
2024-05-28 14:30:40,650:INFO:Importing libraries
2024-05-28 14:30:40,650:INFO:Copying training dataset
2024-05-28 14:30:40,650:INFO:Defining folds
2024-05-28 14:30:40,650:INFO:Declaring metric variables
2024-05-28 14:30:40,650:INFO:Importing untrained model
2024-05-28 14:30:40,650:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:30:40,650:INFO:Starting cross validation
2024-05-28 14:30:40,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:41,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:41,688:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:41,696:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:41,697:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:41,731:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:41,739:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:41,928:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:41,938:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:42,485:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:42,488:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:42,519:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:42,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:42,753:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:42,761:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:42,853:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:42,862:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,271:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:43,282:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,287:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:43,296:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,305:INFO:Calculating mean and std
2024-05-28 14:30:43,305:INFO:Creating metrics dataframe
2024-05-28 14:30:43,305:INFO:Uploading results into container
2024-05-28 14:30:43,305:INFO:Uploading model into container now
2024-05-28 14:30:43,305:INFO:_master_model_container: 7
2024-05-28 14:30:43,305:INFO:_display_container: 2
2024-05-28 14:30:43,305:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2065, verbose=0,
                       warm_start=False)
2024-05-28 14:30:43,305:INFO:create_model() successfully completed......................................
2024-05-28 14:30:43,472:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:43,472:INFO:Creating metrics dataframe
2024-05-28 14:30:43,488:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:30:43,488:INFO:Total runtime is 0.191511332988739 minutes
2024-05-28 14:30:43,488:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:43,488:INFO:Initializing create_model()
2024-05-28 14:30:43,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:43,488:INFO:Checking exceptions
2024-05-28 14:30:43,488:INFO:Importing libraries
2024-05-28 14:30:43,488:INFO:Copying training dataset
2024-05-28 14:30:43,488:INFO:Defining folds
2024-05-28 14:30:43,488:INFO:Declaring metric variables
2024-05-28 14:30:43,488:INFO:Importing untrained model
2024-05-28 14:30:43,488:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:30:43,488:INFO:Starting cross validation
2024-05-28 14:30:43,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:43,731:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:43,747:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:43,747:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:43,757:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:43,838:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,850:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,882:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:43,884:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:44,093:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,106:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,168:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:44,208:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:44,340:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,371:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:30:44,436:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:44,485:INFO:Calculating mean and std
2024-05-28 14:30:44,486:INFO:Creating metrics dataframe
2024-05-28 14:30:44,488:INFO:Uploading results into container
2024-05-28 14:30:44,489:INFO:Uploading model into container now
2024-05-28 14:30:44,490:INFO:_master_model_container: 8
2024-05-28 14:30:44,490:INFO:_display_container: 2
2024-05-28 14:30:44,491:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:30:44,491:INFO:create_model() successfully completed......................................
2024-05-28 14:30:44,708:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:44,709:INFO:Creating metrics dataframe
2024-05-28 14:30:44,712:INFO:Initializing Ada Boost Classifier
2024-05-28 14:30:44,712:INFO:Total runtime is 0.2119182030359904 minutes
2024-05-28 14:30:44,712:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:44,713:INFO:Initializing create_model()
2024-05-28 14:30:44,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:44,713:INFO:Checking exceptions
2024-05-28 14:30:44,713:INFO:Importing libraries
2024-05-28 14:30:44,713:INFO:Copying training dataset
2024-05-28 14:30:44,721:INFO:Defining folds
2024-05-28 14:30:44,721:INFO:Declaring metric variables
2024-05-28 14:30:44,722:INFO:Importing untrained model
2024-05-28 14:30:44,722:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:30:44,722:INFO:Starting cross validation
2024-05-28 14:30:44,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:44,936:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:44,941:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:44,973:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,003:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,022:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,022:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,058:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,095:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,202:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,241:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,264:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,285:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,298:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,326:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,348:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,379:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,474:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,495:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:30:45,568:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,620:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:45,652:INFO:Calculating mean and std
2024-05-28 14:30:45,663:INFO:Creating metrics dataframe
2024-05-28 14:30:45,663:INFO:Uploading results into container
2024-05-28 14:30:45,663:INFO:Uploading model into container now
2024-05-28 14:30:45,663:INFO:_master_model_container: 9
2024-05-28 14:30:45,663:INFO:_display_container: 2
2024-05-28 14:30:45,663:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2065)
2024-05-28 14:30:45,663:INFO:create_model() successfully completed......................................
2024-05-28 14:30:46,083:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:46,083:INFO:Creating metrics dataframe
2024-05-28 14:30:46,090:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:30:46,090:INFO:Total runtime is 0.23488079309463503 minutes
2024-05-28 14:30:46,091:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:46,092:INFO:Initializing create_model()
2024-05-28 14:30:46,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:46,092:INFO:Checking exceptions
2024-05-28 14:30:46,092:INFO:Importing libraries
2024-05-28 14:30:46,092:INFO:Copying training dataset
2024-05-28 14:30:46,102:INFO:Defining folds
2024-05-28 14:30:46,102:INFO:Declaring metric variables
2024-05-28 14:30:46,102:INFO:Importing untrained model
2024-05-28 14:30:46,102:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:30:46,102:INFO:Starting cross validation
2024-05-28 14:30:46,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:46,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:46,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:46,614:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:46,636:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,106:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,116:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,126:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,464:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,485:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:47,496:INFO:Calculating mean and std
2024-05-28 14:30:47,497:INFO:Creating metrics dataframe
2024-05-28 14:30:47,501:INFO:Uploading results into container
2024-05-28 14:30:47,501:INFO:Uploading model into container now
2024-05-28 14:30:47,501:INFO:_master_model_container: 10
2024-05-28 14:30:47,501:INFO:_display_container: 2
2024-05-28 14:30:47,501:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2065, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:30:47,501:INFO:create_model() successfully completed......................................
2024-05-28 14:30:47,692:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:47,692:INFO:Creating metrics dataframe
2024-05-28 14:30:47,700:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:30:47,701:INFO:Total runtime is 0.2617366592089335 minutes
2024-05-28 14:30:47,701:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:47,701:INFO:Initializing create_model()
2024-05-28 14:30:47,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:47,702:INFO:Checking exceptions
2024-05-28 14:30:47,702:INFO:Importing libraries
2024-05-28 14:30:47,702:INFO:Copying training dataset
2024-05-28 14:30:47,715:INFO:Defining folds
2024-05-28 14:30:47,715:INFO:Declaring metric variables
2024-05-28 14:30:47,715:INFO:Importing untrained model
2024-05-28 14:30:47,716:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:30:47,716:INFO:Starting cross validation
2024-05-28 14:30:47,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:48,212:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,239:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,252:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,298:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,819:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,832:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,836:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:48,856:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:49,067:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:49,067:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:49,087:INFO:Calculating mean and std
2024-05-28 14:30:49,087:INFO:Creating metrics dataframe
2024-05-28 14:30:49,087:INFO:Uploading results into container
2024-05-28 14:30:49,087:INFO:Uploading model into container now
2024-05-28 14:30:49,087:INFO:_master_model_container: 11
2024-05-28 14:30:49,087:INFO:_display_container: 2
2024-05-28 14:30:49,087:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:30:49,087:INFO:create_model() successfully completed......................................
2024-05-28 14:30:49,321:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:49,321:INFO:Creating metrics dataframe
2024-05-28 14:30:49,336:INFO:Initializing Extra Trees Classifier
2024-05-28 14:30:49,336:INFO:Total runtime is 0.28898270924886066 minutes
2024-05-28 14:30:49,336:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:49,336:INFO:Initializing create_model()
2024-05-28 14:30:49,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:49,336:INFO:Checking exceptions
2024-05-28 14:30:49,336:INFO:Importing libraries
2024-05-28 14:30:49,336:INFO:Copying training dataset
2024-05-28 14:30:49,352:INFO:Defining folds
2024-05-28 14:30:49,352:INFO:Declaring metric variables
2024-05-28 14:30:49,352:INFO:Importing untrained model
2024-05-28 14:30:49,352:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:30:49,352:INFO:Starting cross validation
2024-05-28 14:30:49,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:50,121:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:50,133:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:50,422:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:50,557:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:50,918:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:50,924:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:51,392:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:51,704:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:51,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:51,812:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:51,845:INFO:Calculating mean and std
2024-05-28 14:30:51,849:INFO:Creating metrics dataframe
2024-05-28 14:30:51,859:INFO:Uploading results into container
2024-05-28 14:30:51,860:INFO:Uploading model into container now
2024-05-28 14:30:51,861:INFO:_master_model_container: 12
2024-05-28 14:30:51,861:INFO:_display_container: 2
2024-05-28 14:30:51,862:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2065, verbose=0,
                     warm_start=False)
2024-05-28 14:30:51,863:INFO:create_model() successfully completed......................................
2024-05-28 14:30:52,075:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:52,075:INFO:Creating metrics dataframe
2024-05-28 14:30:52,075:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:30:52,075:INFO:Total runtime is 0.33462103207906085 minutes
2024-05-28 14:30:52,075:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:52,075:INFO:Initializing create_model()
2024-05-28 14:30:52,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:52,075:INFO:Checking exceptions
2024-05-28 14:30:52,075:INFO:Importing libraries
2024-05-28 14:30:52,075:INFO:Copying training dataset
2024-05-28 14:30:52,102:INFO:Defining folds
2024-05-28 14:30:52,102:INFO:Declaring metric variables
2024-05-28 14:30:52,102:INFO:Importing untrained model
2024-05-28 14:30:52,104:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:30:52,104:INFO:Starting cross validation
2024-05-28 14:30:52,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:52,514:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:52,531:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:52,531:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:52,548:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:52,550:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:52,551:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:52,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,145:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,154:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,166:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,170:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,173:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,186:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,460:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,465:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,496:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:53,502:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:53,520:INFO:Calculating mean and std
2024-05-28 14:30:53,521:INFO:Creating metrics dataframe
2024-05-28 14:30:53,522:INFO:Uploading results into container
2024-05-28 14:30:53,522:INFO:Uploading model into container now
2024-05-28 14:30:53,522:INFO:_master_model_container: 13
2024-05-28 14:30:53,522:INFO:_display_container: 2
2024-05-28 14:30:53,522:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:30:53,522:INFO:create_model() successfully completed......................................
2024-05-28 14:30:53,809:INFO:SubProcess create_model() end ==================================
2024-05-28 14:30:53,809:INFO:Creating metrics dataframe
2024-05-28 14:30:53,823:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:30:53,823:INFO:Total runtime is 0.3637608210245768 minutes
2024-05-28 14:30:53,823:INFO:SubProcess create_model() called ==================================
2024-05-28 14:30:53,823:INFO:Initializing create_model()
2024-05-28 14:30:53,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:30:53,823:INFO:Checking exceptions
2024-05-28 14:30:53,823:INFO:Importing libraries
2024-05-28 14:30:53,823:INFO:Copying training dataset
2024-05-28 14:30:53,823:INFO:Defining folds
2024-05-28 14:30:53,823:INFO:Declaring metric variables
2024-05-28 14:30:53,823:INFO:Importing untrained model
2024-05-28 14:30:53,823:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:30:53,823:INFO:Starting cross validation
2024-05-28 14:30:53,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:30:54,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:54,849:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:54,851:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:54,859:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:54,871:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:54,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:30:55,099:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:30:55,110:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:03,889:INFO:PyCaret ClassificationExperiment
2024-05-28 14:31:03,891:INFO:Logging name: clf-default-name
2024-05-28 14:31:03,892:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:31:03,893:INFO:version 3.3.1
2024-05-28 14:31:03,894:INFO:Initializing setup()
2024-05-28 14:31:03,895:INFO:self.USI: 1893
2024-05-28 14:31:03,962:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:31:03,966:INFO:Checking environment
2024-05-28 14:31:03,968:INFO:python_version: 3.11.9
2024-05-28 14:31:03,969:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:31:03,970:INFO:machine: AMD64
2024-05-28 14:31:03,971:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:31:03,993:INFO:Memory: svmem(total=8469606400, available=1597255680, percent=81.1, used=6872350720, free=1597255680)
2024-05-28 14:31:03,994:INFO:Physical Core: 2
2024-05-28 14:31:03,995:INFO:Logical Core: 4
2024-05-28 14:31:03,997:INFO:Checking libraries
2024-05-28 14:31:04,032:INFO:System:
2024-05-28 14:31:04,034:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:31:04,035:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:31:04,036:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:31:04,037:INFO:PyCaret required dependencies:
2024-05-28 14:31:04,038:INFO:                 pip: 24.0
2024-05-28 14:31:04,039:INFO:          setuptools: 70.0.0
2024-05-28 14:31:04,040:INFO:             pycaret: 3.3.1
2024-05-28 14:31:04,041:INFO:             IPython: 8.24.0
2024-05-28 14:31:04,042:INFO:          ipywidgets: 8.1.2
2024-05-28 14:31:04,042:INFO:                tqdm: 4.66.4
2024-05-28 14:31:04,043:INFO:               numpy: 1.26.4
2024-05-28 14:31:04,044:INFO:              pandas: 2.1.4
2024-05-28 14:31:04,045:INFO:              jinja2: 3.1.4
2024-05-28 14:31:04,047:INFO:               scipy: 1.11.4
2024-05-28 14:31:04,048:INFO:              joblib: 1.3.2
2024-05-28 14:31:04,049:INFO:             sklearn: 1.4.2
2024-05-28 14:31:04,050:INFO:                pyod: 1.1.3
2024-05-28 14:31:04,051:INFO:            imblearn: 0.12.2
2024-05-28 14:31:04,052:INFO:   category_encoders: 2.6.3
2024-05-28 14:31:04,053:INFO:            lightgbm: 4.3.0
2024-05-28 14:31:04,055:INFO:               numba: 0.58.1
2024-05-28 14:31:04,056:INFO:            requests: 2.32.2
2024-05-28 14:31:04,058:INFO:          matplotlib: 3.7.5
2024-05-28 14:31:04,059:INFO:          scikitplot: 0.3.7
2024-05-28 14:31:04,060:INFO:         yellowbrick: 1.5
2024-05-28 14:31:04,061:INFO:              plotly: 5.22.0
2024-05-28 14:31:04,062:INFO:    plotly-resampler: Not installed
2024-05-28 14:31:04,065:INFO:             kaleido: 0.2.1
2024-05-28 14:31:04,089:INFO:           schemdraw: 0.15
2024-05-28 14:31:04,090:INFO:         statsmodels: 0.14.2
2024-05-28 14:31:04,091:INFO:              sktime: 0.26.0
2024-05-28 14:31:04,092:INFO:               tbats: 1.1.3
2024-05-28 14:31:04,093:INFO:            pmdarima: 2.0.4
2024-05-28 14:31:04,094:INFO:              psutil: 5.9.8
2024-05-28 14:31:04,095:INFO:          markupsafe: 2.1.5
2024-05-28 14:31:04,095:INFO:             pickle5: Not installed
2024-05-28 14:31:04,098:INFO:         cloudpickle: 3.0.0
2024-05-28 14:31:04,099:INFO:         deprecation: 2.1.0
2024-05-28 14:31:04,100:INFO:              xxhash: 3.4.1
2024-05-28 14:31:04,101:INFO:           wurlitzer: 3.1.0
2024-05-28 14:31:04,102:INFO:PyCaret optional dependencies:
2024-05-28 14:31:04,104:INFO:                shap: Not installed
2024-05-28 14:31:04,105:INFO:           interpret: Not installed
2024-05-28 14:31:04,107:INFO:                umap: 0.5.5
2024-05-28 14:31:04,108:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:31:04,109:INFO:  explainerdashboard: Not installed
2024-05-28 14:31:04,110:INFO:             autoviz: Not installed
2024-05-28 14:31:04,112:INFO:           fairlearn: Not installed
2024-05-28 14:31:04,115:INFO:          deepchecks: Not installed
2024-05-28 14:31:04,116:INFO:             xgboost: 2.0.3
2024-05-28 14:31:04,117:INFO:            catboost: 1.2.5
2024-05-28 14:31:04,118:INFO:              kmodes: 0.12.2
2024-05-28 14:31:04,119:INFO:             mlxtend: 0.23.1
2024-05-28 14:31:04,119:INFO:       statsforecast: Not installed
2024-05-28 14:31:04,120:INFO:        tune_sklearn: Not installed
2024-05-28 14:31:04,121:INFO:                 ray: Not installed
2024-05-28 14:31:04,122:INFO:            hyperopt: Not installed
2024-05-28 14:31:04,123:INFO:              optuna: Not installed
2024-05-28 14:31:04,159:INFO:               skopt: Not installed
2024-05-28 14:31:04,160:INFO:              mlflow: 2.13.0
2024-05-28 14:31:04,161:INFO:              gradio: Not installed
2024-05-28 14:31:04,162:INFO:             fastapi: Not installed
2024-05-28 14:31:04,162:INFO:             uvicorn: Not installed
2024-05-28 14:31:04,167:INFO:              m2cgen: Not installed
2024-05-28 14:31:04,168:INFO:           evidently: Not installed
2024-05-28 14:31:04,169:INFO:               fugue: Not installed
2024-05-28 14:31:04,170:INFO:           streamlit: 1.35.0
2024-05-28 14:31:04,171:INFO:             prophet: Not installed
2024-05-28 14:31:04,172:INFO:None
2024-05-28 14:31:04,173:INFO:Set up data.
2024-05-28 14:31:04,389:INFO:Set up folding strategy.
2024-05-28 14:31:04,392:INFO:Set up train/test split.
2024-05-28 14:31:04,685:INFO:Set up index.
2024-05-28 14:31:04,690:INFO:Assigning column types.
2024-05-28 14:31:04,956:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:31:08,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:31:08,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:31:09,906:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:10,040:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:11,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:31:11,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:31:11,894:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:11,918:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:11,921:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:31:12,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:31:12,606:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:12,622:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:12,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:31:13,230:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:13,244:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:13,248:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:31:13,732:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:13,750:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:14,193:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:14,210:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:14,216:INFO:Preparing preprocessing pipeline...
2024-05-28 14:31:14,220:INFO:Set up simple imputation.
2024-05-28 14:31:14,234:INFO:Set up encoding of ordinal features.
2024-05-28 14:31:14,249:INFO:Set up encoding of categorical features.
2024-05-28 14:31:14,249:INFO:Set up imbalanced handling.
2024-05-28 14:31:14,887:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:14,914:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:15,263:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:15,281:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:15,326:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:31:15,443:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:31:15,444:INFO:Creating final display dataframe.
2024-05-28 14:31:15,856:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:15,891:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:16,660:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:16,677:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:17,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:17,495:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:17,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:17,543:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:17,670:INFO:Calculating mean and std
2024-05-28 14:31:17,686:INFO:Creating metrics dataframe
2024-05-28 14:31:17,686:INFO:Uploading results into container
2024-05-28 14:31:17,686:INFO:Uploading model into container now
2024-05-28 14:31:17,710:INFO:_master_model_container: 14
2024-05-28 14:31:17,710:INFO:_display_container: 2
2024-05-28 14:31:17,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2065, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:31:17,736:INFO:create_model() successfully completed......................................
2024-05-28 14:31:18,069:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:18,084:INFO:Creating metrics dataframe
2024-05-28 14:31:18,104:INFO:Initializing CatBoost Classifier
2024-05-28 14:31:18,118:INFO:Total runtime is 0.7686619480450948 minutes
2024-05-28 14:31:18,120:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:18,121:INFO:Initializing create_model()
2024-05-28 14:31:18,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:18,132:INFO:Checking exceptions
2024-05-28 14:31:18,133:INFO:Importing libraries
2024-05-28 14:31:18,134:INFO:Copying training dataset
2024-05-28 14:31:18,234:INFO:Defining folds
2024-05-28 14:31:18,240:INFO:Declaring metric variables
2024-05-28 14:31:18,259:INFO:Importing untrained model
2024-05-28 14:31:18,259:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:31:18,259:INFO:Starting cross validation
2024-05-28 14:31:18,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:19,694:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py:287: UserWarning: Persisting input arguments took 1.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-28 14:31:19,919:INFO:Setup _display_container:                     Description             Value
0                    Session id              6958
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              1893
2024-05-28 14:31:19,919:INFO:                    Description             Value
2024-05-28 14:31:19,919:INFO:0                    Session id              6958
2024-05-28 14:31:19,919:INFO:1                        Target          Survived
2024-05-28 14:31:19,919:INFO:2                   Target type            Binary
2024-05-28 14:31:19,919:INFO:3           Original data shape         (891, 12)
2024-05-28 14:31:19,919:INFO:4        Transformed data shape        (1036, 14)
2024-05-28 14:31:19,919:INFO:5   Transformed train set shape         (768, 14)
2024-05-28 14:31:19,919:INFO:6    Transformed test set shape         (268, 14)
2024-05-28 14:31:19,919:INFO:7              Numeric features                 6
2024-05-28 14:31:19,919:INFO:8          Categorical features                 5
2024-05-28 14:31:19,919:INFO:9      Rows with missing values             79.5%
2024-05-28 14:31:19,919:INFO:10                   Preprocess              True
2024-05-28 14:31:19,919:INFO:11              Imputation type            simple
2024-05-28 14:31:19,919:INFO:12           Numeric imputation              mean
2024-05-28 14:31:19,919:INFO:13       Categorical imputation              mode
2024-05-28 14:31:19,919:INFO:14     Maximum one-hot encoding                25
2024-05-28 14:31:19,919:INFO:15              Encoding method              None
2024-05-28 14:31:19,919:INFO:16                Fix imbalance              True
2024-05-28 14:31:19,919:INFO:17         Fix imbalance method             SMOTE
2024-05-28 14:31:19,919:INFO:18               Fold Generator   StratifiedKFold
2024-05-28 14:31:19,919:INFO:19                  Fold Number                10
2024-05-28 14:31:19,919:INFO:20                     CPU Jobs                -1
2024-05-28 14:31:19,919:INFO:21                      Use GPU             False
2024-05-28 14:31:19,919:INFO:22               Log Experiment             False
2024-05-28 14:31:19,919:INFO:23              Experiment Name  clf-default-name
2024-05-28 14:31:19,919:INFO:24                          USI              1893
2024-05-28 14:31:20,251:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:20,261:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:20,640:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:31:20,651:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:31:20,651:INFO:setup() successfully completed in 17.16s...............
2024-05-28 14:31:20,675:INFO:Initializing compare_models()
2024-05-28 14:31:20,676:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:31:20,676:INFO:Checking exceptions
2024-05-28 14:31:20,721:INFO:Preparing display monitor
2024-05-28 14:31:20,742:WARNING:
2024-05-28 14:31:20,742:WARNING:Processing:   0%|                                                                      | 0/69 [00:00<?, ?it/s]
2024-05-28 14:31:20,743:WARNING:[A
2024-05-28 14:31:20,743:INFO:Initializing Logistic Regression
2024-05-28 14:31:20,744:INFO:Total runtime is 1.6629695892333984e-05 minutes
2024-05-28 14:31:20,744:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:20,745:INFO:Initializing create_model()
2024-05-28 14:31:20,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:20,745:INFO:Checking exceptions
2024-05-28 14:31:20,747:INFO:Importing libraries
2024-05-28 14:31:20,747:INFO:Copying training dataset
2024-05-28 14:31:20,761:INFO:Defining folds
2024-05-28 14:31:20,761:INFO:Declaring metric variables
2024-05-28 14:31:20,762:INFO:Importing untrained model
2024-05-28 14:31:20,763:INFO:Logistic Regression Imported successfully
2024-05-28 14:31:20,764:INFO:Starting cross validation
2024-05-28 14:31:20,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:28,264:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:28,276:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:28,601:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:28,613:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:28,790:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:28,803:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:28,894:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:28,905:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:37,089:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:37,114:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:37,589:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:37,616:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:37,733:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:37,751:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:37,930:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:37,955:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:37,987:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:38,412:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:38,535:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:38,715:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:38,830:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:39,285:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:39,375:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:39,492:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:40,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:40,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:40,371:INFO:Calculating mean and std
2024-05-28 14:31:40,371:WARNING:
2024-05-28 14:31:40,371:WARNING:Processing:   7%|####4                                                         | 5/69 [00:19<04:11,  3.93s/it]
2024-05-28 14:31:40,374:WARNING:[A
2024-05-28 14:31:40,374:INFO:Creating metrics dataframe
2024-05-28 14:31:40,378:INFO:Uploading results into container
2024-05-28 14:31:40,379:INFO:Uploading model into container now
2024-05-28 14:31:40,380:INFO:_master_model_container: 1
2024-05-28 14:31:40,380:INFO:_display_container: 2
2024-05-28 14:31:40,381:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:31:40,381:INFO:create_model() successfully completed......................................
2024-05-28 14:31:40,666:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:40,667:INFO:Creating metrics dataframe
2024-05-28 14:31:40,675:INFO:Initializing K Neighbors Classifier
2024-05-28 14:31:40,676:INFO:Total runtime is 0.3322099089622498 minutes
2024-05-28 14:31:40,676:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:40,677:INFO:Initializing create_model()
2024-05-28 14:31:40,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:40,678:INFO:Checking exceptions
2024-05-28 14:31:40,678:INFO:Importing libraries
2024-05-28 14:31:40,679:INFO:Copying training dataset
2024-05-28 14:31:40,689:WARNING:
2024-05-28 14:31:40,689:WARNING:Processing:  10%|######2                                                       | 7/69 [00:19<02:38,  2.56s/it]
2024-05-28 14:31:40,689:WARNING:[A
2024-05-28 14:31:40,689:INFO:Defining folds
2024-05-28 14:31:40,689:INFO:Declaring metric variables
2024-05-28 14:31:40,689:INFO:Importing untrained model
2024-05-28 14:31:40,689:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:31:40,699:INFO:Starting cross validation
2024-05-28 14:31:40,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:41,093:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:41,097:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:41,529:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:41,535:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:41,935:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:41,936:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:42,274:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:42,274:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:42,643:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:42,643:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:42,696:INFO:Calculating mean and std
2024-05-28 14:31:42,696:WARNING:
2024-05-28 14:31:42,699:WARNING:Processing:  13%|########                                                      | 9/69 [00:21<02:01,  2.03s/it]
2024-05-28 14:31:42,699:WARNING:[A
2024-05-28 14:31:42,700:INFO:Creating metrics dataframe
2024-05-28 14:31:42,700:INFO:Uploading results into container
2024-05-28 14:31:42,705:INFO:Uploading model into container now
2024-05-28 14:31:42,706:INFO:_master_model_container: 2
2024-05-28 14:31:42,706:INFO:_display_container: 2
2024-05-28 14:31:42,706:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:31:42,706:INFO:create_model() successfully completed......................................
2024-05-28 14:31:42,978:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:42,978:INFO:Creating metrics dataframe
2024-05-28 14:31:42,987:INFO:Initializing Naive Bayes
2024-05-28 14:31:42,987:INFO:Total runtime is 0.370722766717275 minutes
2024-05-28 14:31:42,988:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:42,988:INFO:Initializing create_model()
2024-05-28 14:31:42,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:42,989:INFO:Checking exceptions
2024-05-28 14:31:42,989:INFO:Importing libraries
2024-05-28 14:31:42,989:INFO:Copying training dataset
2024-05-28 14:31:43,000:WARNING:
2024-05-28 14:31:43,000:WARNING:Processing:  16%|#########7                                                   | 11/69 [00:22<01:21,  1.41s/it]
2024-05-28 14:31:43,000:WARNING:[A
2024-05-28 14:31:43,000:INFO:Defining folds
2024-05-28 14:31:43,000:INFO:Declaring metric variables
2024-05-28 14:31:43,000:INFO:Importing untrained model
2024-05-28 14:31:43,000:INFO:Naive Bayes Imported successfully
2024-05-28 14:31:43,000:INFO:Starting cross validation
2024-05-28 14:31:43,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:43,338:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:43,338:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:43,682:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:43,721:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,018:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,075:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,376:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,465:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,703:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,790:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:44,814:INFO:Calculating mean and std
2024-05-28 14:31:44,816:WARNING:
2024-05-28 14:31:44,816:WARNING:Processing:  19%|###########4                                                 | 13/69 [00:24<01:10,  1.25s/it]
2024-05-28 14:31:44,816:WARNING:[A
2024-05-28 14:31:44,816:INFO:Creating metrics dataframe
2024-05-28 14:31:44,820:INFO:Uploading results into container
2024-05-28 14:31:44,821:INFO:Uploading model into container now
2024-05-28 14:31:44,822:INFO:_master_model_container: 3
2024-05-28 14:31:44,822:INFO:_display_container: 2
2024-05-28 14:31:44,823:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:31:44,823:INFO:create_model() successfully completed......................................
2024-05-28 14:31:45,081:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:45,082:INFO:Creating metrics dataframe
2024-05-28 14:31:45,091:INFO:Initializing Decision Tree Classifier
2024-05-28 14:31:45,091:INFO:Total runtime is 0.4057979623476664 minutes
2024-05-28 14:31:45,092:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:45,093:INFO:Initializing create_model()
2024-05-28 14:31:45,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:45,093:INFO:Checking exceptions
2024-05-28 14:31:45,094:INFO:Importing libraries
2024-05-28 14:31:45,094:INFO:Copying training dataset
2024-05-28 14:31:45,106:WARNING:
2024-05-28 14:31:45,106:WARNING:Processing:  22%|#############2                                               | 15/69 [00:24<00:48,  1.11it/s]
2024-05-28 14:31:45,106:WARNING:[A
2024-05-28 14:31:45,106:INFO:Defining folds
2024-05-28 14:31:45,106:INFO:Declaring metric variables
2024-05-28 14:31:45,106:INFO:Importing untrained model
2024-05-28 14:31:45,106:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:31:45,106:INFO:Starting cross validation
2024-05-28 14:31:45,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:45,464:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:45,472:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:45,482:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:45,482:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:45,830:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:45,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:45,846:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:45,857:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,152:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,161:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,201:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,212:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,470:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,491:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,553:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,587:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,805:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,808:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,816:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,899:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:46,909:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:46,931:INFO:Calculating mean and std
2024-05-28 14:31:46,931:WARNING:
2024-05-28 14:31:46,931:WARNING:Processing:  25%|###############                                              | 17/69 [00:26<00:47,  1.10it/s]
2024-05-28 14:31:46,931:WARNING:[A
2024-05-28 14:31:46,931:INFO:Creating metrics dataframe
2024-05-28 14:31:46,931:INFO:Uploading results into container
2024-05-28 14:31:46,931:INFO:Uploading model into container now
2024-05-28 14:31:46,931:INFO:_master_model_container: 4
2024-05-28 14:31:46,931:INFO:_display_container: 2
2024-05-28 14:31:46,931:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6958, splitter='best')
2024-05-28 14:31:46,931:INFO:create_model() successfully completed......................................
2024-05-28 14:31:47,122:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:47,128:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:47,174:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:47,175:INFO:Creating metrics dataframe
2024-05-28 14:31:47,181:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:31:47,181:INFO:Total runtime is 0.4406219561894735 minutes
2024-05-28 14:31:47,182:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:47,182:INFO:Initializing create_model()
2024-05-28 14:31:47,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:47,183:INFO:Checking exceptions
2024-05-28 14:31:47,183:INFO:Importing libraries
2024-05-28 14:31:47,183:INFO:Copying training dataset
2024-05-28 14:31:47,189:WARNING:
2024-05-28 14:31:47,189:WARNING:Processing:  28%|################7                                            | 19/69 [00:26<00:33,  1.50it/s]
2024-05-28 14:31:47,189:INFO:Calculating mean and std
2024-05-28 14:31:47,190:WARNING:[A
2024-05-28 14:31:47,190:INFO:Defining folds
2024-05-28 14:31:47,191:INFO:Declaring metric variables
2024-05-28 14:31:47,191:INFO:Creating metrics dataframe
2024-05-28 14:31:47,191:INFO:Importing untrained model
2024-05-28 14:31:47,194:INFO:Uploading results into container
2024-05-28 14:31:47,194:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:31:47,195:INFO:Uploading model into container now
2024-05-28 14:31:47,195:INFO:Starting cross validation
2024-05-28 14:31:47,196:INFO:_master_model_container: 15
2024-05-28 14:31:47,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:47,196:INFO:_display_container: 2
2024-05-28 14:31:47,196:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCB00D650>
2024-05-28 14:31:47,196:INFO:create_model() successfully completed......................................
2024-05-28 14:31:47,362:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:47,362:INFO:Creating metrics dataframe
2024-05-28 14:31:47,378:INFO:Initializing Dummy Classifier
2024-05-28 14:31:47,379:INFO:Total runtime is 1.2563496390978495 minutes
2024-05-28 14:31:47,379:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:47,380:INFO:Initializing create_model()
2024-05-28 14:31:47,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA6D7350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:47,380:INFO:Checking exceptions
2024-05-28 14:31:47,381:INFO:Importing libraries
2024-05-28 14:31:47,381:INFO:Copying training dataset
2024-05-28 14:31:47,412:INFO:Defining folds
2024-05-28 14:31:47,412:INFO:Declaring metric variables
2024-05-28 14:31:47,417:INFO:Importing untrained model
2024-05-28 14:31:47,417:INFO:Dummy Classifier Imported successfully
2024-05-28 14:31:47,417:INFO:Starting cross validation
2024-05-28 14:31:47,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:48,123:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,395:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,411:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,443:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,454:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,473:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,483:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,698:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,703:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,707:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,727:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,735:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:48,759:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:48,769:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:49,055:INFO:Calculating mean and std
2024-05-28 14:31:49,056:WARNING:
2024-05-28 14:31:49,057:WARNING:Processing:  30%|##################5                                          | 21/69 [00:28<00:35,  1.33it/s]
2024-05-28 14:31:49,057:WARNING:[A
2024-05-28 14:31:49,057:INFO:Creating metrics dataframe
2024-05-28 14:31:49,061:INFO:Uploading results into container
2024-05-28 14:31:49,062:INFO:Uploading model into container now
2024-05-28 14:31:49,062:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:49,063:INFO:_master_model_container: 5
2024-05-28 14:31:49,064:INFO:_display_container: 2
2024-05-28 14:31:49,065:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6958, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:31:49,065:INFO:create_model() successfully completed......................................
2024-05-28 14:31:49,074:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:49,076:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:49,088:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:49,274:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:49,274:INFO:Creating metrics dataframe
2024-05-28 14:31:49,277:INFO:Initializing Ridge Classifier
2024-05-28 14:31:49,277:INFO:Total runtime is 0.47556878328323365 minutes
2024-05-28 14:31:49,277:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:49,277:INFO:Initializing create_model()
2024-05-28 14:31:49,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:49,277:INFO:Checking exceptions
2024-05-28 14:31:49,277:INFO:Importing libraries
2024-05-28 14:31:49,277:INFO:Copying training dataset
2024-05-28 14:31:49,286:WARNING:
2024-05-28 14:31:49,286:WARNING:Processing:  33%|####################3                                        | 23/69 [00:28<00:25,  1.80it/s]
2024-05-28 14:31:49,286:WARNING:[A
2024-05-28 14:31:49,286:INFO:Defining folds
2024-05-28 14:31:49,286:INFO:Declaring metric variables
2024-05-28 14:31:49,286:INFO:Importing untrained model
2024-05-28 14:31:49,286:INFO:Ridge Classifier Imported successfully
2024-05-28 14:31:49,286:INFO:Starting cross validation
2024-05-28 14:31:49,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:49,296:INFO:Calculating mean and std
2024-05-28 14:31:49,296:INFO:Creating metrics dataframe
2024-05-28 14:31:49,296:INFO:Uploading results into container
2024-05-28 14:31:49,296:INFO:Uploading model into container now
2024-05-28 14:31:49,296:INFO:_master_model_container: 16
2024-05-28 14:31:49,296:INFO:_display_container: 2
2024-05-28 14:31:49,296:INFO:DummyClassifier(constant=None, random_state=2065, strategy='prior')
2024-05-28 14:31:49,296:INFO:create_model() successfully completed......................................
2024-05-28 14:31:49,477:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:49,477:INFO:Creating metrics dataframe
2024-05-28 14:31:49,477:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:31:49,477:INFO:Initializing create_model()
2024-05-28 14:31:49,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3BB0190>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2065, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:49,477:INFO:Checking exceptions
2024-05-28 14:31:49,477:INFO:Importing libraries
2024-05-28 14:31:49,477:INFO:Copying training dataset
2024-05-28 14:31:49,514:INFO:Defining folds
2024-05-28 14:31:49,516:INFO:Declaring metric variables
2024-05-28 14:31:49,517:INFO:Importing untrained model
2024-05-28 14:31:49,521:INFO:Declaring custom model
2024-05-28 14:31:49,522:INFO:Logistic Regression Imported successfully
2024-05-28 14:31:49,530:INFO:Cross validation set to False
2024-05-28 14:31:49,530:INFO:Fitting Model
2024-05-28 14:31:50,435:INFO:Calculating mean and std
2024-05-28 14:31:50,435:WARNING:
2024-05-28 14:31:50,435:WARNING:Processing:  36%|######################1                                      | 25/69 [00:29<00:24,  1.78it/s]
2024-05-28 14:31:50,435:WARNING:[A
2024-05-28 14:31:50,435:INFO:Creating metrics dataframe
2024-05-28 14:31:50,435:INFO:Uploading results into container
2024-05-28 14:31:50,443:INFO:Uploading model into container now
2024-05-28 14:31:50,444:INFO:_master_model_container: 6
2024-05-28 14:31:50,445:INFO:_display_container: 2
2024-05-28 14:31:50,446:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6958, solver='auto',
                tol=0.0001)
2024-05-28 14:31:50,446:INFO:create_model() successfully completed......................................
2024-05-28 14:31:50,660:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:50,660:INFO:Creating metrics dataframe
2024-05-28 14:31:50,677:INFO:Initializing Random Forest Classifier
2024-05-28 14:31:50,677:INFO:Total runtime is 0.498885715007782 minutes
2024-05-28 14:31:50,677:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:50,677:INFO:Initializing create_model()
2024-05-28 14:31:50,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:50,677:INFO:Checking exceptions
2024-05-28 14:31:50,677:INFO:Importing libraries
2024-05-28 14:31:50,677:INFO:Copying training dataset
2024-05-28 14:31:50,677:WARNING:
2024-05-28 14:31:50,677:WARNING:Processing:  39%|#######################8                                     | 27/69 [00:29<00:18,  2.33it/s]
2024-05-28 14:31:50,677:WARNING:[A
2024-05-28 14:31:50,677:INFO:Defining folds
2024-05-28 14:31:50,677:INFO:Declaring metric variables
2024-05-28 14:31:50,677:INFO:Importing untrained model
2024-05-28 14:31:50,693:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:31:50,694:INFO:Starting cross validation
2024-05-28 14:31:50,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:51,471:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:51,481:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:51,488:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:51,490:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:51,492:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:51,492:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:51,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:51,662:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:52,205:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:52,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:52,227:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:52,245:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:52,378:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:52,387:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:52,543:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:52,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:53,002:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:53,012:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:53,012:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:53,032:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:53,036:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:31:53,037:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2065, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:31:53,037:INFO:create_model() successfully completed......................................
2024-05-28 14:31:53,279:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2024-05-28 14:31:53,279:INFO:lr                    Logistic Regression    0.8203  0.8809  0.7991  0.7556   
2024-05-28 14:31:53,279:INFO:Calculating mean and std
2024-05-28 14:31:53,279:INFO:ridge                    Ridge Classifier    0.7720  0.8712  0.5234  0.8242   
2024-05-28 14:31:53,279:WARNING:
2024-05-28 14:31:53,279:INFO:et                 Extra Trees Classifier    0.7639  0.0000  0.5487  0.7802   
2024-05-28 14:31:53,279:WARNING:Processing:  42%|#########################6                                   | 29/69 [00:32<00:27,  1.45it/s]
2024-05-28 14:31:53,279:INFO:nb                            Naive Bayes    0.6467  0.0000  0.1212  0.8040   
2024-05-28 14:31:53,279:WARNING:[A
2024-05-28 14:31:53,279:INFO:dt               Decision Tree Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:Creating metrics dataframe
2024-05-28 14:31:53,279:INFO:rf               Random Forest Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:Uploading results into container
2024-05-28 14:31:53,279:INFO:ada                  Ada Boost Classifier    0.6164  0.5000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:Uploading model into container now
2024-05-28 14:31:53,279:INFO:gbc          Gradient Boosting Classifier    0.6164  0.5000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:_master_model_container: 7
2024-05-28 14:31:53,279:INFO:lda          Linear Discriminant Analysis    0.6164  0.5000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:_display_container: 2
2024-05-28 14:31:53,279:INFO:xgboost         Extreme Gradient Boosting    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6958, verbose=0,
                       warm_start=False)
2024-05-28 14:31:53,279:INFO:lightgbm  Light Gradient Boosting Machine    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,279:INFO:create_model() successfully completed......................................
2024-05-28 14:31:53,279:INFO:catboost              CatBoost Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,478:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:53,478:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:31:53,478:INFO:Creating metrics dataframe
2024-05-28 14:31:53,479:INFO:knn                K Neighbors Classifier    0.6069  0.0000  0.5611  0.4941   
2024-05-28 14:31:53,484:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:31:53,484:INFO:qda       Quadratic Discriminant Analysis    0.5454  0.5423  0.3000  0.1145   
2024-05-28 14:31:53,484:INFO:Total runtime is 0.545685084660848 minutes
2024-05-28 14:31:53,485:INFO:svm                   SVM - Linear Kernel    0.5382  0.6243  0.5837  0.5317   
2024-05-28 14:31:53,485:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:53,485:INFO:
2024-05-28 14:31:53,485:INFO:Initializing create_model()
2024-05-28 14:31:53,486:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-05-28 14:31:53,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:53,486:INFO:lr        0.7741  0.6255  0.6295     0.194  
2024-05-28 14:31:53,486:INFO:Checking exceptions
2024-05-28 14:31:53,486:INFO:ridge     0.6360  0.4826  0.5113     0.130  
2024-05-28 14:31:53,486:INFO:Importing libraries
2024-05-28 14:31:53,486:INFO:et        0.6348  0.4705  0.4920     0.247  
2024-05-28 14:31:53,487:INFO:Copying training dataset
2024-05-28 14:31:53,487:INFO:nb        0.2039  0.1126  0.1990     0.094  
2024-05-28 14:31:53,490:INFO:dt        0.0000  0.0000  0.0000     0.099  
2024-05-28 14:31:53,490:INFO:rf        0.0000  0.0000  0.0000     0.266  
2024-05-28 14:31:53,490:INFO:ada       0.0000  0.0000  0.0000     0.093  
2024-05-28 14:31:53,490:INFO:gbc       0.0000  0.0000  0.0000     0.138  
2024-05-28 14:31:53,490:INFO:lda       0.0000  0.0000  0.0000     0.137  
2024-05-28 14:31:53,490:INFO:xgboost   0.0000  0.0000  0.0000     0.141  
2024-05-28 14:31:53,490:INFO:lightgbm  0.0000  0.0000  0.0000     2.382  
2024-05-28 14:31:53,490:WARNING:
2024-05-28 14:31:53,490:INFO:catboost  0.0000  0.0000  0.0000     2.891  
2024-05-28 14:31:53,490:WARNING:Processing:  45%|###########################4                                 | 31/69 [00:32<00:19,  1.94it/s]
2024-05-28 14:31:53,490:INFO:dummy     0.0000  0.0000  0.0000     0.188  
2024-05-28 14:31:53,490:WARNING:[A
2024-05-28 14:31:53,490:INFO:knn       0.5226  0.1921  0.1948     0.115  
2024-05-28 14:31:53,490:INFO:Defining folds
2024-05-28 14:31:53,490:INFO:qda       0.1657  0.0000  0.0000     0.100  
2024-05-28 14:31:53,490:INFO:Declaring metric variables
2024-05-28 14:31:53,490:INFO:svm       0.4112  0.0915  0.1337     0.102  
2024-05-28 14:31:53,490:INFO:Importing untrained model
2024-05-28 14:31:53,490:INFO:_master_model_container: 16
2024-05-28 14:31:53,490:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:31:53,490:INFO:_display_container: 2
2024-05-28 14:31:53,490:INFO:Starting cross validation
2024-05-28 14:31:53,490:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2065, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:31:53,490:INFO:compare_models() successfully completed......................................
2024-05-28 14:31:53,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:53,724:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:53,756:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:53,775:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:53,799:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:53,842:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:53,858:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:53,869:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,049:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,083:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,108:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,110:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,200:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,204:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,293:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,315:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:31:54,351:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,378:INFO:Calculating mean and std
2024-05-28 14:31:54,379:WARNING:
2024-05-28 14:31:54,379:WARNING:Processing:  48%|#############################1                               | 33/69 [00:33<00:17,  2.02it/s]
2024-05-28 14:31:54,379:WARNING:[A
2024-05-28 14:31:54,379:INFO:Creating metrics dataframe
2024-05-28 14:31:54,381:INFO:Uploading results into container
2024-05-28 14:31:54,382:INFO:Uploading model into container now
2024-05-28 14:31:54,382:INFO:_master_model_container: 8
2024-05-28 14:31:54,382:INFO:_display_container: 2
2024-05-28 14:31:54,383:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:31:54,383:INFO:create_model() successfully completed......................................
2024-05-28 14:31:54,556:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:54,556:INFO:Creating metrics dataframe
2024-05-28 14:31:54,569:INFO:Initializing Ada Boost Classifier
2024-05-28 14:31:54,569:INFO:Total runtime is 0.5637642025947571 minutes
2024-05-28 14:31:54,569:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:54,570:INFO:Initializing create_model()
2024-05-28 14:31:54,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:54,570:INFO:Checking exceptions
2024-05-28 14:31:54,570:INFO:Importing libraries
2024-05-28 14:31:54,570:INFO:Copying training dataset
2024-05-28 14:31:54,577:WARNING:
2024-05-28 14:31:54,578:WARNING:Processing:  51%|##############################9                              | 35/69 [00:33<00:12,  2.66it/s]
2024-05-28 14:31:54,578:WARNING:[A
2024-05-28 14:31:54,578:INFO:Defining folds
2024-05-28 14:31:54,578:INFO:Declaring metric variables
2024-05-28 14:31:54,578:INFO:Importing untrained model
2024-05-28 14:31:54,579:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:31:54,579:INFO:Starting cross validation
2024-05-28 14:31:54,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:54,791:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:54,796:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:54,809:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:54,819:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:54,872:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,872:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,896:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:54,896:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,066:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,073:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,096:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,106:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,179:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,198:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,198:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,352:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,356:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:31:55,417:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,417:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:55,439:INFO:Calculating mean and std
2024-05-28 14:31:55,439:WARNING:
2024-05-28 14:31:55,439:WARNING:Processing:  54%|################################7                            | 37/69 [00:34<00:12,  2.55it/s]
2024-05-28 14:31:55,439:WARNING:[A
2024-05-28 14:31:55,439:INFO:Creating metrics dataframe
2024-05-28 14:31:55,439:INFO:Uploading results into container
2024-05-28 14:31:55,439:INFO:Uploading model into container now
2024-05-28 14:31:55,439:INFO:_master_model_container: 9
2024-05-28 14:31:55,439:INFO:_display_container: 2
2024-05-28 14:31:55,439:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6958)
2024-05-28 14:31:55,439:INFO:create_model() successfully completed......................................
2024-05-28 14:31:55,630:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:55,630:INFO:Creating metrics dataframe
2024-05-28 14:31:55,634:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:31:55,635:INFO:Total runtime is 0.5815333565076193 minutes
2024-05-28 14:31:55,635:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:55,635:INFO:Initializing create_model()
2024-05-28 14:31:55,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:55,636:INFO:Checking exceptions
2024-05-28 14:31:55,636:INFO:Importing libraries
2024-05-28 14:31:55,636:INFO:Copying training dataset
2024-05-28 14:31:55,639:WARNING:
2024-05-28 14:31:55,639:WARNING:Processing:  57%|##################################4                          | 39/69 [00:34<00:09,  3.29it/s]
2024-05-28 14:31:55,639:WARNING:[A
2024-05-28 14:31:55,639:INFO:Defining folds
2024-05-28 14:31:55,639:INFO:Declaring metric variables
2024-05-28 14:31:55,639:INFO:Importing untrained model
2024-05-28 14:31:55,639:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:31:55,639:INFO:Starting cross validation
2024-05-28 14:31:55,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:56,163:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,205:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,205:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,256:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,671:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,706:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,729:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:56,744:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,026:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,042:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,058:INFO:Calculating mean and std
2024-05-28 14:31:57,059:WARNING:
2024-05-28 14:31:57,059:WARNING:Processing:  59%|####################################2                        | 41/69 [00:36<00:11,  2.35it/s]
2024-05-28 14:31:57,059:WARNING:[A
2024-05-28 14:31:57,059:INFO:Creating metrics dataframe
2024-05-28 14:31:57,061:INFO:Uploading results into container
2024-05-28 14:31:57,062:INFO:Uploading model into container now
2024-05-28 14:31:57,062:INFO:_master_model_container: 10
2024-05-28 14:31:57,062:INFO:_display_container: 2
2024-05-28 14:31:57,063:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6958, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:31:57,063:INFO:create_model() successfully completed......................................
2024-05-28 14:31:57,228:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:57,228:INFO:Creating metrics dataframe
2024-05-28 14:31:57,231:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:31:57,231:INFO:Total runtime is 0.608129103978475 minutes
2024-05-28 14:31:57,231:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:57,231:INFO:Initializing create_model()
2024-05-28 14:31:57,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:57,232:INFO:Checking exceptions
2024-05-28 14:31:57,232:INFO:Importing libraries
2024-05-28 14:31:57,232:INFO:Copying training dataset
2024-05-28 14:31:57,238:WARNING:
2024-05-28 14:31:57,238:WARNING:Processing:  62%|######################################                       | 43/69 [00:36<00:08,  3.08it/s]
2024-05-28 14:31:57,238:WARNING:[A
2024-05-28 14:31:57,238:INFO:Defining folds
2024-05-28 14:31:57,238:INFO:Declaring metric variables
2024-05-28 14:31:57,238:INFO:Importing untrained model
2024-05-28 14:31:57,238:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:31:57,238:INFO:Starting cross validation
2024-05-28 14:31:57,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:57,534:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,557:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,557:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,807:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,833:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,838:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:57,868:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:58,108:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:58,146:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:31:58,160:INFO:Calculating mean and std
2024-05-28 14:31:58,160:WARNING:
2024-05-28 14:31:58,160:WARNING:Processing:  65%|#######################################7                     | 45/69 [00:37<00:08,  2.73it/s]
2024-05-28 14:31:58,160:WARNING:[A
2024-05-28 14:31:58,160:INFO:Creating metrics dataframe
2024-05-28 14:31:58,160:INFO:Uploading results into container
2024-05-28 14:31:58,160:INFO:Uploading model into container now
2024-05-28 14:31:58,160:INFO:_master_model_container: 11
2024-05-28 14:31:58,160:INFO:_display_container: 2
2024-05-28 14:31:58,160:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:31:58,160:INFO:create_model() successfully completed......................................
2024-05-28 14:31:58,341:INFO:SubProcess create_model() end ==================================
2024-05-28 14:31:58,341:INFO:Creating metrics dataframe
2024-05-28 14:31:58,344:INFO:Initializing Extra Trees Classifier
2024-05-28 14:31:58,344:INFO:Total runtime is 0.6266782840092977 minutes
2024-05-28 14:31:58,344:INFO:SubProcess create_model() called ==================================
2024-05-28 14:31:58,344:INFO:Initializing create_model()
2024-05-28 14:31:58,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:31:58,345:INFO:Checking exceptions
2024-05-28 14:31:58,345:INFO:Importing libraries
2024-05-28 14:31:58,345:INFO:Copying training dataset
2024-05-28 14:31:58,349:WARNING:
2024-05-28 14:31:58,350:WARNING:Processing:  68%|#########################################5                   | 47/69 [00:37<00:06,  3.51it/s]
2024-05-28 14:31:58,350:WARNING:[A
2024-05-28 14:31:58,350:INFO:Defining folds
2024-05-28 14:31:58,350:INFO:Declaring metric variables
2024-05-28 14:31:58,350:INFO:Importing untrained model
2024-05-28 14:31:58,350:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:31:58,351:INFO:Starting cross validation
2024-05-28 14:31:58,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:31:59,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:59,084:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:59,100:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:31:59,721:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:00,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:00,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:00,212:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:00,852:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:00,996:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,016:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,057:INFO:Calculating mean and std
2024-05-28 14:32:01,059:WARNING:
2024-05-28 14:32:01,060:WARNING:Processing:  71%|###########################################3                 | 49/69 [00:40<00:12,  1.65it/s]
2024-05-28 14:32:01,060:WARNING:[A
2024-05-28 14:32:01,060:INFO:Creating metrics dataframe
2024-05-28 14:32:01,065:INFO:Uploading results into container
2024-05-28 14:32:01,066:INFO:Uploading model into container now
2024-05-28 14:32:01,067:INFO:_master_model_container: 12
2024-05-28 14:32:01,067:INFO:_display_container: 2
2024-05-28 14:32:01,069:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6958, verbose=0,
                     warm_start=False)
2024-05-28 14:32:01,069:INFO:create_model() successfully completed......................................
2024-05-28 14:32:01,353:INFO:SubProcess create_model() end ==================================
2024-05-28 14:32:01,353:INFO:Creating metrics dataframe
2024-05-28 14:32:01,356:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:32:01,357:INFO:Total runtime is 0.6768966356913249 minutes
2024-05-28 14:32:01,357:INFO:SubProcess create_model() called ==================================
2024-05-28 14:32:01,357:INFO:Initializing create_model()
2024-05-28 14:32:01,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:32:01,358:INFO:Checking exceptions
2024-05-28 14:32:01,358:INFO:Importing libraries
2024-05-28 14:32:01,358:INFO:Copying training dataset
2024-05-28 14:32:01,363:WARNING:
2024-05-28 14:32:01,363:WARNING:Processing:  74%|#############################################                | 51/69 [00:40<00:08,  2.13it/s]
2024-05-28 14:32:01,363:WARNING:[A
2024-05-28 14:32:01,363:INFO:Defining folds
2024-05-28 14:32:01,363:INFO:Declaring metric variables
2024-05-28 14:32:01,363:INFO:Importing untrained model
2024-05-28 14:32:01,364:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:32:01,365:INFO:Starting cross validation
2024-05-28 14:32:01,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:32:01,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:01,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:01,688:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:01,688:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:01,698:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,023:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,031:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,057:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,073:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,106:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,123:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,136:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,146:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,416:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,425:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,459:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:02,470:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:02,485:INFO:Calculating mean and std
2024-05-28 14:32:02,487:WARNING:
2024-05-28 14:32:02,488:WARNING:Processing:  77%|##############################################8              | 53/69 [00:41<00:07,  2.01it/s]
2024-05-28 14:32:02,488:WARNING:[A
2024-05-28 14:32:02,488:INFO:Creating metrics dataframe
2024-05-28 14:32:02,491:INFO:Uploading results into container
2024-05-28 14:32:02,491:INFO:Uploading model into container now
2024-05-28 14:32:02,492:INFO:_master_model_container: 13
2024-05-28 14:32:02,492:INFO:_display_container: 2
2024-05-28 14:32:02,493:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:32:02,493:INFO:create_model() successfully completed......................................
2024-05-28 14:32:02,702:INFO:SubProcess create_model() end ==================================
2024-05-28 14:32:02,702:INFO:Creating metrics dataframe
2024-05-28 14:32:02,706:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:32:02,707:INFO:Total runtime is 0.6994013905525207 minutes
2024-05-28 14:32:02,707:INFO:SubProcess create_model() called ==================================
2024-05-28 14:32:02,707:INFO:Initializing create_model()
2024-05-28 14:32:02,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:32:02,708:INFO:Checking exceptions
2024-05-28 14:32:02,708:INFO:Importing libraries
2024-05-28 14:32:02,708:INFO:Copying training dataset
2024-05-28 14:32:02,717:WARNING:
2024-05-28 14:32:02,718:WARNING:Processing:  80%|################################################6            | 55/69 [00:41<00:05,  2.61it/s]
2024-05-28 14:32:02,718:WARNING:[A
2024-05-28 14:32:02,718:INFO:Defining folds
2024-05-28 14:32:02,718:INFO:Declaring metric variables
2024-05-28 14:32:02,718:INFO:Importing untrained model
2024-05-28 14:32:02,719:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:32:02,719:INFO:Starting cross validation
2024-05-28 14:32:02,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:32:03,843:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:03,844:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:03,850:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:03,850:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:03,850:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:03,860:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:03,917:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:03,927:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:05,132:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:05,141:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:05,141:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:05,154:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:05,160:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:05,162:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:05,170:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:05,171:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:06,086:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:06,099:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:06,100:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:06,110:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:06,128:INFO:Calculating mean and std
2024-05-28 14:32:06,131:WARNING:
2024-05-28 14:32:06,131:WARNING:Processing:  83%|##################################################3          | 57/69 [00:45<00:09,  1.28it/s]
2024-05-28 14:32:06,131:WARNING:[A
2024-05-28 14:32:06,131:INFO:Creating metrics dataframe
2024-05-28 14:32:06,131:INFO:Uploading results into container
2024-05-28 14:32:06,131:INFO:Uploading model into container now
2024-05-28 14:32:06,131:INFO:_master_model_container: 14
2024-05-28 14:32:06,131:INFO:_display_container: 2
2024-05-28 14:32:06,131:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6958, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:32:06,131:INFO:create_model() successfully completed......................................
2024-05-28 14:32:06,375:INFO:SubProcess create_model() end ==================================
2024-05-28 14:32:06,375:INFO:Creating metrics dataframe
2024-05-28 14:32:06,386:INFO:Initializing CatBoost Classifier
2024-05-28 14:32:06,386:INFO:Total runtime is 0.7607141812642415 minutes
2024-05-28 14:32:06,387:INFO:SubProcess create_model() called ==================================
2024-05-28 14:32:06,387:INFO:Initializing create_model()
2024-05-28 14:32:06,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:32:06,387:INFO:Checking exceptions
2024-05-28 14:32:06,388:INFO:Importing libraries
2024-05-28 14:32:06,388:INFO:Copying training dataset
2024-05-28 14:32:06,399:WARNING:
2024-05-28 14:32:06,399:WARNING:Processing:  86%|####################################################1        | 59/69 [00:45<00:05,  1.71it/s]
2024-05-28 14:32:06,399:WARNING:[A
2024-05-28 14:32:06,399:INFO:Defining folds
2024-05-28 14:32:06,399:INFO:Declaring metric variables
2024-05-28 14:32:06,399:INFO:Importing untrained model
2024-05-28 14:32:06,400:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:32:06,400:INFO:Starting cross validation
2024-05-28 14:32:06,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:32:35,896:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:35,922:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:36,097:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:36,129:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:36,563:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:36,590:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:36,993:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:37,058:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:49,257:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:49,270:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:49,696:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:49,707:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:49,804:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:49,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:50,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:50,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:55,404:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:55,424:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:55,545:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:55,556:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:55,566:INFO:Calculating mean and std
2024-05-28 14:32:55,566:WARNING:
2024-05-28 14:32:55,566:WARNING:Processing:  88%|#####################################################9       | 61/69 [01:34<01:02,  7.79s/it]
2024-05-28 14:32:55,566:WARNING:[A
2024-05-28 14:32:55,566:INFO:Creating metrics dataframe
2024-05-28 14:32:55,566:INFO:Uploading results into container
2024-05-28 14:32:55,566:INFO:Uploading model into container now
2024-05-28 14:32:55,566:INFO:_master_model_container: 15
2024-05-28 14:32:55,566:INFO:_display_container: 2
2024-05-28 14:32:55,566:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCA643850>
2024-05-28 14:32:55,566:INFO:create_model() successfully completed......................................
2024-05-28 14:32:55,770:INFO:SubProcess create_model() end ==================================
2024-05-28 14:32:55,770:INFO:Creating metrics dataframe
2024-05-28 14:32:55,770:INFO:Initializing Dummy Classifier
2024-05-28 14:32:55,770:INFO:Total runtime is 1.583776843547821 minutes
2024-05-28 14:32:55,770:INFO:SubProcess create_model() called ==================================
2024-05-28 14:32:55,770:INFO:Initializing create_model()
2024-05-28 14:32:55,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCB42A4D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:32:55,770:INFO:Checking exceptions
2024-05-28 14:32:55,770:INFO:Importing libraries
2024-05-28 14:32:55,770:INFO:Copying training dataset
2024-05-28 14:32:55,786:WARNING:
2024-05-28 14:32:55,786:WARNING:Processing:  91%|#######################################################6     | 63/69 [01:35<00:32,  5.48s/it]
2024-05-28 14:32:55,786:WARNING:[A
2024-05-28 14:32:55,786:INFO:Defining folds
2024-05-28 14:32:55,786:INFO:Declaring metric variables
2024-05-28 14:32:55,786:INFO:Importing untrained model
2024-05-28 14:32:55,790:INFO:Dummy Classifier Imported successfully
2024-05-28 14:32:55,791:INFO:Starting cross validation
2024-05-28 14:32:55,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:32:56,104:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,120:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,136:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,147:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,147:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,162:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,162:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,179:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,438:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,453:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,453:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,463:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,463:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,496:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,500:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,789:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,789:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:32:56,811:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,811:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:32:56,839:INFO:Calculating mean and std
2024-05-28 14:32:56,839:WARNING:
2024-05-28 14:32:56,839:WARNING:Processing:  94%|#########################################################4   | 65/69 [01:36<00:15,  4.00s/it]
2024-05-28 14:32:56,839:WARNING:[A
2024-05-28 14:32:56,839:INFO:Creating metrics dataframe
2024-05-28 14:32:56,839:INFO:Uploading results into container
2024-05-28 14:32:56,839:INFO:Uploading model into container now
2024-05-28 14:32:56,839:INFO:_master_model_container: 16
2024-05-28 14:32:56,839:INFO:_display_container: 2
2024-05-28 14:32:56,839:INFO:DummyClassifier(constant=None, random_state=6958, strategy='prior')
2024-05-28 14:32:56,839:INFO:create_model() successfully completed......................................
2024-05-28 14:32:57,114:INFO:SubProcess create_model() end ==================================
2024-05-28 14:32:57,114:INFO:Creating metrics dataframe
2024-05-28 14:32:57,130:WARNING:
2024-05-28 14:32:57,130:WARNING:Processing:  97%|###########################################################2 | 67/69 [01:36<00:05,  2.84s/it]
2024-05-28 14:32:57,130:WARNING:[A
2024-05-28 14:32:57,130:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:32:57,130:INFO:Initializing create_model()
2024-05-28 14:32:57,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:32:57,130:INFO:Checking exceptions
2024-05-28 14:32:57,130:INFO:Importing libraries
2024-05-28 14:32:57,130:INFO:Copying training dataset
2024-05-28 14:32:57,145:INFO:Defining folds
2024-05-28 14:32:57,145:INFO:Declaring metric variables
2024-05-28 14:32:57,145:INFO:Importing untrained model
2024-05-28 14:32:57,145:INFO:Declaring custom model
2024-05-28 14:32:57,145:INFO:Logistic Regression Imported successfully
2024-05-28 14:32:57,145:INFO:Cross validation set to False
2024-05-28 14:32:57,154:INFO:Fitting Model
2024-05-28 14:32:57,629:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:32:57,629:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:32:57,629:INFO:create_model() successfully completed......................................
2024-05-28 14:32:57,852:WARNING:
2024-05-28 14:32:57,852:WARNING:Processing: 100%|#############################################################| 69/69 [01:37<00:00,  2.10s/it]
2024-05-28 14:32:57,852:WARNING:[A
2024-05-28 14:32:57,852:WARNING:
2024-05-28 14:32:57,852:WARNING:                                                                                                              
2024-05-28 14:32:57,853:WARNING:[A
2024-05-28 14:32:57,871:INFO:_master_model_container: 16
2024-05-28 14:32:57,871:INFO:_display_container: 2
2024-05-28 14:32:57,871:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:32:57,871:INFO:compare_models() successfully completed......................................
2024-05-28 14:32:57,927:INFO:Initializing save_model()
2024-05-28 14:32:57,927:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:32:57,927:INFO:Adding model into prep_pipe
2024-05-28 14:32:57,937:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:32:57,977:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=6958,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:32:57,978:INFO:save_model() successfully completed......................................
2024-05-28 14:32:58,143:INFO:Initializing plot_model()
2024-05-28 14:32:58,143:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCBDABC50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6958, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-05-28 14:32:58,143:INFO:Checking exceptions
2024-05-28 14:32:58,143:INFO:Preloading libraries
2024-05-28 14:32:58,143:INFO:Copying training dataset
2024-05-28 14:32:58,143:INFO:Plot type: auc
2024-05-28 14:32:58,338:INFO:Fitting Model
2024-05-28 14:32:58,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-05-28 14:32:58,339:INFO:Scoring test/hold-out set
2024-05-28 14:32:58,370:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2024-05-28 14:32:58,399:INFO:Visual Rendered Successfully
2024-05-28 14:32:58,579:INFO:plot_model() successfully completed......................................
2024-05-28 14:37:53,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:37:53,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:37:53,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:37:53,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:37:58,342:INFO:PyCaret ClassificationExperiment
2024-05-28 14:37:58,342:INFO:Logging name: clf-default-name
2024-05-28 14:37:58,342:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:37:58,342:INFO:version 3.3.1
2024-05-28 14:37:58,342:INFO:Initializing setup()
2024-05-28 14:37:58,342:INFO:self.USI: 6820
2024-05-28 14:37:58,342:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:37:58,342:INFO:Checking environment
2024-05-28 14:37:58,342:INFO:python_version: 3.11.9
2024-05-28 14:37:58,342:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:37:58,342:INFO:machine: AMD64
2024-05-28 14:37:58,342:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:37:58,360:INFO:Memory: svmem(total=8469606400, available=1793949696, percent=78.8, used=6675656704, free=1793949696)
2024-05-28 14:37:58,360:INFO:Physical Core: 2
2024-05-28 14:37:58,360:INFO:Logical Core: 4
2024-05-28 14:37:58,361:INFO:Checking libraries
2024-05-28 14:37:58,362:INFO:System:
2024-05-28 14:37:58,362:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:37:58,362:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:37:58,362:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:37:58,362:INFO:PyCaret required dependencies:
2024-05-28 14:37:58,363:INFO:                 pip: 24.0
2024-05-28 14:37:58,363:INFO:          setuptools: 70.0.0
2024-05-28 14:37:58,363:INFO:             pycaret: 3.3.1
2024-05-28 14:37:58,363:INFO:             IPython: 8.24.0
2024-05-28 14:37:58,363:INFO:          ipywidgets: 8.1.2
2024-05-28 14:37:58,364:INFO:                tqdm: 4.66.4
2024-05-28 14:37:58,364:INFO:               numpy: 1.26.4
2024-05-28 14:37:58,364:INFO:              pandas: 2.1.4
2024-05-28 14:37:58,364:INFO:              jinja2: 3.1.4
2024-05-28 14:37:58,364:INFO:               scipy: 1.11.4
2024-05-28 14:37:58,364:INFO:              joblib: 1.3.2
2024-05-28 14:37:58,365:INFO:             sklearn: 1.4.2
2024-05-28 14:37:58,365:INFO:                pyod: 1.1.3
2024-05-28 14:37:58,365:INFO:            imblearn: 0.12.2
2024-05-28 14:37:58,365:INFO:   category_encoders: 2.6.3
2024-05-28 14:37:58,365:INFO:            lightgbm: 4.3.0
2024-05-28 14:37:58,365:INFO:               numba: 0.58.1
2024-05-28 14:37:58,365:INFO:            requests: 2.32.2
2024-05-28 14:37:58,367:INFO:          matplotlib: 3.7.5
2024-05-28 14:37:58,367:INFO:          scikitplot: 0.3.7
2024-05-28 14:37:58,367:INFO:         yellowbrick: 1.5
2024-05-28 14:37:58,367:INFO:              plotly: 5.22.0
2024-05-28 14:37:58,368:INFO:    plotly-resampler: Not installed
2024-05-28 14:37:58,368:INFO:             kaleido: 0.2.1
2024-05-28 14:37:58,369:INFO:           schemdraw: 0.15
2024-05-28 14:37:58,370:INFO:         statsmodels: 0.14.2
2024-05-28 14:37:58,370:INFO:              sktime: 0.26.0
2024-05-28 14:37:58,370:INFO:               tbats: 1.1.3
2024-05-28 14:37:58,370:INFO:            pmdarima: 2.0.4
2024-05-28 14:37:58,370:INFO:              psutil: 5.9.8
2024-05-28 14:37:58,370:INFO:          markupsafe: 2.1.5
2024-05-28 14:37:58,370:INFO:             pickle5: Not installed
2024-05-28 14:37:58,371:INFO:         cloudpickle: 3.0.0
2024-05-28 14:37:58,371:INFO:         deprecation: 2.1.0
2024-05-28 14:37:58,371:INFO:              xxhash: 3.4.1
2024-05-28 14:37:58,371:INFO:           wurlitzer: 3.1.0
2024-05-28 14:37:58,372:INFO:PyCaret optional dependencies:
2024-05-28 14:37:58,372:INFO:                shap: Not installed
2024-05-28 14:37:58,372:INFO:           interpret: Not installed
2024-05-28 14:37:58,373:INFO:                umap: 0.5.5
2024-05-28 14:37:58,373:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:37:58,374:INFO:  explainerdashboard: Not installed
2024-05-28 14:37:58,374:INFO:             autoviz: Not installed
2024-05-28 14:37:58,374:INFO:           fairlearn: Not installed
2024-05-28 14:37:58,374:INFO:          deepchecks: Not installed
2024-05-28 14:37:58,374:INFO:             xgboost: 2.0.3
2024-05-28 14:37:58,374:INFO:            catboost: 1.2.5
2024-05-28 14:37:58,374:INFO:              kmodes: 0.12.2
2024-05-28 14:37:58,375:INFO:             mlxtend: 0.23.1
2024-05-28 14:37:58,375:INFO:       statsforecast: Not installed
2024-05-28 14:37:58,375:INFO:        tune_sklearn: Not installed
2024-05-28 14:37:58,376:INFO:                 ray: Not installed
2024-05-28 14:37:58,376:INFO:            hyperopt: Not installed
2024-05-28 14:37:58,376:INFO:              optuna: Not installed
2024-05-28 14:37:58,377:INFO:               skopt: Not installed
2024-05-28 14:37:58,377:INFO:              mlflow: 2.13.0
2024-05-28 14:37:58,377:INFO:              gradio: Not installed
2024-05-28 14:37:58,378:INFO:             fastapi: Not installed
2024-05-28 14:37:58,378:INFO:             uvicorn: Not installed
2024-05-28 14:37:58,378:INFO:              m2cgen: Not installed
2024-05-28 14:37:58,378:INFO:           evidently: Not installed
2024-05-28 14:37:58,378:INFO:               fugue: Not installed
2024-05-28 14:37:58,379:INFO:           streamlit: 1.35.0
2024-05-28 14:37:58,380:INFO:             prophet: Not installed
2024-05-28 14:37:58,380:INFO:None
2024-05-28 14:37:58,380:INFO:Set up data.
2024-05-28 14:37:58,407:INFO:Set up folding strategy.
2024-05-28 14:37:58,407:INFO:Set up train/test split.
2024-05-28 14:37:58,424:INFO:Set up index.
2024-05-28 14:37:58,424:INFO:Assigning column types.
2024-05-28 14:37:58,468:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:37:58,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:37:58,624:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:37:58,692:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:58,708:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:58,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:37:58,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:37:58,908:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:58,926:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:58,927:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:37:59,024:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:37:59,074:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:59,074:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:59,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:37:59,190:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:59,190:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:59,190:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:37:59,307:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:59,307:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:59,457:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:37:59,473:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:37:59,473:INFO:Preparing preprocessing pipeline...
2024-05-28 14:37:59,473:INFO:Set up simple imputation.
2024-05-28 14:37:59,473:INFO:Set up encoding of ordinal features.
2024-05-28 14:37:59,491:INFO:Set up encoding of categorical features.
2024-05-28 14:37:59,491:INFO:Set up imbalanced handling.
2024-05-28 14:37:59,807:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:37:59,858:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:37:59,859:INFO:Creating final display dataframe.
2024-05-28 14:38:00,663:INFO:Setup _display_container:                     Description             Value
0                    Session id              7618
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              6820
2024-05-28 14:38:00,783:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:38:00,786:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:38:00,879:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:38:00,882:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:38:00,884:INFO:setup() successfully completed in 2.57s...............
2024-05-28 14:38:00,890:INFO:Initializing compare_models()
2024-05-28 14:38:00,890:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:38:00,891:INFO:Checking exceptions
2024-05-28 14:38:00,898:INFO:Preparing display monitor
2024-05-28 14:38:00,898:INFO:Initializing Logistic Regression
2024-05-28 14:38:00,898:INFO:Total runtime is 0.0 minutes
2024-05-28 14:38:00,898:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:00,898:INFO:Initializing create_model()
2024-05-28 14:38:00,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:00,898:INFO:Checking exceptions
2024-05-28 14:38:00,898:INFO:Importing libraries
2024-05-28 14:38:00,898:INFO:Copying training dataset
2024-05-28 14:38:00,906:INFO:Defining folds
2024-05-28 14:38:00,906:INFO:Declaring metric variables
2024-05-28 14:38:00,906:INFO:Importing untrained model
2024-05-28 14:38:00,906:INFO:Logistic Regression Imported successfully
2024-05-28 14:38:00,906:INFO:Starting cross validation
2024-05-28 14:38:00,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:10,845:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:10,947:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:11,073:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:11,364:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:11,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:11,737:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:11,821:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:12,120:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:12,274:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:12,305:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:38:12,369:INFO:Calculating mean and std
2024-05-28 14:38:12,370:INFO:Creating metrics dataframe
2024-05-28 14:38:12,372:INFO:Uploading results into container
2024-05-28 14:38:12,373:INFO:Uploading model into container now
2024-05-28 14:38:12,373:INFO:_master_model_container: 1
2024-05-28 14:38:12,373:INFO:_display_container: 2
2024-05-28 14:38:12,374:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:38:12,374:INFO:create_model() successfully completed......................................
2024-05-28 14:38:12,548:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:12,548:INFO:Creating metrics dataframe
2024-05-28 14:38:12,550:INFO:Initializing K Neighbors Classifier
2024-05-28 14:38:12,552:INFO:Total runtime is 0.1942213257153829 minutes
2024-05-28 14:38:12,552:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:12,552:INFO:Initializing create_model()
2024-05-28 14:38:12,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:12,552:INFO:Checking exceptions
2024-05-28 14:38:12,552:INFO:Importing libraries
2024-05-28 14:38:12,552:INFO:Copying training dataset
2024-05-28 14:38:12,556:INFO:Defining folds
2024-05-28 14:38:12,557:INFO:Declaring metric variables
2024-05-28 14:38:12,557:INFO:Importing untrained model
2024-05-28 14:38:12,557:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:38:12,558:INFO:Starting cross validation
2024-05-28 14:38:12,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:12,922:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:12,922:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:12,922:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,016:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,251:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,251:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,370:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,377:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,532:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:13,545:INFO:Calculating mean and std
2024-05-28 14:38:13,546:INFO:Creating metrics dataframe
2024-05-28 14:38:13,548:INFO:Uploading results into container
2024-05-28 14:38:13,548:INFO:Uploading model into container now
2024-05-28 14:38:13,549:INFO:_master_model_container: 2
2024-05-28 14:38:13,549:INFO:_display_container: 2
2024-05-28 14:38:13,549:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:38:13,549:INFO:create_model() successfully completed......................................
2024-05-28 14:38:13,719:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:13,719:INFO:Creating metrics dataframe
2024-05-28 14:38:13,722:INFO:Initializing Naive Bayes
2024-05-28 14:38:13,722:INFO:Total runtime is 0.21373753945032756 minutes
2024-05-28 14:38:13,722:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:13,723:INFO:Initializing create_model()
2024-05-28 14:38:13,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:13,723:INFO:Checking exceptions
2024-05-28 14:38:13,723:INFO:Importing libraries
2024-05-28 14:38:13,723:INFO:Copying training dataset
2024-05-28 14:38:13,728:INFO:Defining folds
2024-05-28 14:38:13,728:INFO:Declaring metric variables
2024-05-28 14:38:13,728:INFO:Importing untrained model
2024-05-28 14:38:13,728:INFO:Naive Bayes Imported successfully
2024-05-28 14:38:13,728:INFO:Starting cross validation
2024-05-28 14:38:13,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:14,004:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,005:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,015:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,302:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,302:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,312:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,322:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,571:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:14,592:INFO:Calculating mean and std
2024-05-28 14:38:14,593:INFO:Creating metrics dataframe
2024-05-28 14:38:14,596:INFO:Uploading results into container
2024-05-28 14:38:14,596:INFO:Uploading model into container now
2024-05-28 14:38:14,597:INFO:_master_model_container: 3
2024-05-28 14:38:14,597:INFO:_display_container: 2
2024-05-28 14:38:14,597:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:38:14,597:INFO:create_model() successfully completed......................................
2024-05-28 14:38:14,761:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:14,761:INFO:Creating metrics dataframe
2024-05-28 14:38:14,761:INFO:Initializing Decision Tree Classifier
2024-05-28 14:38:14,761:INFO:Total runtime is 0.2310503880182902 minutes
2024-05-28 14:38:14,761:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:14,761:INFO:Initializing create_model()
2024-05-28 14:38:14,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:14,761:INFO:Checking exceptions
2024-05-28 14:38:14,761:INFO:Importing libraries
2024-05-28 14:38:14,761:INFO:Copying training dataset
2024-05-28 14:38:14,778:INFO:Defining folds
2024-05-28 14:38:14,778:INFO:Declaring metric variables
2024-05-28 14:38:14,779:INFO:Importing untrained model
2024-05-28 14:38:14,779:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:38:14,779:INFO:Starting cross validation
2024-05-28 14:38:14,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:15,044:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,049:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,051:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,060:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,062:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,063:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,064:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,075:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,344:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,357:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,359:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,387:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,395:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,572:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,581:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,589:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:15,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:15,614:INFO:Calculating mean and std
2024-05-28 14:38:15,614:INFO:Creating metrics dataframe
2024-05-28 14:38:15,614:INFO:Uploading results into container
2024-05-28 14:38:15,614:INFO:Uploading model into container now
2024-05-28 14:38:15,614:INFO:_master_model_container: 4
2024-05-28 14:38:15,614:INFO:_display_container: 2
2024-05-28 14:38:15,614:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7618, splitter='best')
2024-05-28 14:38:15,614:INFO:create_model() successfully completed......................................
2024-05-28 14:38:15,810:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:15,810:INFO:Creating metrics dataframe
2024-05-28 14:38:15,810:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:38:15,810:INFO:Total runtime is 0.24852704207102458 minutes
2024-05-28 14:38:15,810:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:15,810:INFO:Initializing create_model()
2024-05-28 14:38:15,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:15,810:INFO:Checking exceptions
2024-05-28 14:38:15,810:INFO:Importing libraries
2024-05-28 14:38:15,810:INFO:Copying training dataset
2024-05-28 14:38:15,810:INFO:Defining folds
2024-05-28 14:38:15,810:INFO:Declaring metric variables
2024-05-28 14:38:15,810:INFO:Importing untrained model
2024-05-28 14:38:15,810:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:38:15,810:INFO:Starting cross validation
2024-05-28 14:38:15,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:16,580:INFO:Calculating mean and std
2024-05-28 14:38:16,583:INFO:Creating metrics dataframe
2024-05-28 14:38:16,586:INFO:Uploading results into container
2024-05-28 14:38:16,587:INFO:Uploading model into container now
2024-05-28 14:38:16,587:INFO:_master_model_container: 5
2024-05-28 14:38:16,587:INFO:_display_container: 2
2024-05-28 14:38:16,589:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7618, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:38:16,589:INFO:create_model() successfully completed......................................
2024-05-28 14:38:16,797:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:16,797:INFO:Creating metrics dataframe
2024-05-28 14:38:16,800:INFO:Initializing Ridge Classifier
2024-05-28 14:38:16,800:INFO:Total runtime is 0.265034278233846 minutes
2024-05-28 14:38:16,800:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:16,800:INFO:Initializing create_model()
2024-05-28 14:38:16,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:16,801:INFO:Checking exceptions
2024-05-28 14:38:16,801:INFO:Importing libraries
2024-05-28 14:38:16,801:INFO:Copying training dataset
2024-05-28 14:38:16,806:INFO:Defining folds
2024-05-28 14:38:16,806:INFO:Declaring metric variables
2024-05-28 14:38:16,807:INFO:Importing untrained model
2024-05-28 14:38:16,807:INFO:Ridge Classifier Imported successfully
2024-05-28 14:38:16,807:INFO:Starting cross validation
2024-05-28 14:38:16,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:17,552:INFO:Calculating mean and std
2024-05-28 14:38:17,553:INFO:Creating metrics dataframe
2024-05-28 14:38:17,555:INFO:Uploading results into container
2024-05-28 14:38:17,556:INFO:Uploading model into container now
2024-05-28 14:38:17,556:INFO:_master_model_container: 6
2024-05-28 14:38:17,557:INFO:_display_container: 2
2024-05-28 14:38:17,557:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7618, solver='auto',
                tol=0.0001)
2024-05-28 14:38:17,557:INFO:create_model() successfully completed......................................
2024-05-28 14:38:17,746:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:17,746:INFO:Creating metrics dataframe
2024-05-28 14:38:17,751:INFO:Initializing Random Forest Classifier
2024-05-28 14:38:17,751:INFO:Total runtime is 0.2808716893196106 minutes
2024-05-28 14:38:17,751:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:17,752:INFO:Initializing create_model()
2024-05-28 14:38:17,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:17,752:INFO:Checking exceptions
2024-05-28 14:38:17,752:INFO:Importing libraries
2024-05-28 14:38:17,752:INFO:Copying training dataset
2024-05-28 14:38:17,758:INFO:Defining folds
2024-05-28 14:38:17,758:INFO:Declaring metric variables
2024-05-28 14:38:17,758:INFO:Importing untrained model
2024-05-28 14:38:17,758:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:38:17,758:INFO:Starting cross validation
2024-05-28 14:38:17,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:18,499:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:18,511:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:18,511:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:18,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:18,577:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:18,585:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:18,595:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:19,223:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,230:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,242:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:19,332:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,342:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:19,353:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,359:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:19,793:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,807:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:19,809:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:19,829:INFO:Calculating mean and std
2024-05-28 14:38:19,829:INFO:Creating metrics dataframe
2024-05-28 14:38:19,829:INFO:Uploading results into container
2024-05-28 14:38:19,829:INFO:Uploading model into container now
2024-05-28 14:38:19,829:INFO:_master_model_container: 7
2024-05-28 14:38:19,829:INFO:_display_container: 2
2024-05-28 14:38:19,829:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7618, verbose=0,
                       warm_start=False)
2024-05-28 14:38:19,829:INFO:create_model() successfully completed......................................
2024-05-28 14:38:20,023:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:20,023:INFO:Creating metrics dataframe
2024-05-28 14:38:20,023:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:38:20,023:INFO:Total runtime is 0.31875240405400596 minutes
2024-05-28 14:38:20,023:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:20,023:INFO:Initializing create_model()
2024-05-28 14:38:20,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:20,023:INFO:Checking exceptions
2024-05-28 14:38:20,023:INFO:Importing libraries
2024-05-28 14:38:20,023:INFO:Copying training dataset
2024-05-28 14:38:20,023:INFO:Defining folds
2024-05-28 14:38:20,023:INFO:Declaring metric variables
2024-05-28 14:38:20,023:INFO:Importing untrained model
2024-05-28 14:38:20,023:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:38:20,023:INFO:Starting cross validation
2024-05-28 14:38:20,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:20,242:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,271:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,282:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,293:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,346:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:20,376:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:20,385:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:20,555:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,580:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,591:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,667:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:20,772:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,774:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:38:20,824:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:20,845:INFO:Calculating mean and std
2024-05-28 14:38:20,846:INFO:Creating metrics dataframe
2024-05-28 14:38:20,848:INFO:Uploading results into container
2024-05-28 14:38:20,849:INFO:Uploading model into container now
2024-05-28 14:38:20,850:INFO:_master_model_container: 8
2024-05-28 14:38:20,850:INFO:_display_container: 2
2024-05-28 14:38:20,850:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:38:20,850:INFO:create_model() successfully completed......................................
2024-05-28 14:38:21,021:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:21,022:INFO:Creating metrics dataframe
2024-05-28 14:38:21,023:INFO:Initializing Ada Boost Classifier
2024-05-28 14:38:21,023:INFO:Total runtime is 0.33540789286295575 minutes
2024-05-28 14:38:21,023:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:21,023:INFO:Initializing create_model()
2024-05-28 14:38:21,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:21,023:INFO:Checking exceptions
2024-05-28 14:38:21,023:INFO:Importing libraries
2024-05-28 14:38:21,023:INFO:Copying training dataset
2024-05-28 14:38:21,023:INFO:Defining folds
2024-05-28 14:38:21,023:INFO:Declaring metric variables
2024-05-28 14:38:21,023:INFO:Importing untrained model
2024-05-28 14:38:21,023:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:38:21,023:INFO:Starting cross validation
2024-05-28 14:38:21,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:21,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,223:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,235:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,300:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,303:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,304:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,319:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,480:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,486:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,489:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,508:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,573:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,594:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,594:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,616:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,750:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,781:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:38:21,833:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,855:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:21,866:INFO:Calculating mean and std
2024-05-28 14:38:21,867:INFO:Creating metrics dataframe
2024-05-28 14:38:21,869:INFO:Uploading results into container
2024-05-28 14:38:21,870:INFO:Uploading model into container now
2024-05-28 14:38:21,871:INFO:_master_model_container: 9
2024-05-28 14:38:21,871:INFO:_display_container: 2
2024-05-28 14:38:21,871:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7618)
2024-05-28 14:38:21,871:INFO:create_model() successfully completed......................................
2024-05-28 14:38:22,038:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:22,038:INFO:Creating metrics dataframe
2024-05-28 14:38:22,038:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:38:22,038:INFO:Total runtime is 0.3523292422294617 minutes
2024-05-28 14:38:22,038:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:22,038:INFO:Initializing create_model()
2024-05-28 14:38:22,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:22,038:INFO:Checking exceptions
2024-05-28 14:38:22,038:INFO:Importing libraries
2024-05-28 14:38:22,038:INFO:Copying training dataset
2024-05-28 14:38:22,038:INFO:Defining folds
2024-05-28 14:38:22,038:INFO:Declaring metric variables
2024-05-28 14:38:22,038:INFO:Importing untrained model
2024-05-28 14:38:22,054:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:38:22,054:INFO:Starting cross validation
2024-05-28 14:38:22,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:22,509:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:22,513:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:22,514:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:22,522:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,033:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,074:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,087:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,390:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,405:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,422:INFO:Calculating mean and std
2024-05-28 14:38:23,423:INFO:Creating metrics dataframe
2024-05-28 14:38:23,425:INFO:Uploading results into container
2024-05-28 14:38:23,426:INFO:Uploading model into container now
2024-05-28 14:38:23,426:INFO:_master_model_container: 10
2024-05-28 14:38:23,426:INFO:_display_container: 2
2024-05-28 14:38:23,427:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7618, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:38:23,427:INFO:create_model() successfully completed......................................
2024-05-28 14:38:23,595:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:23,596:INFO:Creating metrics dataframe
2024-05-28 14:38:23,599:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:38:23,599:INFO:Total runtime is 0.37835380633672083 minutes
2024-05-28 14:38:23,599:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:23,599:INFO:Initializing create_model()
2024-05-28 14:38:23,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:23,599:INFO:Checking exceptions
2024-05-28 14:38:23,600:INFO:Importing libraries
2024-05-28 14:38:23,600:INFO:Copying training dataset
2024-05-28 14:38:23,604:INFO:Defining folds
2024-05-28 14:38:23,604:INFO:Declaring metric variables
2024-05-28 14:38:23,604:INFO:Importing untrained model
2024-05-28 14:38:23,604:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:38:23,604:INFO:Starting cross validation
2024-05-28 14:38:23,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:23,885:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,892:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,904:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:23,904:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,163:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,187:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,197:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,197:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,409:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,431:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:24,448:INFO:Calculating mean and std
2024-05-28 14:38:24,448:INFO:Creating metrics dataframe
2024-05-28 14:38:24,448:INFO:Uploading results into container
2024-05-28 14:38:24,448:INFO:Uploading model into container now
2024-05-28 14:38:24,453:INFO:_master_model_container: 11
2024-05-28 14:38:24,453:INFO:_display_container: 2
2024-05-28 14:38:24,453:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:38:24,453:INFO:create_model() successfully completed......................................
2024-05-28 14:38:24,620:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:24,620:INFO:Creating metrics dataframe
2024-05-28 14:38:24,620:INFO:Initializing Extra Trees Classifier
2024-05-28 14:38:24,620:INFO:Total runtime is 0.39535915454228726 minutes
2024-05-28 14:38:24,620:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:24,620:INFO:Initializing create_model()
2024-05-28 14:38:24,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:24,620:INFO:Checking exceptions
2024-05-28 14:38:24,620:INFO:Importing libraries
2024-05-28 14:38:24,620:INFO:Copying training dataset
2024-05-28 14:38:24,620:INFO:Defining folds
2024-05-28 14:38:24,620:INFO:Declaring metric variables
2024-05-28 14:38:24,620:INFO:Importing untrained model
2024-05-28 14:38:24,620:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:38:24,620:INFO:Starting cross validation
2024-05-28 14:38:24,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:25,215:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:25,282:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:25,848:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:25,855:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:25,981:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,041:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,333:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,348:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,364:INFO:Calculating mean and std
2024-05-28 14:38:26,364:INFO:Creating metrics dataframe
2024-05-28 14:38:26,364:INFO:Uploading results into container
2024-05-28 14:38:26,364:INFO:Uploading model into container now
2024-05-28 14:38:26,364:INFO:_master_model_container: 12
2024-05-28 14:38:26,364:INFO:_display_container: 2
2024-05-28 14:38:26,364:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7618, verbose=0,
                     warm_start=False)
2024-05-28 14:38:26,364:INFO:create_model() successfully completed......................................
2024-05-28 14:38:26,578:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:26,578:INFO:Creating metrics dataframe
2024-05-28 14:38:26,583:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:38:26,583:INFO:Total runtime is 0.42807920773824065 minutes
2024-05-28 14:38:26,583:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:26,584:INFO:Initializing create_model()
2024-05-28 14:38:26,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:26,585:INFO:Checking exceptions
2024-05-28 14:38:26,585:INFO:Importing libraries
2024-05-28 14:38:26,585:INFO:Copying training dataset
2024-05-28 14:38:26,593:INFO:Defining folds
2024-05-28 14:38:26,593:INFO:Declaring metric variables
2024-05-28 14:38:26,594:INFO:Importing untrained model
2024-05-28 14:38:26,595:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:38:26,595:INFO:Starting cross validation
2024-05-28 14:38:26,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:26,991:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,991:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:26,991:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,004:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,004:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,005:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,009:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,304:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,304:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,304:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,314:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,314:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,314:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,325:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,550:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,554:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:27,556:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,563:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:27,576:INFO:Calculating mean and std
2024-05-28 14:38:27,576:INFO:Creating metrics dataframe
2024-05-28 14:38:27,576:INFO:Uploading results into container
2024-05-28 14:38:27,576:INFO:Uploading model into container now
2024-05-28 14:38:27,576:INFO:_master_model_container: 13
2024-05-28 14:38:27,576:INFO:_display_container: 2
2024-05-28 14:38:27,584:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:38:27,584:INFO:create_model() successfully completed......................................
2024-05-28 14:38:27,767:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:27,767:INFO:Creating metrics dataframe
2024-05-28 14:38:27,785:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:38:27,785:INFO:Total runtime is 0.4481125712394715 minutes
2024-05-28 14:38:27,785:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:27,786:INFO:Initializing create_model()
2024-05-28 14:38:27,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:27,786:INFO:Checking exceptions
2024-05-28 14:38:27,786:INFO:Importing libraries
2024-05-28 14:38:27,786:INFO:Copying training dataset
2024-05-28 14:38:27,794:INFO:Defining folds
2024-05-28 14:38:27,794:INFO:Declaring metric variables
2024-05-28 14:38:27,794:INFO:Importing untrained model
2024-05-28 14:38:27,795:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:38:27,795:INFO:Starting cross validation
2024-05-28 14:38:27,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:28,240:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,251:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,266:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:28,287:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,297:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:28,307:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,318:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:28,749:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,756:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,758:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:28,758:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:28,833:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:28,842:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:29,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:29,018:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:29,170:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:29,173:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:29,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:29,181:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:29,195:INFO:Calculating mean and std
2024-05-28 14:38:29,198:INFO:Creating metrics dataframe
2024-05-28 14:38:29,201:INFO:Uploading results into container
2024-05-28 14:38:29,202:INFO:Uploading model into container now
2024-05-28 14:38:29,203:INFO:_master_model_container: 14
2024-05-28 14:38:29,203:INFO:_display_container: 2
2024-05-28 14:38:29,204:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7618, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:38:29,204:INFO:create_model() successfully completed......................................
2024-05-28 14:38:29,407:INFO:SubProcess create_model() end ==================================
2024-05-28 14:38:29,408:INFO:Creating metrics dataframe
2024-05-28 14:38:29,411:INFO:Initializing CatBoost Classifier
2024-05-28 14:38:29,411:INFO:Total runtime is 0.47521800597508757 minutes
2024-05-28 14:38:29,411:INFO:SubProcess create_model() called ==================================
2024-05-28 14:38:29,412:INFO:Initializing create_model()
2024-05-28 14:38:29,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:38:29,412:INFO:Checking exceptions
2024-05-28 14:38:29,412:INFO:Importing libraries
2024-05-28 14:38:29,412:INFO:Copying training dataset
2024-05-28 14:38:29,419:INFO:Defining folds
2024-05-28 14:38:29,419:INFO:Declaring metric variables
2024-05-28 14:38:29,419:INFO:Importing untrained model
2024-05-28 14:38:29,420:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:38:29,420:INFO:Starting cross validation
2024-05-28 14:38:29,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:38:37,357:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:37,359:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:37,509:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:37,532:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:37,628:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:37,645:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:38:37,807:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:38:37,808:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:03,622:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:03,622:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:03,655:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:03,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:03,888:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:03,905:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:04,025:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:04,039:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,023:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:10,032:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:10,037:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,037:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,069:INFO:Calculating mean and std
2024-05-28 14:39:10,073:INFO:Creating metrics dataframe
2024-05-28 14:39:10,079:INFO:Uploading results into container
2024-05-28 14:39:10,080:INFO:Uploading model into container now
2024-05-28 14:39:10,082:INFO:_master_model_container: 15
2024-05-28 14:39:10,083:INFO:_display_container: 2
2024-05-28 14:39:10,083:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BB8B33E50>
2024-05-28 14:39:10,083:INFO:create_model() successfully completed......................................
2024-05-28 14:39:10,379:INFO:SubProcess create_model() end ==================================
2024-05-28 14:39:10,379:INFO:Creating metrics dataframe
2024-05-28 14:39:10,388:INFO:Initializing Dummy Classifier
2024-05-28 14:39:10,389:INFO:Total runtime is 1.1581767559051515 minutes
2024-05-28 14:39:10,389:INFO:SubProcess create_model() called ==================================
2024-05-28 14:39:10,390:INFO:Initializing create_model()
2024-05-28 14:39:10,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA681290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:39:10,390:INFO:Checking exceptions
2024-05-28 14:39:10,390:INFO:Importing libraries
2024-05-28 14:39:10,390:INFO:Copying training dataset
2024-05-28 14:39:10,398:INFO:Defining folds
2024-05-28 14:39:10,398:INFO:Declaring metric variables
2024-05-28 14:39:10,398:INFO:Importing untrained model
2024-05-28 14:39:10,398:INFO:Dummy Classifier Imported successfully
2024-05-28 14:39:10,398:INFO:Starting cross validation
2024-05-28 14:39:10,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:39:10,825:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:10,827:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:10,837:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,852:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:10,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:10,889:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,238:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,248:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,258:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,270:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,277:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,277:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,282:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,289:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,547:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,554:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:39:11,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,564:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:39:11,585:INFO:Calculating mean and std
2024-05-28 14:39:11,585:INFO:Creating metrics dataframe
2024-05-28 14:39:11,585:INFO:Uploading results into container
2024-05-28 14:39:11,585:INFO:Uploading model into container now
2024-05-28 14:39:11,585:INFO:_master_model_container: 16
2024-05-28 14:39:11,585:INFO:_display_container: 2
2024-05-28 14:39:11,585:INFO:DummyClassifier(constant=None, random_state=7618, strategy='prior')
2024-05-28 14:39:11,585:INFO:create_model() successfully completed......................................
2024-05-28 14:39:11,807:INFO:SubProcess create_model() end ==================================
2024-05-28 14:39:11,808:INFO:Creating metrics dataframe
2024-05-28 14:39:11,815:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:39:11,818:INFO:Initializing create_model()
2024-05-28 14:39:11,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:39:11,818:INFO:Checking exceptions
2024-05-28 14:39:11,819:INFO:Importing libraries
2024-05-28 14:39:11,819:INFO:Copying training dataset
2024-05-28 14:39:11,826:INFO:Defining folds
2024-05-28 14:39:11,826:INFO:Declaring metric variables
2024-05-28 14:39:11,826:INFO:Importing untrained model
2024-05-28 14:39:11,826:INFO:Declaring custom model
2024-05-28 14:39:11,827:INFO:Logistic Regression Imported successfully
2024-05-28 14:39:11,831:INFO:Cross validation set to False
2024-05-28 14:39:11,831:INFO:Fitting Model
2024-05-28 14:39:12,432:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:39:12,432:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:39:12,432:INFO:create_model() successfully completed......................................
2024-05-28 14:39:12,695:INFO:_master_model_container: 16
2024-05-28 14:39:12,696:INFO:_display_container: 2
2024-05-28 14:39:12,697:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:39:12,697:INFO:compare_models() successfully completed......................................
2024-05-28 14:39:12,761:INFO:Initializing save_model()
2024-05-28 14:39:12,762:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:39:12,762:INFO:Adding model into prep_pipe
2024-05-28 14:39:12,791:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:39:12,854:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7618,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:39:12,854:INFO:save_model() successfully completed......................................
2024-05-28 14:39:13,138:INFO:Initializing plot_model()
2024-05-28 14:39:13,139:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3EC3FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7618, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 14:39:13,139:INFO:Checking exceptions
2024-05-28 14:39:13,140:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 14:39:13,146:INFO:Preloading libraries
2024-05-28 14:39:13,146:INFO:Copying training dataset
2024-05-28 14:39:13,147:INFO:Plot type: feature
2024-05-28 14:39:13,680:INFO:Saving 'Feature Importance.png'
2024-05-28 14:39:13,946:INFO:Visual Rendered Successfully
2024-05-28 14:39:14,129:INFO:plot_model() successfully completed......................................
2024-05-28 14:50:22,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:50:22,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:50:22,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:50:22,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:52:20,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:52:20,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:52:20,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:52:20,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:53:59,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:53:59,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:53:59,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:53:59,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:54:43,610:INFO:PyCaret ClassificationExperiment
2024-05-28 14:54:43,611:INFO:Logging name: clf-default-name
2024-05-28 14:54:43,611:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:54:43,611:INFO:version 3.3.1
2024-05-28 14:54:43,611:INFO:Initializing setup()
2024-05-28 14:54:43,611:INFO:self.USI: 6fdf
2024-05-28 14:54:43,611:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:54:43,612:INFO:Checking environment
2024-05-28 14:54:43,612:INFO:python_version: 3.11.9
2024-05-28 14:54:43,612:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:54:43,612:INFO:machine: AMD64
2024-05-28 14:54:43,612:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:54:43,616:INFO:Memory: svmem(total=8469606400, available=1375272960, percent=83.8, used=7094333440, free=1375272960)
2024-05-28 14:54:43,616:INFO:Physical Core: 2
2024-05-28 14:54:43,616:INFO:Logical Core: 4
2024-05-28 14:54:43,616:INFO:Checking libraries
2024-05-28 14:54:43,616:INFO:System:
2024-05-28 14:54:43,616:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:54:43,616:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:54:43,616:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:54:43,616:INFO:PyCaret required dependencies:
2024-05-28 14:54:43,616:INFO:                 pip: 24.0
2024-05-28 14:54:43,616:INFO:          setuptools: 70.0.0
2024-05-28 14:54:43,616:INFO:             pycaret: 3.3.1
2024-05-28 14:54:43,616:INFO:             IPython: 8.24.0
2024-05-28 14:54:43,616:INFO:          ipywidgets: 8.1.2
2024-05-28 14:54:43,616:INFO:                tqdm: 4.66.4
2024-05-28 14:54:43,616:INFO:               numpy: 1.26.4
2024-05-28 14:54:43,616:INFO:              pandas: 2.1.4
2024-05-28 14:54:43,632:INFO:              jinja2: 3.1.4
2024-05-28 14:54:43,634:INFO:               scipy: 1.11.4
2024-05-28 14:54:43,634:INFO:              joblib: 1.3.2
2024-05-28 14:54:43,634:INFO:             sklearn: 1.4.2
2024-05-28 14:54:43,634:INFO:                pyod: 1.1.3
2024-05-28 14:54:43,634:INFO:            imblearn: 0.12.2
2024-05-28 14:54:43,634:INFO:   category_encoders: 2.6.3
2024-05-28 14:54:43,634:INFO:            lightgbm: 4.3.0
2024-05-28 14:54:43,634:INFO:               numba: 0.58.1
2024-05-28 14:54:43,634:INFO:            requests: 2.32.2
2024-05-28 14:54:43,634:INFO:          matplotlib: 3.7.5
2024-05-28 14:54:43,634:INFO:          scikitplot: 0.3.7
2024-05-28 14:54:43,634:INFO:         yellowbrick: 1.5
2024-05-28 14:54:43,634:INFO:              plotly: 5.22.0
2024-05-28 14:54:43,634:INFO:    plotly-resampler: Not installed
2024-05-28 14:54:43,634:INFO:             kaleido: 0.2.1
2024-05-28 14:54:43,634:INFO:           schemdraw: 0.15
2024-05-28 14:54:43,634:INFO:         statsmodels: 0.14.2
2024-05-28 14:54:43,634:INFO:              sktime: 0.26.0
2024-05-28 14:54:43,634:INFO:               tbats: 1.1.3
2024-05-28 14:54:43,634:INFO:            pmdarima: 2.0.4
2024-05-28 14:54:43,634:INFO:              psutil: 5.9.8
2024-05-28 14:54:43,634:INFO:          markupsafe: 2.1.5
2024-05-28 14:54:43,634:INFO:             pickle5: Not installed
2024-05-28 14:54:43,634:INFO:         cloudpickle: 3.0.0
2024-05-28 14:54:43,634:INFO:         deprecation: 2.1.0
2024-05-28 14:54:43,634:INFO:              xxhash: 3.4.1
2024-05-28 14:54:43,634:INFO:           wurlitzer: 3.1.0
2024-05-28 14:54:43,634:INFO:PyCaret optional dependencies:
2024-05-28 14:54:43,634:INFO:                shap: Not installed
2024-05-28 14:54:43,634:INFO:           interpret: Not installed
2024-05-28 14:54:43,634:INFO:                umap: 0.5.5
2024-05-28 14:54:43,634:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:54:43,634:INFO:  explainerdashboard: Not installed
2024-05-28 14:54:43,634:INFO:             autoviz: Not installed
2024-05-28 14:54:43,634:INFO:           fairlearn: Not installed
2024-05-28 14:54:43,634:INFO:          deepchecks: Not installed
2024-05-28 14:54:43,634:INFO:             xgboost: 2.0.3
2024-05-28 14:54:43,634:INFO:            catboost: 1.2.5
2024-05-28 14:54:43,634:INFO:              kmodes: 0.12.2
2024-05-28 14:54:43,634:INFO:             mlxtend: 0.23.1
2024-05-28 14:54:43,634:INFO:       statsforecast: Not installed
2024-05-28 14:54:43,634:INFO:        tune_sklearn: Not installed
2024-05-28 14:54:43,634:INFO:                 ray: Not installed
2024-05-28 14:54:43,634:INFO:            hyperopt: Not installed
2024-05-28 14:54:43,634:INFO:              optuna: Not installed
2024-05-28 14:54:43,634:INFO:               skopt: Not installed
2024-05-28 14:54:43,634:INFO:              mlflow: 2.13.0
2024-05-28 14:54:43,634:INFO:              gradio: Not installed
2024-05-28 14:54:43,634:INFO:             fastapi: Not installed
2024-05-28 14:54:43,634:INFO:             uvicorn: Not installed
2024-05-28 14:54:43,634:INFO:              m2cgen: Not installed
2024-05-28 14:54:43,649:INFO:           evidently: Not installed
2024-05-28 14:54:43,649:INFO:               fugue: Not installed
2024-05-28 14:54:43,649:INFO:           streamlit: 1.35.0
2024-05-28 14:54:43,650:INFO:             prophet: Not installed
2024-05-28 14:54:43,650:INFO:None
2024-05-28 14:54:43,650:INFO:Set up data.
2024-05-28 14:54:43,675:INFO:Set up folding strategy.
2024-05-28 14:54:43,676:INFO:Set up train/test split.
2024-05-28 14:54:43,699:INFO:Set up index.
2024-05-28 14:54:43,700:INFO:Assigning column types.
2024-05-28 14:54:43,710:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:54:43,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:54:43,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:54:43,950:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:43,967:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:54:44,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:54:44,150:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:44,166:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,167:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:54:44,261:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:54:44,317:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:44,320:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:54:44,416:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:44,433:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,433:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:54:44,550:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:44,550:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,697:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:44,701:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:44,703:INFO:Preparing preprocessing pipeline...
2024-05-28 14:54:44,704:INFO:Set up simple imputation.
2024-05-28 14:54:44,707:INFO:Set up encoding of ordinal features.
2024-05-28 14:54:44,709:INFO:Set up encoding of categorical features.
2024-05-28 14:54:44,710:INFO:Set up removing multicollinearity.
2024-05-28 14:54:44,710:INFO:Set up imbalanced handling.
2024-05-28 14:54:44,923:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:54:44,949:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:54:44,949:INFO:Creating final display dataframe.
2024-05-28 14:54:45,962:INFO:Setup _display_container:                     Description             Value
0                    Session id              4193
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 12)
5   Transformed train set shape         (768, 12)
6    Transformed test set shape         (268, 12)
7               Ignore features                 2
8              Numeric features                 5
9          Categorical features                 4
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              6fdf
2024-05-28 14:54:46,115:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:46,115:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:46,268:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:54:46,275:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:54:46,278:INFO:setup() successfully completed in 2.69s...............
2024-05-28 14:54:46,284:INFO:Initializing compare_models()
2024-05-28 14:54:46,284:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:54:46,285:INFO:Checking exceptions
2024-05-28 14:54:46,293:INFO:Preparing display monitor
2024-05-28 14:54:46,302:INFO:Initializing Logistic Regression
2024-05-28 14:54:46,302:INFO:Total runtime is 0.0 minutes
2024-05-28 14:54:46,302:INFO:SubProcess create_model() called ==================================
2024-05-28 14:54:46,303:INFO:Initializing create_model()
2024-05-28 14:54:46,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:54:46,303:INFO:Checking exceptions
2024-05-28 14:54:46,303:INFO:Importing libraries
2024-05-28 14:54:46,304:INFO:Copying training dataset
2024-05-28 14:54:46,315:INFO:Defining folds
2024-05-28 14:54:46,315:INFO:Declaring metric variables
2024-05-28 14:54:46,315:INFO:Importing untrained model
2024-05-28 14:54:46,315:INFO:Logistic Regression Imported successfully
2024-05-28 14:54:46,315:INFO:Starting cross validation
2024-05-28 14:54:46,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:54:55,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:54:55,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:54:55,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:54:55,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:55:00,518:INFO:Calculating mean and std
2024-05-28 14:55:00,519:INFO:Creating metrics dataframe
2024-05-28 14:55:00,519:INFO:Uploading results into container
2024-05-28 14:55:00,519:INFO:Uploading model into container now
2024-05-28 14:55:00,519:INFO:_master_model_container: 1
2024-05-28 14:55:00,519:INFO:_display_container: 2
2024-05-28 14:55:00,519:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4193, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:55:00,519:INFO:create_model() successfully completed......................................
2024-05-28 14:55:00,804:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:00,804:INFO:Creating metrics dataframe
2024-05-28 14:55:00,804:INFO:Initializing K Neighbors Classifier
2024-05-28 14:55:00,804:INFO:Total runtime is 0.24168996810913085 minutes
2024-05-28 14:55:00,804:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:00,804:INFO:Initializing create_model()
2024-05-28 14:55:00,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:00,804:INFO:Checking exceptions
2024-05-28 14:55:00,804:INFO:Importing libraries
2024-05-28 14:55:00,804:INFO:Copying training dataset
2024-05-28 14:55:00,827:INFO:Defining folds
2024-05-28 14:55:00,827:INFO:Declaring metric variables
2024-05-28 14:55:00,827:INFO:Importing untrained model
2024-05-28 14:55:00,828:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:55:00,829:INFO:Starting cross validation
2024-05-28 14:55:00,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:01,316:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,321:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,335:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,632:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,819:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,836:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,972:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:01,976:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,155:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,186:INFO:Calculating mean and std
2024-05-28 14:55:02,187:INFO:Creating metrics dataframe
2024-05-28 14:55:02,190:INFO:Uploading results into container
2024-05-28 14:55:02,191:INFO:Uploading model into container now
2024-05-28 14:55:02,192:INFO:_master_model_container: 2
2024-05-28 14:55:02,192:INFO:_display_container: 2
2024-05-28 14:55:02,192:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:55:02,193:INFO:create_model() successfully completed......................................
2024-05-28 14:55:02,407:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:02,407:INFO:Creating metrics dataframe
2024-05-28 14:55:02,415:INFO:Initializing Naive Bayes
2024-05-28 14:55:02,415:INFO:Total runtime is 0.26854708592096965 minutes
2024-05-28 14:55:02,416:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:02,416:INFO:Initializing create_model()
2024-05-28 14:55:02,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:02,417:INFO:Checking exceptions
2024-05-28 14:55:02,417:INFO:Importing libraries
2024-05-28 14:55:02,417:INFO:Copying training dataset
2024-05-28 14:55:02,417:INFO:Defining folds
2024-05-28 14:55:02,417:INFO:Declaring metric variables
2024-05-28 14:55:02,417:INFO:Importing untrained model
2024-05-28 14:55:02,417:INFO:Naive Bayes Imported successfully
2024-05-28 14:55:02,417:INFO:Starting cross validation
2024-05-28 14:55:02,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:02,776:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,801:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,810:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:02,837:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,122:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,204:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,500:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,557:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:03,582:INFO:Calculating mean and std
2024-05-28 14:55:03,587:INFO:Creating metrics dataframe
2024-05-28 14:55:03,590:INFO:Uploading results into container
2024-05-28 14:55:03,591:INFO:Uploading model into container now
2024-05-28 14:55:03,593:INFO:_master_model_container: 3
2024-05-28 14:55:03,593:INFO:_display_container: 2
2024-05-28 14:55:03,593:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:55:03,594:INFO:create_model() successfully completed......................................
2024-05-28 14:55:03,833:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:03,833:INFO:Creating metrics dataframe
2024-05-28 14:55:03,850:INFO:Initializing Decision Tree Classifier
2024-05-28 14:55:03,850:INFO:Total runtime is 0.292461363474528 minutes
2024-05-28 14:55:03,850:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:03,850:INFO:Initializing create_model()
2024-05-28 14:55:03,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:03,850:INFO:Checking exceptions
2024-05-28 14:55:03,850:INFO:Importing libraries
2024-05-28 14:55:03,850:INFO:Copying training dataset
2024-05-28 14:55:03,868:INFO:Defining folds
2024-05-28 14:55:03,868:INFO:Declaring metric variables
2024-05-28 14:55:03,868:INFO:Importing untrained model
2024-05-28 14:55:03,868:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:55:03,868:INFO:Starting cross validation
2024-05-28 14:55:03,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:04,393:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:04,413:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:04,470:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:04,516:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,044:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,059:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,121:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,379:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,391:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:05,417:INFO:Calculating mean and std
2024-05-28 14:55:05,418:INFO:Creating metrics dataframe
2024-05-28 14:55:05,418:INFO:Uploading results into container
2024-05-28 14:55:05,418:INFO:Uploading model into container now
2024-05-28 14:55:05,418:INFO:_master_model_container: 4
2024-05-28 14:55:05,418:INFO:_display_container: 2
2024-05-28 14:55:05,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4193, splitter='best')
2024-05-28 14:55:05,418:INFO:create_model() successfully completed......................................
2024-05-28 14:55:05,632:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:05,632:INFO:Creating metrics dataframe
2024-05-28 14:55:05,632:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:55:05,632:INFO:Total runtime is 0.3221639076868693 minutes
2024-05-28 14:55:05,632:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:05,632:INFO:Initializing create_model()
2024-05-28 14:55:05,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:05,632:INFO:Checking exceptions
2024-05-28 14:55:05,632:INFO:Importing libraries
2024-05-28 14:55:05,648:INFO:Copying training dataset
2024-05-28 14:55:05,659:INFO:Defining folds
2024-05-28 14:55:05,660:INFO:Declaring metric variables
2024-05-28 14:55:05,660:INFO:Importing untrained model
2024-05-28 14:55:05,661:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:55:05,662:INFO:Starting cross validation
2024-05-28 14:55:05,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:06,871:INFO:Calculating mean and std
2024-05-28 14:55:06,873:INFO:Creating metrics dataframe
2024-05-28 14:55:06,877:INFO:Uploading results into container
2024-05-28 14:55:06,883:INFO:Uploading model into container now
2024-05-28 14:55:06,884:INFO:_master_model_container: 5
2024-05-28 14:55:06,884:INFO:_display_container: 2
2024-05-28 14:55:06,886:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4193, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:55:06,886:INFO:create_model() successfully completed......................................
2024-05-28 14:55:07,098:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:07,098:INFO:Creating metrics dataframe
2024-05-28 14:55:07,098:INFO:Initializing Ridge Classifier
2024-05-28 14:55:07,098:INFO:Total runtime is 0.3465938131014506 minutes
2024-05-28 14:55:07,098:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:07,098:INFO:Initializing create_model()
2024-05-28 14:55:07,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:07,098:INFO:Checking exceptions
2024-05-28 14:55:07,098:INFO:Importing libraries
2024-05-28 14:55:07,098:INFO:Copying training dataset
2024-05-28 14:55:07,122:INFO:Defining folds
2024-05-28 14:55:07,122:INFO:Declaring metric variables
2024-05-28 14:55:07,122:INFO:Importing untrained model
2024-05-28 14:55:07,123:INFO:Ridge Classifier Imported successfully
2024-05-28 14:55:07,124:INFO:Starting cross validation
2024-05-28 14:55:07,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:08,407:INFO:Calculating mean and std
2024-05-28 14:55:08,407:INFO:Creating metrics dataframe
2024-05-28 14:55:08,413:INFO:Uploading results into container
2024-05-28 14:55:08,414:INFO:Uploading model into container now
2024-05-28 14:55:08,415:INFO:_master_model_container: 6
2024-05-28 14:55:08,416:INFO:_display_container: 2
2024-05-28 14:55:08,416:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4193, solver='auto',
                tol=0.0001)
2024-05-28 14:55:08,417:INFO:create_model() successfully completed......................................
2024-05-28 14:55:08,630:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:08,630:INFO:Creating metrics dataframe
2024-05-28 14:55:08,647:INFO:Initializing Random Forest Classifier
2024-05-28 14:55:08,648:INFO:Total runtime is 0.3724350174268087 minutes
2024-05-28 14:55:08,648:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:08,649:INFO:Initializing create_model()
2024-05-28 14:55:08,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:08,649:INFO:Checking exceptions
2024-05-28 14:55:08,649:INFO:Importing libraries
2024-05-28 14:55:08,649:INFO:Copying training dataset
2024-05-28 14:55:08,658:INFO:Defining folds
2024-05-28 14:55:08,658:INFO:Declaring metric variables
2024-05-28 14:55:08,658:INFO:Importing untrained model
2024-05-28 14:55:08,659:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:55:08,659:INFO:Starting cross validation
2024-05-28 14:55:08,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:09,597:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:09,597:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:09,607:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:09,939:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:10,403:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:10,412:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:10,550:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:10,889:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:11,024:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:11,025:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:11,052:INFO:Calculating mean and std
2024-05-28 14:55:11,053:INFO:Creating metrics dataframe
2024-05-28 14:55:11,056:INFO:Uploading results into container
2024-05-28 14:55:11,057:INFO:Uploading model into container now
2024-05-28 14:55:11,058:INFO:_master_model_container: 7
2024-05-28 14:55:11,058:INFO:_display_container: 2
2024-05-28 14:55:11,059:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4193, verbose=0,
                       warm_start=False)
2024-05-28 14:55:11,059:INFO:create_model() successfully completed......................................
2024-05-28 14:55:11,243:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:11,243:INFO:Creating metrics dataframe
2024-05-28 14:55:11,243:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:55:11,243:INFO:Total runtime is 0.4156868894894918 minutes
2024-05-28 14:55:11,243:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:11,243:INFO:Initializing create_model()
2024-05-28 14:55:11,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:11,243:INFO:Checking exceptions
2024-05-28 14:55:11,243:INFO:Importing libraries
2024-05-28 14:55:11,243:INFO:Copying training dataset
2024-05-28 14:55:11,263:INFO:Defining folds
2024-05-28 14:55:11,263:INFO:Declaring metric variables
2024-05-28 14:55:11,264:INFO:Importing untrained model
2024-05-28 14:55:11,264:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:55:11,264:INFO:Starting cross validation
2024-05-28 14:55:11,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:11,470:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,481:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,496:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,496:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,732:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,750:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,778:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:11,780:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:12,030:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:12,044:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:55:12,116:INFO:Calculating mean and std
2024-05-28 14:55:12,116:INFO:Creating metrics dataframe
2024-05-28 14:55:12,116:INFO:Uploading results into container
2024-05-28 14:55:12,116:INFO:Uploading model into container now
2024-05-28 14:55:12,116:INFO:_master_model_container: 8
2024-05-28 14:55:12,116:INFO:_display_container: 2
2024-05-28 14:55:12,116:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:55:12,116:INFO:create_model() successfully completed......................................
2024-05-28 14:55:12,293:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:12,293:INFO:Creating metrics dataframe
2024-05-28 14:55:12,293:INFO:Initializing Ada Boost Classifier
2024-05-28 14:55:12,293:INFO:Total runtime is 0.4331870953241984 minutes
2024-05-28 14:55:12,293:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:12,293:INFO:Initializing create_model()
2024-05-28 14:55:12,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:12,293:INFO:Checking exceptions
2024-05-28 14:55:12,293:INFO:Importing libraries
2024-05-28 14:55:12,293:INFO:Copying training dataset
2024-05-28 14:55:12,315:INFO:Defining folds
2024-05-28 14:55:12,315:INFO:Declaring metric variables
2024-05-28 14:55:12,315:INFO:Importing untrained model
2024-05-28 14:55:12,316:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:55:12,316:INFO:Starting cross validation
2024-05-28 14:55:12,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:12,549:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:12,548:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:12,594:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:12,604:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,088:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,130:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,143:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,193:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,666:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,697:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:55:13,922:INFO:Calculating mean and std
2024-05-28 14:55:13,923:INFO:Creating metrics dataframe
2024-05-28 14:55:13,925:INFO:Uploading results into container
2024-05-28 14:55:13,925:INFO:Uploading model into container now
2024-05-28 14:55:13,925:INFO:_master_model_container: 9
2024-05-28 14:55:13,925:INFO:_display_container: 2
2024-05-28 14:55:13,925:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4193)
2024-05-28 14:55:13,925:INFO:create_model() successfully completed......................................
2024-05-28 14:55:14,107:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:14,107:INFO:Creating metrics dataframe
2024-05-28 14:55:14,110:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:55:14,110:INFO:Total runtime is 0.46347113450368244 minutes
2024-05-28 14:55:14,111:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:14,111:INFO:Initializing create_model()
2024-05-28 14:55:14,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:14,111:INFO:Checking exceptions
2024-05-28 14:55:14,111:INFO:Importing libraries
2024-05-28 14:55:14,111:INFO:Copying training dataset
2024-05-28 14:55:14,116:INFO:Defining folds
2024-05-28 14:55:14,116:INFO:Declaring metric variables
2024-05-28 14:55:14,116:INFO:Importing untrained model
2024-05-28 14:55:14,117:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:55:14,117:INFO:Starting cross validation
2024-05-28 14:55:14,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:16,112:INFO:Calculating mean and std
2024-05-28 14:55:16,113:INFO:Creating metrics dataframe
2024-05-28 14:55:16,115:INFO:Uploading results into container
2024-05-28 14:55:16,116:INFO:Uploading model into container now
2024-05-28 14:55:16,116:INFO:_master_model_container: 10
2024-05-28 14:55:16,116:INFO:_display_container: 2
2024-05-28 14:55:16,117:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4193, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:55:16,117:INFO:create_model() successfully completed......................................
2024-05-28 14:55:16,317:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:16,318:INFO:Creating metrics dataframe
2024-05-28 14:55:16,321:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:55:16,321:INFO:Total runtime is 0.5003097454706827 minutes
2024-05-28 14:55:16,322:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:16,322:INFO:Initializing create_model()
2024-05-28 14:55:16,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:16,323:INFO:Checking exceptions
2024-05-28 14:55:16,323:INFO:Importing libraries
2024-05-28 14:55:16,323:INFO:Copying training dataset
2024-05-28 14:55:16,332:INFO:Defining folds
2024-05-28 14:55:16,332:INFO:Declaring metric variables
2024-05-28 14:55:16,332:INFO:Importing untrained model
2024-05-28 14:55:16,332:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:55:16,333:INFO:Starting cross validation
2024-05-28 14:55:16,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:17,139:INFO:Calculating mean and std
2024-05-28 14:55:17,139:INFO:Creating metrics dataframe
2024-05-28 14:55:17,139:INFO:Uploading results into container
2024-05-28 14:55:17,139:INFO:Uploading model into container now
2024-05-28 14:55:17,139:INFO:_master_model_container: 11
2024-05-28 14:55:17,139:INFO:_display_container: 2
2024-05-28 14:55:17,139:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:55:17,139:INFO:create_model() successfully completed......................................
2024-05-28 14:55:17,338:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:17,338:INFO:Creating metrics dataframe
2024-05-28 14:55:17,357:INFO:Initializing Extra Trees Classifier
2024-05-28 14:55:17,357:INFO:Total runtime is 0.5175764838854472 minutes
2024-05-28 14:55:17,357:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:17,357:INFO:Initializing create_model()
2024-05-28 14:55:17,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:17,357:INFO:Checking exceptions
2024-05-28 14:55:17,357:INFO:Importing libraries
2024-05-28 14:55:17,358:INFO:Copying training dataset
2024-05-28 14:55:17,363:INFO:Defining folds
2024-05-28 14:55:17,363:INFO:Declaring metric variables
2024-05-28 14:55:17,363:INFO:Importing untrained model
2024-05-28 14:55:17,364:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:55:17,364:INFO:Starting cross validation
2024-05-28 14:55:17,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:17,958:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:17,962:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:17,972:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:18,082:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:18,630:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:18,641:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:18,742:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:18,762:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,146:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,171:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,187:INFO:Calculating mean and std
2024-05-28 14:55:19,188:INFO:Creating metrics dataframe
2024-05-28 14:55:19,190:INFO:Uploading results into container
2024-05-28 14:55:19,191:INFO:Uploading model into container now
2024-05-28 14:55:19,191:INFO:_master_model_container: 12
2024-05-28 14:55:19,191:INFO:_display_container: 2
2024-05-28 14:55:19,192:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4193, verbose=0,
                     warm_start=False)
2024-05-28 14:55:19,192:INFO:create_model() successfully completed......................................
2024-05-28 14:55:19,381:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:19,381:INFO:Creating metrics dataframe
2024-05-28 14:55:19,387:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:55:19,387:INFO:Total runtime is 0.5514090259869894 minutes
2024-05-28 14:55:19,388:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:19,388:INFO:Initializing create_model()
2024-05-28 14:55:19,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:19,388:INFO:Checking exceptions
2024-05-28 14:55:19,388:INFO:Importing libraries
2024-05-28 14:55:19,388:INFO:Copying training dataset
2024-05-28 14:55:19,393:INFO:Defining folds
2024-05-28 14:55:19,394:INFO:Declaring metric variables
2024-05-28 14:55:19,394:INFO:Importing untrained model
2024-05-28 14:55:19,396:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:55:19,396:INFO:Starting cross validation
2024-05-28 14:55:19,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:19,805:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,805:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,823:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:19,848:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,126:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,126:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,137:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,425:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,427:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:20,443:INFO:Calculating mean and std
2024-05-28 14:55:20,444:INFO:Creating metrics dataframe
2024-05-28 14:55:20,446:INFO:Uploading results into container
2024-05-28 14:55:20,447:INFO:Uploading model into container now
2024-05-28 14:55:20,447:INFO:_master_model_container: 13
2024-05-28 14:55:20,447:INFO:_display_container: 2
2024-05-28 14:55:20,448:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:55:20,448:INFO:create_model() successfully completed......................................
2024-05-28 14:55:20,623:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:20,623:INFO:Creating metrics dataframe
2024-05-28 14:55:20,626:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:55:20,626:INFO:Total runtime is 0.5720598101615906 minutes
2024-05-28 14:55:20,626:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:20,627:INFO:Initializing create_model()
2024-05-28 14:55:20,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:20,627:INFO:Checking exceptions
2024-05-28 14:55:20,627:INFO:Importing libraries
2024-05-28 14:55:20,627:INFO:Copying training dataset
2024-05-28 14:55:20,633:INFO:Defining folds
2024-05-28 14:55:20,633:INFO:Declaring metric variables
2024-05-28 14:55:20,634:INFO:Importing untrained model
2024-05-28 14:55:20,636:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:55:20,636:INFO:Starting cross validation
2024-05-28 14:55:20,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:21,429:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:21,464:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:21,484:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:22,065:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:22,751:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:22,762:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:22,828:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:23,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:23,385:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:23,405:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:23,429:INFO:Calculating mean and std
2024-05-28 14:55:23,429:INFO:Creating metrics dataframe
2024-05-28 14:55:23,434:INFO:Uploading results into container
2024-05-28 14:55:23,434:INFO:Uploading model into container now
2024-05-28 14:55:23,434:INFO:_master_model_container: 14
2024-05-28 14:55:23,434:INFO:_display_container: 2
2024-05-28 14:55:23,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4193, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:55:23,434:INFO:create_model() successfully completed......................................
2024-05-28 14:55:23,669:INFO:SubProcess create_model() end ==================================
2024-05-28 14:55:23,669:INFO:Creating metrics dataframe
2024-05-28 14:55:23,683:INFO:Initializing CatBoost Classifier
2024-05-28 14:55:23,684:INFO:Total runtime is 0.6230290293693542 minutes
2024-05-28 14:55:23,685:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:23,685:INFO:Initializing create_model()
2024-05-28 14:55:23,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:23,685:INFO:Checking exceptions
2024-05-28 14:55:23,685:INFO:Importing libraries
2024-05-28 14:55:23,685:INFO:Copying training dataset
2024-05-28 14:55:23,685:INFO:Defining folds
2024-05-28 14:55:23,685:INFO:Declaring metric variables
2024-05-28 14:55:23,685:INFO:Importing untrained model
2024-05-28 14:55:23,685:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:55:23,685:INFO:Starting cross validation
2024-05-28 14:55:23,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:55:28,944:INFO:PyCaret ClassificationExperiment
2024-05-28 14:55:28,947:INFO:Logging name: clf-default-name
2024-05-28 14:55:28,949:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:55:28,950:INFO:version 3.3.1
2024-05-28 14:55:28,951:INFO:Initializing setup()
2024-05-28 14:55:28,953:INFO:self.USI: 3ad2
2024-05-28 14:55:28,954:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:55:28,956:INFO:Checking environment
2024-05-28 14:55:28,957:INFO:python_version: 3.11.9
2024-05-28 14:55:29,250:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:55:29,259:INFO:machine: AMD64
2024-05-28 14:55:29,261:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:55:29,284:INFO:Memory: svmem(total=8469606400, available=1097560064, percent=87.0, used=7372046336, free=1097560064)
2024-05-28 14:55:29,286:INFO:Physical Core: 2
2024-05-28 14:55:29,288:INFO:Logical Core: 4
2024-05-28 14:55:29,290:INFO:Checking libraries
2024-05-28 14:55:29,292:INFO:System:
2024-05-28 14:55:29,458:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:55:29,460:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:55:29,475:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:55:29,477:INFO:PyCaret required dependencies:
2024-05-28 14:55:29,481:INFO:                 pip: 24.0
2024-05-28 14:55:29,483:INFO:          setuptools: 70.0.0
2024-05-28 14:55:29,483:INFO:             pycaret: 3.3.1
2024-05-28 14:55:29,484:INFO:             IPython: 8.24.0
2024-05-28 14:55:29,487:INFO:          ipywidgets: 8.1.2
2024-05-28 14:55:29,487:INFO:                tqdm: 4.66.4
2024-05-28 14:55:29,488:INFO:               numpy: 1.26.4
2024-05-28 14:55:29,491:INFO:              pandas: 2.1.4
2024-05-28 14:55:29,493:INFO:              jinja2: 3.1.4
2024-05-28 14:55:29,496:INFO:               scipy: 1.11.4
2024-05-28 14:55:29,497:INFO:              joblib: 1.3.2
2024-05-28 14:55:29,498:INFO:             sklearn: 1.4.2
2024-05-28 14:55:29,499:INFO:                pyod: 1.1.3
2024-05-28 14:55:29,500:INFO:            imblearn: 0.12.2
2024-05-28 14:55:29,500:INFO:   category_encoders: 2.6.3
2024-05-28 14:55:29,501:INFO:            lightgbm: 4.3.0
2024-05-28 14:55:29,502:INFO:               numba: 0.58.1
2024-05-28 14:55:29,503:INFO:            requests: 2.32.2
2024-05-28 14:55:29,504:INFO:          matplotlib: 3.7.5
2024-05-28 14:55:29,505:INFO:          scikitplot: 0.3.7
2024-05-28 14:55:29,506:INFO:         yellowbrick: 1.5
2024-05-28 14:55:29,507:INFO:              plotly: 5.22.0
2024-05-28 14:55:29,508:INFO:    plotly-resampler: Not installed
2024-05-28 14:55:29,600:INFO:             kaleido: 0.2.1
2024-05-28 14:55:29,602:INFO:           schemdraw: 0.15
2024-05-28 14:55:29,604:INFO:         statsmodels: 0.14.2
2024-05-28 14:55:29,605:INFO:              sktime: 0.26.0
2024-05-28 14:55:29,606:INFO:               tbats: 1.1.3
2024-05-28 14:55:29,607:INFO:            pmdarima: 2.0.4
2024-05-28 14:55:29,608:INFO:              psutil: 5.9.8
2024-05-28 14:55:29,608:INFO:          markupsafe: 2.1.5
2024-05-28 14:55:29,609:INFO:             pickle5: Not installed
2024-05-28 14:55:29,610:INFO:         cloudpickle: 3.0.0
2024-05-28 14:55:29,613:INFO:         deprecation: 2.1.0
2024-05-28 14:55:29,614:INFO:              xxhash: 3.4.1
2024-05-28 14:55:29,615:INFO:           wurlitzer: 3.1.0
2024-05-28 14:55:29,616:INFO:PyCaret optional dependencies:
2024-05-28 14:55:29,617:INFO:                shap: Not installed
2024-05-28 14:55:29,618:INFO:           interpret: Not installed
2024-05-28 14:55:29,619:INFO:                umap: 0.5.5
2024-05-28 14:55:29,620:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:55:29,621:INFO:  explainerdashboard: Not installed
2024-05-28 14:55:29,621:INFO:             autoviz: Not installed
2024-05-28 14:55:29,622:INFO:           fairlearn: Not installed
2024-05-28 14:55:29,623:INFO:          deepchecks: Not installed
2024-05-28 14:55:29,624:INFO:             xgboost: 2.0.3
2024-05-28 14:55:29,625:INFO:            catboost: 1.2.5
2024-05-28 14:55:29,627:INFO:              kmodes: 0.12.2
2024-05-28 14:55:29,629:INFO:             mlxtend: 0.23.1
2024-05-28 14:55:29,630:INFO:       statsforecast: Not installed
2024-05-28 14:55:29,632:INFO:        tune_sklearn: Not installed
2024-05-28 14:55:29,633:INFO:                 ray: Not installed
2024-05-28 14:55:29,634:INFO:            hyperopt: Not installed
2024-05-28 14:55:29,749:INFO:              optuna: Not installed
2024-05-28 14:55:29,750:INFO:               skopt: Not installed
2024-05-28 14:55:29,751:INFO:              mlflow: 2.13.0
2024-05-28 14:55:29,752:INFO:              gradio: Not installed
2024-05-28 14:55:29,753:INFO:             fastapi: Not installed
2024-05-28 14:55:29,754:INFO:             uvicorn: Not installed
2024-05-28 14:55:29,755:INFO:              m2cgen: Not installed
2024-05-28 14:55:29,755:INFO:           evidently: Not installed
2024-05-28 14:55:29,756:INFO:               fugue: Not installed
2024-05-28 14:55:29,757:INFO:           streamlit: 1.35.0
2024-05-28 14:55:29,758:INFO:             prophet: Not installed
2024-05-28 14:55:29,758:INFO:None
2024-05-28 14:55:29,759:INFO:Set up data.
2024-05-28 14:55:30,023:INFO:Set up folding strategy.
2024-05-28 14:55:30,024:INFO:Set up train/test split.
2024-05-28 14:55:30,270:INFO:Set up index.
2024-05-28 14:55:30,273:INFO:Assigning column types.
2024-05-28 14:55:30,416:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:55:33,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:55:33,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:55:35,456:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:35,630:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:38,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:55:38,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:55:40,246:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:40,409:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:40,432:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:55:42,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:55:43,000:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:43,043:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:43,421:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:55:43,662:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:43,681:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:43,703:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:55:44,259:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:44,275:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:44,796:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:44,811:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:44,820:INFO:Preparing preprocessing pipeline...
2024-05-28 14:55:44,820:INFO:Set up simple imputation.
2024-05-28 14:55:44,850:INFO:Set up encoding of ordinal features.
2024-05-28 14:55:44,856:INFO:Set up encoding of categorical features.
2024-05-28 14:55:44,856:INFO:Set up removing multicollinearity.
2024-05-28 14:55:44,856:INFO:Set up imbalanced handling.
2024-05-28 14:55:45,718:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:55:46,766:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:55:46,766:INFO:Creating final display dataframe.
2024-05-28 14:55:51,504:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py:287: UserWarning: Persisting input arguments took 4.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-28 14:55:53,995:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py:287: UserWarning: Persisting input arguments took 1.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-28 14:55:55,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:55,866:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:56,152:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:56,291:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:55:57,262:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py:287: UserWarning: Persisting input arguments took 2.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-28 14:55:57,411:INFO:Setup _display_container:                     Description             Value
0                    Session id              2867
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 11)
5   Transformed train set shape         (768, 11)
6    Transformed test set shape         (268, 11)
7               Ignore features                 3
8              Numeric features                 5
9          Categorical features                 3
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              3ad2
2024-05-28 14:55:57,426:INFO:                    Description             Value
2024-05-28 14:55:57,426:INFO:0                    Session id              2867
2024-05-28 14:55:57,427:INFO:1                        Target          Survived
2024-05-28 14:55:57,427:INFO:2                   Target type            Binary
2024-05-28 14:55:57,427:INFO:3           Original data shape         (891, 12)
2024-05-28 14:55:57,428:INFO:4        Transformed data shape        (1036, 11)
2024-05-28 14:55:57,428:INFO:5   Transformed train set shape         (768, 11)
2024-05-28 14:55:57,428:INFO:6    Transformed test set shape         (268, 11)
2024-05-28 14:55:57,428:INFO:7               Ignore features                 3
2024-05-28 14:55:57,428:INFO:8              Numeric features                 5
2024-05-28 14:55:57,429:INFO:9          Categorical features                 3
2024-05-28 14:55:57,429:INFO:10     Rows with missing values             79.5%
2024-05-28 14:55:57,429:INFO:11                   Preprocess              True
2024-05-28 14:55:57,429:INFO:12              Imputation type            simple
2024-05-28 14:55:57,429:INFO:13           Numeric imputation              mean
2024-05-28 14:55:57,429:INFO:14       Categorical imputation              mode
2024-05-28 14:55:57,430:INFO:15     Maximum one-hot encoding                25
2024-05-28 14:55:57,430:INFO:16              Encoding method              None
2024-05-28 14:55:57,430:INFO:17     Remove multicollinearity              True
2024-05-28 14:55:57,430:INFO:18  Multicollinearity threshold               0.9
2024-05-28 14:55:57,431:INFO:19                Fix imbalance              True
2024-05-28 14:55:57,431:INFO:20         Fix imbalance method             SMOTE
2024-05-28 14:55:57,431:INFO:21               Fold Generator   StratifiedKFold
2024-05-28 14:55:57,431:INFO:22                  Fold Number                10
2024-05-28 14:55:57,431:INFO:23                     CPU Jobs                -1
2024-05-28 14:55:57,431:INFO:24                      Use GPU             False
2024-05-28 14:55:57,432:INFO:25               Log Experiment             False
2024-05-28 14:55:57,432:INFO:26              Experiment Name  clf-default-name
2024-05-28 14:55:57,432:INFO:27                          USI              3ad2
2024-05-28 14:55:57,974:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:57,986:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:58,626:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:55:58,639:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:55:58,643:INFO:setup() successfully completed in 30.69s...............
2024-05-28 14:55:58,725:INFO:Initializing compare_models()
2024-05-28 14:55:58,725:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:55:58,726:INFO:Checking exceptions
2024-05-28 14:55:58,738:INFO:Preparing display monitor
2024-05-28 14:55:58,746:WARNING:
2024-05-28 14:55:58,747:WARNING:Processing:   0%|                                                                      | 0/69 [00:00<?, ?it/s]
2024-05-28 14:55:58,747:WARNING:[A
2024-05-28 14:55:58,748:INFO:Initializing Logistic Regression
2024-05-28 14:55:58,748:INFO:Total runtime is 0.0 minutes
2024-05-28 14:55:58,749:INFO:SubProcess create_model() called ==================================
2024-05-28 14:55:58,750:INFO:Initializing create_model()
2024-05-28 14:55:58,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:55:58,750:INFO:Checking exceptions
2024-05-28 14:55:58,750:INFO:Importing libraries
2024-05-28 14:55:58,751:INFO:Copying training dataset
2024-05-28 14:55:58,819:INFO:Defining folds
2024-05-28 14:55:58,820:INFO:Declaring metric variables
2024-05-28 14:55:58,821:INFO:Importing untrained model
2024-05-28 14:55:58,822:INFO:Logistic Regression Imported successfully
2024-05-28 14:55:58,823:INFO:Starting cross validation
2024-05-28 14:55:58,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:08,832:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:09,001:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:09,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:09,336:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:12,693:INFO:Calculating mean and std
2024-05-28 14:56:12,693:WARNING:
2024-05-28 14:56:12,693:WARNING:Processing:   7%|####4                                                         | 5/69 [00:13<02:58,  2.79s/it]
2024-05-28 14:56:12,693:WARNING:[A
2024-05-28 14:56:12,693:INFO:Creating metrics dataframe
2024-05-28 14:56:12,693:INFO:Uploading results into container
2024-05-28 14:56:12,693:INFO:Uploading model into container now
2024-05-28 14:56:12,693:INFO:_master_model_container: 1
2024-05-28 14:56:12,693:INFO:_display_container: 2
2024-05-28 14:56:12,693:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2867, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:56:12,702:INFO:create_model() successfully completed......................................
2024-05-28 14:56:13,066:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:13,066:INFO:Creating metrics dataframe
2024-05-28 14:56:13,074:INFO:Initializing K Neighbors Classifier
2024-05-28 14:56:13,075:INFO:Total runtime is 0.23879660765329996 minutes
2024-05-28 14:56:13,076:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:13,076:INFO:Initializing create_model()
2024-05-28 14:56:13,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:13,076:INFO:Checking exceptions
2024-05-28 14:56:13,079:INFO:Importing libraries
2024-05-28 14:56:13,079:INFO:Copying training dataset
2024-05-28 14:56:13,094:WARNING:
2024-05-28 14:56:13,095:WARNING:Processing:  10%|######2                                                       | 7/69 [00:14<01:54,  1.85s/it]
2024-05-28 14:56:13,095:WARNING:[A
2024-05-28 14:56:13,095:INFO:Defining folds
2024-05-28 14:56:13,099:INFO:Declaring metric variables
2024-05-28 14:56:13,100:INFO:Importing untrained model
2024-05-28 14:56:13,100:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:56:13,101:INFO:Starting cross validation
2024-05-28 14:56:13,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:13,556:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:13,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:14,977:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:14,987:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:16,080:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:16,080:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:16,864:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:16,909:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:17,623:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:17,695:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:17,741:INFO:Calculating mean and std
2024-05-28 14:56:17,742:WARNING:
2024-05-28 14:56:17,742:WARNING:Processing:  13%|########                                                      | 9/69 [00:18<02:00,  2.01s/it]
2024-05-28 14:56:17,743:WARNING:[A
2024-05-28 14:56:17,743:INFO:Creating metrics dataframe
2024-05-28 14:56:17,747:INFO:Uploading results into container
2024-05-28 14:56:17,748:INFO:Uploading model into container now
2024-05-28 14:56:17,749:INFO:_master_model_container: 2
2024-05-28 14:56:17,750:INFO:_display_container: 2
2024-05-28 14:56:17,750:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:56:17,751:INFO:create_model() successfully completed......................................
2024-05-28 14:56:18,124:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:18,124:INFO:Creating metrics dataframe
2024-05-28 14:56:18,124:INFO:Initializing Naive Bayes
2024-05-28 14:56:18,124:INFO:Total runtime is 0.32293937603632605 minutes
2024-05-28 14:56:18,124:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:18,124:INFO:Initializing create_model()
2024-05-28 14:56:18,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:18,124:INFO:Checking exceptions
2024-05-28 14:56:18,124:INFO:Importing libraries
2024-05-28 14:56:18,124:INFO:Copying training dataset
2024-05-28 14:56:18,151:WARNING:
2024-05-28 14:56:18,152:WARNING:Processing:  16%|#########7                                                   | 11/69 [00:19<01:22,  1.42s/it]
2024-05-28 14:56:18,152:WARNING:[A
2024-05-28 14:56:18,153:INFO:Defining folds
2024-05-28 14:56:18,153:INFO:Declaring metric variables
2024-05-28 14:56:18,154:INFO:Importing untrained model
2024-05-28 14:56:18,155:INFO:Naive Bayes Imported successfully
2024-05-28 14:56:18,156:INFO:Starting cross validation
2024-05-28 14:56:18,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:18,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:18,547:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:18,889:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:18,971:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:19,466:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:19,564:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:19,631:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:19,820:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:19,942:INFO:Calculating mean and std
2024-05-28 14:56:20,094:INFO:Creating metrics dataframe
2024-05-28 14:56:20,247:INFO:Uploading results into container
2024-05-28 14:56:20,248:INFO:Uploading model into container now
2024-05-28 14:56:20,248:INFO:_master_model_container: 15
2024-05-28 14:56:20,249:INFO:_display_container: 2
2024-05-28 14:56:20,249:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCB409490>
2024-05-28 14:56:20,249:INFO:create_model() successfully completed......................................
2024-05-28 14:56:20,307:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:20,383:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:20,432:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:20,579:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:20,771:INFO:Calculating mean and std
2024-05-28 14:56:20,772:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:20,773:WARNING:
2024-05-28 14:56:20,774:INFO:Creating metrics dataframe
2024-05-28 14:56:20,775:WARNING:Processing:  19%|###########4                                                 | 13/69 [00:22<01:17,  1.38s/it]
2024-05-28 14:56:20,784:INFO:Initializing Dummy Classifier
2024-05-28 14:56:20,784:WARNING:[A
2024-05-28 14:56:20,784:INFO:Total runtime is 1.5746997316678364 minutes
2024-05-28 14:56:20,785:INFO:Creating metrics dataframe
2024-05-28 14:56:20,785:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:20,791:INFO:Uploading results into container
2024-05-28 14:56:20,792:INFO:Initializing create_model()
2024-05-28 14:56:20,793:INFO:Uploading model into container now
2024-05-28 14:56:20,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA69EE10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:20,795:INFO:_master_model_container: 3
2024-05-28 14:56:20,795:INFO:Checking exceptions
2024-05-28 14:56:20,795:INFO:_display_container: 2
2024-05-28 14:56:20,796:INFO:Importing libraries
2024-05-28 14:56:20,796:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:56:20,796:INFO:Copying training dataset
2024-05-28 14:56:20,797:INFO:create_model() successfully completed......................................
2024-05-28 14:56:21,198:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:21,199:INFO:Creating metrics dataframe
2024-05-28 14:56:21,241:INFO:Initializing Decision Tree Classifier
2024-05-28 14:56:21,242:INFO:Total runtime is 0.3749124685923258 minutes
2024-05-28 14:56:21,242:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:21,243:INFO:Initializing create_model()
2024-05-28 14:56:21,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:21,243:INFO:Checking exceptions
2024-05-28 14:56:21,244:INFO:Importing libraries
2024-05-28 14:56:21,244:INFO:Copying training dataset
2024-05-28 14:56:21,249:INFO:Defining folds
2024-05-28 14:56:21,251:INFO:Declaring metric variables
2024-05-28 14:56:21,252:INFO:Importing untrained model
2024-05-28 14:56:21,254:INFO:Dummy Classifier Imported successfully
2024-05-28 14:56:21,255:INFO:Starting cross validation
2024-05-28 14:56:21,260:WARNING:
2024-05-28 14:56:21,266:WARNING:Processing:  22%|#############2                                               | 15/69 [00:22<00:55,  1.03s/it]
2024-05-28 14:56:21,266:WARNING:[A
2024-05-28 14:56:21,266:INFO:Defining folds
2024-05-28 14:56:21,266:INFO:Declaring metric variables
2024-05-28 14:56:21,272:INFO:Importing untrained model
2024-05-28 14:56:21,274:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:56:21,275:INFO:Starting cross validation
2024-05-28 14:56:21,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:21,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:21,772:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:21,776:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:21,799:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:21,841:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,241:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,274:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,292:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,360:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,855:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,877:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,898:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:22,905:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:22,976:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:22,995:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,050:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,082:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,443:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,453:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,496:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,509:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,516:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,530:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,574:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,586:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,843:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,910:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,941:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,946:INFO:Calculating mean and std
2024-05-28 14:56:23,947:WARNING:
2024-05-28 14:56:23,947:WARNING:Processing:  25%|###############                                              | 17/69 [00:25<00:58,  1.12s/it]
2024-05-28 14:56:23,947:WARNING:[A
2024-05-28 14:56:23,948:INFO:Creating metrics dataframe
2024-05-28 14:56:23,952:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:23,955:INFO:Uploading results into container
2024-05-28 14:56:23,956:INFO:Uploading model into container now
2024-05-28 14:56:23,956:INFO:_master_model_container: 4
2024-05-28 14:56:23,957:INFO:_display_container: 2
2024-05-28 14:56:23,957:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2867, splitter='best')
2024-05-28 14:56:23,958:INFO:create_model() successfully completed......................................
2024-05-28 14:56:23,966:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:23,990:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:24,218:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:24,218:INFO:Creating metrics dataframe
2024-05-28 14:56:24,218:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:56:24,218:INFO:Total runtime is 0.42450271844863885 minutes
2024-05-28 14:56:24,235:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:24,236:INFO:Initializing create_model()
2024-05-28 14:56:24,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:24,236:INFO:Checking exceptions
2024-05-28 14:56:24,236:INFO:Importing libraries
2024-05-28 14:56:24,237:INFO:Copying training dataset
2024-05-28 14:56:24,247:WARNING:
2024-05-28 14:56:24,247:INFO:Calculating mean and std
2024-05-28 14:56:24,248:WARNING:Processing:  28%|################7                                            | 19/69 [00:25<00:41,  1.21it/s]
2024-05-28 14:56:24,249:WARNING:[A
2024-05-28 14:56:24,250:INFO:Defining folds
2024-05-28 14:56:24,251:INFO:Declaring metric variables
2024-05-28 14:56:24,251:INFO:Creating metrics dataframe
2024-05-28 14:56:24,251:INFO:Importing untrained model
2024-05-28 14:56:24,256:INFO:Uploading results into container
2024-05-28 14:56:24,257:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:56:24,258:INFO:Uploading model into container now
2024-05-28 14:56:24,259:INFO:Starting cross validation
2024-05-28 14:56:24,260:INFO:_master_model_container: 16
2024-05-28 14:56:24,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:24,265:INFO:_display_container: 2
2024-05-28 14:56:24,269:INFO:DummyClassifier(constant=None, random_state=4193, strategy='prior')
2024-05-28 14:56:24,270:INFO:create_model() successfully completed......................................
2024-05-28 14:56:24,533:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:24,533:INFO:Creating metrics dataframe
2024-05-28 14:56:24,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:56:24,551:INFO:Initializing create_model()
2024-05-28 14:56:24,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA1EA5D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4193, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:24,551:INFO:Checking exceptions
2024-05-28 14:56:24,551:INFO:Importing libraries
2024-05-28 14:56:24,551:INFO:Copying training dataset
2024-05-28 14:56:24,585:INFO:Defining folds
2024-05-28 14:56:24,590:INFO:Declaring metric variables
2024-05-28 14:56:24,590:INFO:Importing untrained model
2024-05-28 14:56:24,594:INFO:Declaring custom model
2024-05-28 14:56:24,600:INFO:Logistic Regression Imported successfully
2024-05-28 14:56:24,600:INFO:Cross validation set to False
2024-05-28 14:56:24,600:INFO:Fitting Model
2024-05-28 14:56:25,695:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:56:25,741:INFO:Calculating mean and std
2024-05-28 14:56:25,742:WARNING:
2024-05-28 14:56:25,743:WARNING:Processing:  30%|##################5                                          | 21/69 [00:26<00:38,  1.25it/s]
2024-05-28 14:56:25,743:WARNING:[A
2024-05-28 14:56:25,743:INFO:Creating metrics dataframe
2024-05-28 14:56:25,748:INFO:Uploading results into container
2024-05-28 14:56:25,751:INFO:Uploading model into container now
2024-05-28 14:56:25,753:INFO:_master_model_container: 5
2024-05-28 14:56:25,753:INFO:_display_container: 2
2024-05-28 14:56:25,755:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2867, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:56:25,755:INFO:create_model() successfully completed......................................
2024-05-28 14:56:26,085:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:26,086:INFO:Creating metrics dataframe
2024-05-28 14:56:26,093:INFO:Initializing Ridge Classifier
2024-05-28 14:56:26,093:INFO:Total runtime is 0.4557513674100239 minutes
2024-05-28 14:56:26,094:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:26,095:INFO:Initializing create_model()
2024-05-28 14:56:26,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:26,096:INFO:Checking exceptions
2024-05-28 14:56:26,096:INFO:Importing libraries
2024-05-28 14:56:26,096:INFO:Copying training dataset
2024-05-28 14:56:26,110:WARNING:
2024-05-28 14:56:26,111:WARNING:Processing:  33%|####################3                                        | 23/69 [00:27<00:28,  1.63it/s]
2024-05-28 14:56:26,111:WARNING:[A
2024-05-28 14:56:26,111:INFO:Defining folds
2024-05-28 14:56:26,112:INFO:Declaring metric variables
2024-05-28 14:56:26,112:INFO:Importing untrained model
2024-05-28 14:56:26,113:INFO:Ridge Classifier Imported successfully
2024-05-28 14:56:26,114:INFO:Starting cross validation
2024-05-28 14:56:26,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:27,095:INFO:Calculating mean and std
2024-05-28 14:56:27,097:WARNING:
2024-05-28 14:56:27,098:WARNING:Processing:  36%|######################1                                      | 25/69 [00:28<00:25,  1.73it/s]
2024-05-28 14:56:27,098:WARNING:[A
2024-05-28 14:56:27,099:INFO:Creating metrics dataframe
2024-05-28 14:56:27,102:INFO:Uploading results into container
2024-05-28 14:56:27,103:INFO:Uploading model into container now
2024-05-28 14:56:27,104:INFO:_master_model_container: 6
2024-05-28 14:56:27,105:INFO:_display_container: 2
2024-05-28 14:56:27,106:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2867, solver='auto',
                tol=0.0001)
2024-05-28 14:56:27,106:INFO:create_model() successfully completed......................................
2024-05-28 14:56:27,359:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:27,360:INFO:Creating metrics dataframe
2024-05-28 14:56:27,369:INFO:Initializing Random Forest Classifier
2024-05-28 14:56:27,369:INFO:Total runtime is 0.47701757351557406 minutes
2024-05-28 14:56:27,370:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:27,370:INFO:Initializing create_model()
2024-05-28 14:56:27,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:27,371:INFO:Checking exceptions
2024-05-28 14:56:27,371:INFO:Importing libraries
2024-05-28 14:56:27,372:INFO:Copying training dataset
2024-05-28 14:56:27,382:WARNING:
2024-05-28 14:56:27,383:WARNING:Processing:  39%|#######################8                                     | 27/69 [00:28<00:18,  2.24it/s]
2024-05-28 14:56:27,383:WARNING:[A
2024-05-28 14:56:27,384:INFO:Defining folds
2024-05-28 14:56:27,384:INFO:Declaring metric variables
2024-05-28 14:56:27,385:INFO:Importing untrained model
2024-05-28 14:56:27,386:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:56:27,386:INFO:Starting cross validation
2024-05-28 14:56:27,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:28,474:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:28,477:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:28,501:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:28,847:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:29,791:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:29,810:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:30,387:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:30,554:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:31,042:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:31,091:INFO:Calculating mean and std
2024-05-28 14:56:31,093:WARNING:
2024-05-28 14:56:31,093:WARNING:Processing:  42%|#########################6                                   | 29/69 [00:32<00:34,  1.15it/s]
2024-05-28 14:56:31,095:WARNING:[A
2024-05-28 14:56:31,096:INFO:Creating metrics dataframe
2024-05-28 14:56:31,100:INFO:Uploading results into container
2024-05-28 14:56:31,101:INFO:Uploading model into container now
2024-05-28 14:56:31,102:INFO:_master_model_container: 7
2024-05-28 14:56:31,102:INFO:_display_container: 2
2024-05-28 14:56:31,103:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2867, verbose=0,
                       warm_start=False)
2024-05-28 14:56:31,103:INFO:create_model() successfully completed......................................
2024-05-28 14:56:31,447:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:31,447:INFO:Creating metrics dataframe
2024-05-28 14:56:31,453:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:56:31,453:INFO:Total runtime is 0.5450902303059895 minutes
2024-05-28 14:56:31,454:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:31,454:INFO:Initializing create_model()
2024-05-28 14:56:31,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:31,454:INFO:Checking exceptions
2024-05-28 14:56:31,454:INFO:Importing libraries
2024-05-28 14:56:31,455:INFO:Copying training dataset
2024-05-28 14:56:31,465:WARNING:
2024-05-28 14:56:31,466:WARNING:Processing:  45%|###########################4                                 | 31/69 [00:32<00:25,  1.50it/s]
2024-05-28 14:56:31,466:WARNING:[A
2024-05-28 14:56:31,466:INFO:Defining folds
2024-05-28 14:56:31,467:INFO:Declaring metric variables
2024-05-28 14:56:31,468:INFO:Importing untrained model
2024-05-28 14:56:31,469:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:56:31,469:INFO:Starting cross validation
2024-05-28 14:56:31,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:31,695:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:31,759:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:31,979:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:31,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,208:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,241:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,387:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,415:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,613:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,626:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:56:32,736:INFO:Calculating mean and std
2024-05-28 14:56:32,738:WARNING:
2024-05-28 14:56:32,739:WARNING:Processing:  48%|#############################1                               | 33/69 [00:33<00:23,  1.52it/s]
2024-05-28 14:56:32,739:WARNING:[A
2024-05-28 14:56:32,740:INFO:Creating metrics dataframe
2024-05-28 14:56:32,746:INFO:Uploading results into container
2024-05-28 14:56:32,747:INFO:Uploading model into container now
2024-05-28 14:56:32,748:INFO:_master_model_container: 8
2024-05-28 14:56:32,748:INFO:_display_container: 2
2024-05-28 14:56:32,749:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:56:32,749:INFO:create_model() successfully completed......................................
2024-05-28 14:56:33,052:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:33,053:INFO:Creating metrics dataframe
2024-05-28 14:56:33,063:INFO:Initializing Ada Boost Classifier
2024-05-28 14:56:33,064:INFO:Total runtime is 0.5719459811846413 minutes
2024-05-28 14:56:33,064:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:33,065:INFO:Initializing create_model()
2024-05-28 14:56:33,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:33,066:INFO:Checking exceptions
2024-05-28 14:56:33,067:INFO:Importing libraries
2024-05-28 14:56:33,067:INFO:Copying training dataset
2024-05-28 14:56:33,083:WARNING:
2024-05-28 14:56:33,083:WARNING:Processing:  51%|##############################9                              | 35/69 [00:34<00:17,  1.96it/s]
2024-05-28 14:56:33,084:WARNING:[A
2024-05-28 14:56:33,084:INFO:Defining folds
2024-05-28 14:56:33,084:INFO:Declaring metric variables
2024-05-28 14:56:33,085:INFO:Importing untrained model
2024-05-28 14:56:33,086:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:56:33,087:INFO:Starting cross validation
2024-05-28 14:56:33,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:33,409:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:33,427:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:33,489:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:33,489:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,063:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,081:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,089:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,092:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,482:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4193, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:56:34,482:INFO:create_model() successfully completed......................................
2024-05-28 14:56:34,558:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,574:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:56:34,746:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2024-05-28 14:56:34,746:INFO:lr                    Logistic Regression    0.8072  0.8582  0.7495  0.7523   
2024-05-28 14:56:34,746:INFO:gbc          Gradient Boosting Classifier    0.7864  0.7719  0.6656  0.7502   
2024-05-28 14:56:34,746:INFO:ridge                    Ridge Classifier    0.7847  0.8318  0.6529  0.7531   
2024-05-28 14:56:34,746:INFO:lightgbm  Light Gradient Boosting Machine    0.7800  0.0000  0.6614  0.7365   
2024-05-28 14:56:34,746:INFO:catboost              CatBoost Classifier    0.7784  0.0000  0.6279  0.7479   
2024-05-28 14:56:34,746:INFO:rf               Random Forest Classifier    0.7768  0.0000  0.6279  0.7480   
2024-05-28 14:56:34,746:INFO:et                 Extra Trees Classifier    0.7752  0.0000  0.6739  0.7231   
2024-05-28 14:56:34,746:INFO:xgboost         Extreme Gradient Boosting    0.7591  0.0000  0.5572  0.7355   
2024-05-28 14:56:34,746:INFO:ada                  Ada Boost Classifier    0.7348  0.7687  0.6616  0.6866   
2024-05-28 14:56:34,746:INFO:dt               Decision Tree Classifier    0.7238  0.0000  0.6614  0.6538   
2024-05-28 14:56:34,746:INFO:qda       Quadratic Discriminant Analysis    0.6981  0.7594  0.4904  0.6605   
2024-05-28 14:56:34,746:INFO:nb                            Naive Bayes    0.6952  0.0000  0.4736  0.6377   
2024-05-28 14:56:34,746:INFO:lda          Linear Discriminant Analysis    0.6870  0.7796  0.3014  0.7262   
2024-05-28 14:56:34,746:INFO:svm                   SVM - Linear Kernel    0.6858  0.7382  0.5611  0.6736   
2024-05-28 14:56:34,746:INFO:knn                K Neighbors Classifier    0.6725  0.0000  0.6525  0.5680   
2024-05-28 14:56:34,746:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 14:56:34,746:INFO:
2024-05-28 14:56:34,746:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-05-28 14:56:34,746:INFO:lr        0.7476  0.5921  0.5955     1.418  
2024-05-28 14:56:34,746:INFO:gbc       0.7016  0.5371  0.5422     0.199  
2024-05-28 14:56:34,746:INFO:ridge     0.6965  0.5318  0.5372     0.128  
2024-05-28 14:56:34,746:INFO:lightgbm  0.6926  0.5234  0.5282     0.279  
2024-05-28 14:56:34,746:INFO:catboost  0.6753  0.5124  0.5205     5.626  
2024-05-28 14:56:34,746:INFO:rf        0.6750  0.5098  0.5187     0.239  
2024-05-28 14:56:34,746:INFO:et        0.6943  0.5177  0.5212     0.182  
2024-05-28 14:56:34,746:INFO:xgboost   0.6117  0.4551  0.4716     0.104  
2024-05-28 14:56:34,746:INFO:ada       0.6587  0.4466  0.4585     0.160  
2024-05-28 14:56:34,746:INFO:dt        0.6439  0.4228  0.4324     0.155  
2024-05-28 14:56:34,746:INFO:qda       0.5537  0.3335  0.3484     0.085  
2024-05-28 14:56:34,746:INFO:nb        0.5423  0.3220  0.3303     0.115  
2024-05-28 14:56:34,746:INFO:lda       0.4203  0.2557  0.3035     0.080  
2024-05-28 14:56:34,746:INFO:svm       0.5527  0.3313  0.3659     0.120  
2024-05-28 14:56:34,746:INFO:knn       0.6022  0.3279  0.3343     0.135  
2024-05-28 14:56:34,746:INFO:dummy     0.0000  0.0000  0.0000     0.297  
2024-05-28 14:56:34,746:INFO:_master_model_container: 16
2024-05-28 14:56:34,746:INFO:_display_container: 2
2024-05-28 14:56:34,759:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4193, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:56:34,760:INFO:compare_models() successfully completed......................................
2024-05-28 14:56:34,996:INFO:Calculating mean and std
2024-05-28 14:56:34,998:WARNING:
2024-05-28 14:56:34,998:WARNING:Processing:  54%|################################7                            | 37/69 [00:36<00:20,  1.55it/s]
2024-05-28 14:56:34,998:WARNING:[A
2024-05-28 14:56:34,998:INFO:Creating metrics dataframe
2024-05-28 14:56:35,000:INFO:Uploading results into container
2024-05-28 14:56:35,001:INFO:Uploading model into container now
2024-05-28 14:56:35,002:INFO:_master_model_container: 9
2024-05-28 14:56:35,002:INFO:_display_container: 2
2024-05-28 14:56:35,002:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2867)
2024-05-28 14:56:35,002:INFO:create_model() successfully completed......................................
2024-05-28 14:56:35,208:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:35,208:INFO:Creating metrics dataframe
2024-05-28 14:56:35,208:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:56:35,208:INFO:Total runtime is 0.6076710621515908 minutes
2024-05-28 14:56:35,208:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:35,208:INFO:Initializing create_model()
2024-05-28 14:56:35,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:35,208:INFO:Checking exceptions
2024-05-28 14:56:35,208:INFO:Importing libraries
2024-05-28 14:56:35,208:INFO:Copying training dataset
2024-05-28 14:56:35,208:WARNING:
2024-05-28 14:56:35,208:WARNING:Processing:  57%|##################################4                          | 39/69 [00:36<00:14,  2.07it/s]
2024-05-28 14:56:35,208:WARNING:[A
2024-05-28 14:56:35,208:INFO:Defining folds
2024-05-28 14:56:35,208:INFO:Declaring metric variables
2024-05-28 14:56:35,208:INFO:Importing untrained model
2024-05-28 14:56:35,208:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:56:35,208:INFO:Starting cross validation
2024-05-28 14:56:35,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:37,015:INFO:Calculating mean and std
2024-05-28 14:56:37,015:WARNING:
2024-05-28 14:56:37,015:WARNING:Processing:  59%|####################################2                        | 41/69 [00:38<00:17,  1.64it/s]
2024-05-28 14:56:37,015:WARNING:[A
2024-05-28 14:56:37,015:INFO:Creating metrics dataframe
2024-05-28 14:56:37,015:INFO:Uploading results into container
2024-05-28 14:56:37,015:INFO:Uploading model into container now
2024-05-28 14:56:37,015:INFO:_master_model_container: 10
2024-05-28 14:56:37,015:INFO:_display_container: 2
2024-05-28 14:56:37,015:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2867, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:56:37,015:INFO:create_model() successfully completed......................................
2024-05-28 14:56:37,197:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:37,197:INFO:Creating metrics dataframe
2024-05-28 14:56:37,202:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:56:37,202:INFO:Total runtime is 0.6409001191457111 minutes
2024-05-28 14:56:37,203:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:37,203:INFO:Initializing create_model()
2024-05-28 14:56:37,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:37,204:INFO:Checking exceptions
2024-05-28 14:56:37,204:INFO:Importing libraries
2024-05-28 14:56:37,204:INFO:Copying training dataset
2024-05-28 14:56:37,206:WARNING:
2024-05-28 14:56:37,206:WARNING:Processing:  62%|######################################                       | 43/69 [00:38<00:11,  2.20it/s]
2024-05-28 14:56:37,206:WARNING:[A
2024-05-28 14:56:37,206:INFO:Defining folds
2024-05-28 14:56:37,206:INFO:Declaring metric variables
2024-05-28 14:56:37,206:INFO:Importing untrained model
2024-05-28 14:56:37,206:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:56:37,206:INFO:Starting cross validation
2024-05-28 14:56:37,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:38,119:INFO:Calculating mean and std
2024-05-28 14:56:38,119:WARNING:
2024-05-28 14:56:38,119:WARNING:Processing:  65%|#######################################7                     | 45/69 [00:39<00:10,  2.20it/s]
2024-05-28 14:56:38,119:WARNING:[A
2024-05-28 14:56:38,119:INFO:Creating metrics dataframe
2024-05-28 14:56:38,124:INFO:Uploading results into container
2024-05-28 14:56:38,125:INFO:Uploading model into container now
2024-05-28 14:56:38,125:INFO:_master_model_container: 11
2024-05-28 14:56:38,126:INFO:_display_container: 2
2024-05-28 14:56:38,126:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:56:38,126:INFO:create_model() successfully completed......................................
2024-05-28 14:56:38,319:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:38,320:INFO:Creating metrics dataframe
2024-05-28 14:56:38,323:INFO:Initializing Extra Trees Classifier
2024-05-28 14:56:38,323:INFO:Total runtime is 0.6595872759819029 minutes
2024-05-28 14:56:38,323:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:38,323:INFO:Initializing create_model()
2024-05-28 14:56:38,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:38,323:INFO:Checking exceptions
2024-05-28 14:56:38,323:INFO:Importing libraries
2024-05-28 14:56:38,323:INFO:Copying training dataset
2024-05-28 14:56:38,323:WARNING:
2024-05-28 14:56:38,323:WARNING:Processing:  68%|#########################################5                   | 47/69 [00:39<00:07,  2.86it/s]
2024-05-28 14:56:38,323:WARNING:[A
2024-05-28 14:56:38,323:INFO:Defining folds
2024-05-28 14:56:38,323:INFO:Declaring metric variables
2024-05-28 14:56:38,323:INFO:Importing untrained model
2024-05-28 14:56:38,323:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:56:38,323:INFO:Starting cross validation
2024-05-28 14:56:38,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:39,032:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,076:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,091:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,143:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,643:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,645:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,658:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:39,838:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,215:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,238:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,258:INFO:Calculating mean and std
2024-05-28 14:56:40,258:WARNING:
2024-05-28 14:56:40,258:WARNING:Processing:  71%|###########################################3                 | 49/69 [00:41<00:10,  1.87it/s]
2024-05-28 14:56:40,260:WARNING:[A
2024-05-28 14:56:40,260:INFO:Creating metrics dataframe
2024-05-28 14:56:40,262:INFO:Uploading results into container
2024-05-28 14:56:40,263:INFO:Uploading model into container now
2024-05-28 14:56:40,263:INFO:_master_model_container: 12
2024-05-28 14:56:40,263:INFO:_display_container: 2
2024-05-28 14:56:40,264:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2867, verbose=0,
                     warm_start=False)
2024-05-28 14:56:40,264:INFO:create_model() successfully completed......................................
2024-05-28 14:56:40,454:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:40,454:INFO:Creating metrics dataframe
2024-05-28 14:56:40,454:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:56:40,454:INFO:Total runtime is 0.6951116164525348 minutes
2024-05-28 14:56:40,454:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:40,454:INFO:Initializing create_model()
2024-05-28 14:56:40,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:40,454:INFO:Checking exceptions
2024-05-28 14:56:40,454:INFO:Importing libraries
2024-05-28 14:56:40,454:INFO:Copying training dataset
2024-05-28 14:56:40,454:WARNING:
2024-05-28 14:56:40,454:WARNING:Processing:  74%|#############################################                | 51/69 [00:41<00:07,  2.48it/s]
2024-05-28 14:56:40,454:WARNING:[A
2024-05-28 14:56:40,454:INFO:Defining folds
2024-05-28 14:56:40,454:INFO:Declaring metric variables
2024-05-28 14:56:40,454:INFO:Importing untrained model
2024-05-28 14:56:40,454:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:56:40,454:INFO:Starting cross validation
2024-05-28 14:56:40,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:40,827:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,830:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,843:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:40,849:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,191:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,445:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,449:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:41,473:INFO:Calculating mean and std
2024-05-28 14:56:41,473:WARNING:
2024-05-28 14:56:41,473:WARNING:Processing:  77%|##############################################8              | 53/69 [00:42<00:06,  2.30it/s]
2024-05-28 14:56:41,473:WARNING:[A
2024-05-28 14:56:41,473:INFO:Creating metrics dataframe
2024-05-28 14:56:41,473:INFO:Uploading results into container
2024-05-28 14:56:41,473:INFO:Uploading model into container now
2024-05-28 14:56:41,473:INFO:_master_model_container: 13
2024-05-28 14:56:41,473:INFO:_display_container: 2
2024-05-28 14:56:41,473:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:56:41,473:INFO:create_model() successfully completed......................................
2024-05-28 14:56:41,653:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:41,653:INFO:Creating metrics dataframe
2024-05-28 14:56:41,653:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:56:41,653:INFO:Total runtime is 0.7150832335154214 minutes
2024-05-28 14:56:41,653:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:41,653:INFO:Initializing create_model()
2024-05-28 14:56:41,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:41,653:INFO:Checking exceptions
2024-05-28 14:56:41,653:INFO:Importing libraries
2024-05-28 14:56:41,653:INFO:Copying training dataset
2024-05-28 14:56:41,653:WARNING:
2024-05-28 14:56:41,653:WARNING:Processing:  80%|################################################6            | 55/69 [00:42<00:04,  3.01it/s]
2024-05-28 14:56:41,653:WARNING:[A
2024-05-28 14:56:41,653:INFO:Defining folds
2024-05-28 14:56:41,653:INFO:Declaring metric variables
2024-05-28 14:56:41,653:INFO:Importing untrained model
2024-05-28 14:56:41,653:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:56:41,653:INFO:Starting cross validation
2024-05-28 14:56:41,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:42,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:42,342:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:42,396:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:42,513:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,015:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,035:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,087:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,277:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,540:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,586:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:43,610:INFO:Calculating mean and std
2024-05-28 14:56:43,610:WARNING:
2024-05-28 14:56:43,610:WARNING:Processing:  83%|##################################################3          | 57/69 [00:44<00:06,  1.90it/s]
2024-05-28 14:56:43,610:WARNING:[A
2024-05-28 14:56:43,610:INFO:Creating metrics dataframe
2024-05-28 14:56:43,610:INFO:Uploading results into container
2024-05-28 14:56:43,635:INFO:Uploading model into container now
2024-05-28 14:56:43,635:INFO:_master_model_container: 14
2024-05-28 14:56:43,635:INFO:_display_container: 2
2024-05-28 14:56:43,635:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2867, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:56:43,635:INFO:create_model() successfully completed......................................
2024-05-28 14:56:43,868:INFO:SubProcess create_model() end ==================================
2024-05-28 14:56:43,868:INFO:Creating metrics dataframe
2024-05-28 14:56:43,871:INFO:Initializing CatBoost Classifier
2024-05-28 14:56:43,872:INFO:Total runtime is 0.7520639499028522 minutes
2024-05-28 14:56:43,872:INFO:SubProcess create_model() called ==================================
2024-05-28 14:56:43,872:INFO:Initializing create_model()
2024-05-28 14:56:43,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:56:43,872:INFO:Checking exceptions
2024-05-28 14:56:43,872:INFO:Importing libraries
2024-05-28 14:56:43,872:INFO:Copying training dataset
2024-05-28 14:56:43,876:WARNING:
2024-05-28 14:56:43,877:WARNING:Processing:  86%|####################################################1        | 59/69 [00:45<00:04,  2.45it/s]
2024-05-28 14:56:43,877:WARNING:[A
2024-05-28 14:56:43,877:INFO:Defining folds
2024-05-28 14:56:43,877:INFO:Declaring metric variables
2024-05-28 14:56:43,877:INFO:Importing untrained model
2024-05-28 14:56:43,877:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:56:43,878:INFO:Starting cross validation
2024-05-28 14:56:43,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:56:49,117:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:49,126:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:49,333:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:56:49,397:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:17,087:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:17,833:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:19,041:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:20,391:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:25,873:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:25,952:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:25,972:INFO:Calculating mean and std
2024-05-28 14:57:25,973:WARNING:
2024-05-28 14:57:25,973:WARNING:Processing:  88%|#####################################################9       | 61/69 [01:27<00:52,  6.60s/it]
2024-05-28 14:57:25,974:WARNING:[A
2024-05-28 14:57:25,974:INFO:Creating metrics dataframe
2024-05-28 14:57:25,976:INFO:Uploading results into container
2024-05-28 14:57:25,977:INFO:Uploading model into container now
2024-05-28 14:57:25,978:INFO:_master_model_container: 15
2024-05-28 14:57:25,978:INFO:_display_container: 2
2024-05-28 14:57:25,978:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCA67A810>
2024-05-28 14:57:25,978:INFO:create_model() successfully completed......................................
2024-05-28 14:57:26,227:INFO:SubProcess create_model() end ==================================
2024-05-28 14:57:26,228:INFO:Creating metrics dataframe
2024-05-28 14:57:26,232:INFO:Initializing Dummy Classifier
2024-05-28 14:57:26,233:INFO:Total runtime is 1.458084952831268 minutes
2024-05-28 14:57:26,233:INFO:SubProcess create_model() called ==================================
2024-05-28 14:57:26,234:INFO:Initializing create_model()
2024-05-28 14:57:26,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA2C8F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:57:26,235:INFO:Checking exceptions
2024-05-28 14:57:26,235:INFO:Importing libraries
2024-05-28 14:57:26,235:INFO:Copying training dataset
2024-05-28 14:57:26,248:WARNING:
2024-05-28 14:57:26,249:WARNING:Processing:  91%|#######################################################6     | 63/69 [01:27<00:27,  4.66s/it]
2024-05-28 14:57:26,249:WARNING:[A
2024-05-28 14:57:26,249:INFO:Defining folds
2024-05-28 14:57:26,250:INFO:Declaring metric variables
2024-05-28 14:57:26,251:INFO:Importing untrained model
2024-05-28 14:57:26,252:INFO:Dummy Classifier Imported successfully
2024-05-28 14:57:26,253:INFO:Starting cross validation
2024-05-28 14:57:26,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:57:26,573:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,583:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,586:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,592:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,596:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,601:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,609:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,635:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,884:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,912:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,929:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,946:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,956:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:26,956:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:26,983:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:27,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:27,195:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:57:27,196:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:27,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:57:27,220:INFO:Calculating mean and std
2024-05-28 14:57:27,220:WARNING:
2024-05-28 14:57:27,220:WARNING:Processing:  94%|#########################################################4   | 65/69 [01:28<00:13,  3.41s/it]
2024-05-28 14:57:27,220:WARNING:[A
2024-05-28 14:57:27,220:INFO:Creating metrics dataframe
2024-05-28 14:57:27,220:INFO:Uploading results into container
2024-05-28 14:57:27,220:INFO:Uploading model into container now
2024-05-28 14:57:27,220:INFO:_master_model_container: 16
2024-05-28 14:57:27,220:INFO:_display_container: 2
2024-05-28 14:57:27,220:INFO:DummyClassifier(constant=None, random_state=2867, strategy='prior')
2024-05-28 14:57:27,220:INFO:create_model() successfully completed......................................
2024-05-28 14:57:27,458:INFO:SubProcess create_model() end ==================================
2024-05-28 14:57:27,458:INFO:Creating metrics dataframe
2024-05-28 14:57:27,463:WARNING:
2024-05-28 14:57:27,463:WARNING:Processing:  97%|###########################################################2 | 67/69 [01:28<00:04,  2.42s/it]
2024-05-28 14:57:27,464:WARNING:[A
2024-05-28 14:57:27,465:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:57:27,468:INFO:Initializing create_model()
2024-05-28 14:57:27,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023BCA67A810>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:57:27,469:INFO:Checking exceptions
2024-05-28 14:57:27,470:INFO:Importing libraries
2024-05-28 14:57:27,471:INFO:Copying training dataset
2024-05-28 14:57:27,480:INFO:Defining folds
2024-05-28 14:57:27,480:INFO:Declaring metric variables
2024-05-28 14:57:27,480:INFO:Importing untrained model
2024-05-28 14:57:27,480:INFO:Declaring custom model
2024-05-28 14:57:27,481:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:57:27,482:INFO:Cross validation set to False
2024-05-28 14:57:27,482:INFO:Fitting Model
2024-05-28 14:57:31,679:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>
2024-05-28 14:57:31,679:INFO:create_model() successfully completed......................................
2024-05-28 14:57:31,868:WARNING:
2024-05-28 14:57:31,869:WARNING:Processing: 100%|#############################################################| 69/69 [01:33<00:00,  2.36s/it]
2024-05-28 14:57:31,869:WARNING:[A
2024-05-28 14:57:31,869:WARNING:
2024-05-28 14:57:31,869:WARNING:                                                                                                              
2024-05-28 14:57:31,869:WARNING:[A
2024-05-28 14:57:31,895:INFO:                                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC  TT (Sec)
2024-05-28 14:57:31,895:INFO:catboost              CatBoost Classifier    0.8266  0.0000  0.7190  0.8075  0.7598  0.6249  0.6282     4.209
2024-05-28 14:57:31,895:INFO:gbc          Gradient Boosting Classifier    0.8186  0.8492  0.7274  0.7864  0.7532  0.6105  0.6139     0.181
2024-05-28 14:57:31,895:INFO:et                 Extra Trees Classifier    0.8008  0.0000  0.6982  0.7635  0.7273  0.5713  0.5746     0.194
2024-05-28 14:57:31,895:INFO:lightgbm  Light Gradient Boosting Machine    0.7994  0.0000  0.6980  0.7633  0.7264  0.5689  0.5727     0.194
2024-05-28 14:57:31,895:INFO:rf               Random Forest Classifier    0.7977  0.0000  0.7024  0.7553  0.7246  0.5656  0.5696     0.370
2024-05-28 14:57:31,895:INFO:xgboost         Extreme Gradient Boosting    0.7945  0.0000  0.7230  0.7357  0.7271  0.5626  0.5647     0.102
2024-05-28 14:57:31,895:INFO:lda          Linear Discriminant Analysis    0.7928  0.8360  0.7317  0.7299  0.7290  0.5614  0.5633     0.090
2024-05-28 14:57:31,895:INFO:ridge                    Ridge Classifier    0.7896  0.8317  0.7275  0.7263  0.7252  0.5548  0.5566     0.098
2024-05-28 14:57:31,895:INFO:ada                  Ada Boost Classifier    0.7768  0.8047  0.7150  0.7082  0.7104  0.5291  0.5303     0.190
2024-05-28 14:57:31,895:INFO:dt               Decision Tree Classifier    0.7753  0.0000  0.6730  0.7236  0.6933  0.5172  0.5211     0.266
2024-05-28 14:57:31,895:INFO:lr                    Logistic Regression    0.7752  0.8326  0.7487  0.6925  0.7183  0.5319  0.5344     1.386
2024-05-28 14:57:31,895:INFO:nb                            Naive Bayes    0.7479  0.0000  0.5850  0.7200  0.6393  0.4492  0.4595     0.261
2024-05-28 14:57:31,895:INFO:qda       Quadratic Discriminant Analysis    0.7110  0.7115  0.5808  0.6870  0.5902  0.3780  0.4085     0.126
2024-05-28 14:57:31,895:INFO:knn                K Neighbors Classifier    0.6707  0.0000  0.6605  0.5568  0.6032  0.3246  0.3299     0.464
2024-05-28 14:57:31,895:INFO:svm                   SVM - Linear Kernel    0.6534  0.7545  0.6043  0.5330  0.5196  0.2845  0.3137     0.148
2024-05-28 14:57:31,895:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000     0.096
2024-05-28 14:57:31,895:INFO:_master_model_container: 16
2024-05-28 14:57:31,895:INFO:_display_container: 2
2024-05-28 14:57:31,895:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>
2024-05-28 14:57:31,895:INFO:compare_models() successfully completed......................................
2024-05-28 14:57:31,961:INFO:Initializing save_model()
2024-05-28 14:57:31,961:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>, model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:57:31,961:INFO:Adding model into prep_pipe
2024-05-28 14:57:31,987:INFO:Transformation Pipeline and Model Successfully Saved
2024-05-28 14:57:31,987:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:57:32,029:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>)],
         verbose=False)
2024-05-28 14:57:32,029:INFO:save_model() successfully completed......................................
2024-05-28 14:57:32,312:INFO:Initializing plot_model()
2024-05-28 14:57:32,312:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>, plot=auc, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 14:57:32,312:INFO:Checking exceptions
2024-05-28 14:57:32,312:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 14:57:32,320:INFO:Preloading libraries
2024-05-28 14:57:32,327:INFO:Copying training dataset
2024-05-28 14:57:32,327:INFO:Plot type: auc
2024-05-28 14:57:32,512:INFO:Fitting Model
2024-05-28 14:57:32,538:INFO:Scoring test/hold-out set
2024-05-28 14:57:32,573:INFO:Saving 'AUC.png'
2024-05-28 14:57:33,095:INFO:Visual Rendered Successfully
2024-05-28 14:57:33,344:INFO:plot_model() successfully completed......................................
2024-05-28 14:57:33,344:INFO:Initializing plot_model()
2024-05-28 14:57:33,344:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>, plot=confusion_matrix, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 14:57:33,344:INFO:Checking exceptions
2024-05-28 14:57:33,344:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 14:57:33,361:INFO:Preloading libraries
2024-05-28 14:57:33,361:INFO:Copying training dataset
2024-05-28 14:57:33,361:INFO:Plot type: confusion_matrix
2024-05-28 14:57:33,522:INFO:Fitting Model
2024-05-28 14:57:33,523:INFO:Scoring test/hold-out set
2024-05-28 14:57:33,563:INFO:Saving 'Confusion Matrix.png'
2024-05-28 14:57:33,777:INFO:Visual Rendered Successfully
2024-05-28 14:57:33,961:INFO:plot_model() successfully completed......................................
2024-05-28 14:57:33,961:INFO:Initializing plot_model()
2024-05-28 14:57:33,976:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC95EE510>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023BCAFD5CD0>, plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 14:57:33,976:INFO:Checking exceptions
2024-05-28 14:57:33,976:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 14:57:33,979:INFO:Preloading libraries
2024-05-28 14:57:33,983:INFO:Copying training dataset
2024-05-28 14:57:33,983:INFO:Plot type: feature
2024-05-28 14:57:33,984:WARNING:No coef_ found. Trying feature_importances_
2024-05-28 14:57:34,027:INFO:Saving 'Feature Importance.png'
2024-05-28 14:57:34,264:INFO:Visual Rendered Successfully
2024-05-28 14:57:34,427:INFO:plot_model() successfully completed......................................
2024-05-28 14:59:30,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:59:30,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:59:30,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:59:30,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 15:00:42,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 15:00:42,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 15:00:42,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 15:00:42,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 15:01:25,102:INFO:PyCaret ClassificationExperiment
2024-05-28 15:01:25,103:INFO:Logging name: clf-default-name
2024-05-28 15:01:25,103:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 15:01:25,103:INFO:version 3.3.1
2024-05-28 15:01:25,104:INFO:Initializing setup()
2024-05-28 15:01:25,104:INFO:self.USI: 9753
2024-05-28 15:01:25,104:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 15:01:25,105:INFO:Checking environment
2024-05-28 15:01:25,105:INFO:python_version: 3.11.9
2024-05-28 15:01:25,105:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 15:01:25,106:INFO:machine: AMD64
2024-05-28 15:01:25,106:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 15:01:25,111:INFO:Memory: svmem(total=8469606400, available=1196175360, percent=85.9, used=7273431040, free=1196175360)
2024-05-28 15:01:25,112:INFO:Physical Core: 2
2024-05-28 15:01:25,112:INFO:Logical Core: 4
2024-05-28 15:01:25,113:INFO:Checking libraries
2024-05-28 15:01:25,113:INFO:System:
2024-05-28 15:01:25,113:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 15:01:25,113:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 15:01:25,113:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 15:01:25,114:INFO:PyCaret required dependencies:
2024-05-28 15:01:25,115:INFO:                 pip: 24.0
2024-05-28 15:01:25,115:INFO:          setuptools: 70.0.0
2024-05-28 15:01:25,115:INFO:             pycaret: 3.3.1
2024-05-28 15:01:25,115:INFO:             IPython: 8.24.0
2024-05-28 15:01:25,117:INFO:          ipywidgets: 8.1.2
2024-05-28 15:01:25,118:INFO:                tqdm: 4.66.4
2024-05-28 15:01:25,118:INFO:               numpy: 1.26.4
2024-05-28 15:01:25,118:INFO:              pandas: 2.1.4
2024-05-28 15:01:25,119:INFO:              jinja2: 3.1.4
2024-05-28 15:01:25,119:INFO:               scipy: 1.11.4
2024-05-28 15:01:25,119:INFO:              joblib: 1.3.2
2024-05-28 15:01:25,119:INFO:             sklearn: 1.4.2
2024-05-28 15:01:25,119:INFO:                pyod: 1.1.3
2024-05-28 15:01:25,120:INFO:            imblearn: 0.12.2
2024-05-28 15:01:25,120:INFO:   category_encoders: 2.6.3
2024-05-28 15:01:25,120:INFO:            lightgbm: 4.3.0
2024-05-28 15:01:25,120:INFO:               numba: 0.58.1
2024-05-28 15:01:25,120:INFO:            requests: 2.32.2
2024-05-28 15:01:25,120:INFO:          matplotlib: 3.7.5
2024-05-28 15:01:25,120:INFO:          scikitplot: 0.3.7
2024-05-28 15:01:25,120:INFO:         yellowbrick: 1.5
2024-05-28 15:01:25,120:INFO:              plotly: 5.22.0
2024-05-28 15:01:25,120:INFO:    plotly-resampler: Not installed
2024-05-28 15:01:25,120:INFO:             kaleido: 0.2.1
2024-05-28 15:01:25,120:INFO:           schemdraw: 0.15
2024-05-28 15:01:25,120:INFO:         statsmodels: 0.14.2
2024-05-28 15:01:25,120:INFO:              sktime: 0.26.0
2024-05-28 15:01:25,120:INFO:               tbats: 1.1.3
2024-05-28 15:01:25,120:INFO:            pmdarima: 2.0.4
2024-05-28 15:01:25,120:INFO:              psutil: 5.9.8
2024-05-28 15:01:25,120:INFO:          markupsafe: 2.1.5
2024-05-28 15:01:25,120:INFO:             pickle5: Not installed
2024-05-28 15:01:25,120:INFO:         cloudpickle: 3.0.0
2024-05-28 15:01:25,120:INFO:         deprecation: 2.1.0
2024-05-28 15:01:25,120:INFO:              xxhash: 3.4.1
2024-05-28 15:01:25,120:INFO:           wurlitzer: 3.1.0
2024-05-28 15:01:25,120:INFO:PyCaret optional dependencies:
2024-05-28 15:01:25,120:INFO:                shap: Not installed
2024-05-28 15:01:25,120:INFO:           interpret: Not installed
2024-05-28 15:01:25,120:INFO:                umap: 0.5.5
2024-05-28 15:01:25,120:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 15:01:25,120:INFO:  explainerdashboard: Not installed
2024-05-28 15:01:25,120:INFO:             autoviz: Not installed
2024-05-28 15:01:25,120:INFO:           fairlearn: Not installed
2024-05-28 15:01:25,120:INFO:          deepchecks: Not installed
2024-05-28 15:01:25,120:INFO:             xgboost: 2.0.3
2024-05-28 15:01:25,120:INFO:            catboost: 1.2.5
2024-05-28 15:01:25,120:INFO:              kmodes: 0.12.2
2024-05-28 15:01:25,120:INFO:             mlxtend: 0.23.1
2024-05-28 15:01:25,120:INFO:       statsforecast: Not installed
2024-05-28 15:01:25,120:INFO:        tune_sklearn: Not installed
2024-05-28 15:01:25,120:INFO:                 ray: Not installed
2024-05-28 15:01:25,120:INFO:            hyperopt: Not installed
2024-05-28 15:01:25,120:INFO:              optuna: Not installed
2024-05-28 15:01:25,120:INFO:               skopt: Not installed
2024-05-28 15:01:25,120:INFO:              mlflow: 2.13.0
2024-05-28 15:01:25,120:INFO:              gradio: Not installed
2024-05-28 15:01:25,120:INFO:             fastapi: Not installed
2024-05-28 15:01:25,120:INFO:             uvicorn: Not installed
2024-05-28 15:01:25,120:INFO:              m2cgen: Not installed
2024-05-28 15:01:25,120:INFO:           evidently: Not installed
2024-05-28 15:01:25,120:INFO:               fugue: Not installed
2024-05-28 15:01:25,136:INFO:           streamlit: 1.35.0
2024-05-28 15:01:25,137:INFO:             prophet: Not installed
2024-05-28 15:01:25,137:INFO:None
2024-05-28 15:01:25,137:INFO:Set up data.
2024-05-28 15:01:25,159:INFO:Set up folding strategy.
2024-05-28 15:01:25,160:INFO:Set up train/test split.
2024-05-28 15:01:41,390:INFO:PyCaret ClassificationExperiment
2024-05-28 15:01:41,390:INFO:Logging name: clf-default-name
2024-05-28 15:01:41,390:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 15:01:41,390:INFO:version 3.3.1
2024-05-28 15:01:41,390:INFO:Initializing setup()
2024-05-28 15:01:41,390:INFO:self.USI: 9ceb
2024-05-28 15:01:41,390:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 15:01:41,390:INFO:Checking environment
2024-05-28 15:01:41,390:INFO:python_version: 3.11.9
2024-05-28 15:01:41,390:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 15:01:41,390:INFO:machine: AMD64
2024-05-28 15:01:41,390:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 15:01:41,390:INFO:Memory: svmem(total=8469606400, available=1185599488, percent=86.0, used=7284006912, free=1185599488)
2024-05-28 15:01:41,390:INFO:Physical Core: 2
2024-05-28 15:01:41,390:INFO:Logical Core: 4
2024-05-28 15:01:41,390:INFO:Checking libraries
2024-05-28 15:01:41,390:INFO:System:
2024-05-28 15:01:41,390:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 15:01:41,390:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 15:01:41,390:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 15:01:41,390:INFO:PyCaret required dependencies:
2024-05-28 15:01:41,390:INFO:                 pip: 24.0
2024-05-28 15:01:41,390:INFO:          setuptools: 70.0.0
2024-05-28 15:01:41,390:INFO:             pycaret: 3.3.1
2024-05-28 15:01:41,390:INFO:             IPython: 8.24.0
2024-05-28 15:01:41,390:INFO:          ipywidgets: 8.1.2
2024-05-28 15:01:41,390:INFO:                tqdm: 4.66.4
2024-05-28 15:01:41,390:INFO:               numpy: 1.26.4
2024-05-28 15:01:41,390:INFO:              pandas: 2.1.4
2024-05-28 15:01:41,390:INFO:              jinja2: 3.1.4
2024-05-28 15:01:41,390:INFO:               scipy: 1.11.4
2024-05-28 15:01:41,390:INFO:              joblib: 1.3.2
2024-05-28 15:01:41,390:INFO:             sklearn: 1.4.2
2024-05-28 15:01:41,390:INFO:                pyod: 1.1.3
2024-05-28 15:01:41,390:INFO:            imblearn: 0.12.2
2024-05-28 15:01:41,390:INFO:   category_encoders: 2.6.3
2024-05-28 15:01:41,390:INFO:            lightgbm: 4.3.0
2024-05-28 15:01:41,390:INFO:               numba: 0.58.1
2024-05-28 15:01:41,390:INFO:            requests: 2.32.2
2024-05-28 15:01:41,390:INFO:          matplotlib: 3.7.5
2024-05-28 15:01:41,390:INFO:          scikitplot: 0.3.7
2024-05-28 15:01:41,390:INFO:         yellowbrick: 1.5
2024-05-28 15:01:41,390:INFO:              plotly: 5.22.0
2024-05-28 15:01:41,390:INFO:    plotly-resampler: Not installed
2024-05-28 15:01:41,406:INFO:             kaleido: 0.2.1
2024-05-28 15:01:41,406:INFO:           schemdraw: 0.15
2024-05-28 15:01:41,406:INFO:         statsmodels: 0.14.2
2024-05-28 15:01:41,406:INFO:              sktime: 0.26.0
2024-05-28 15:01:41,406:INFO:               tbats: 1.1.3
2024-05-28 15:01:41,406:INFO:            pmdarima: 2.0.4
2024-05-28 15:01:41,406:INFO:              psutil: 5.9.8
2024-05-28 15:01:41,406:INFO:          markupsafe: 2.1.5
2024-05-28 15:01:41,406:INFO:             pickle5: Not installed
2024-05-28 15:01:41,406:INFO:         cloudpickle: 3.0.0
2024-05-28 15:01:41,407:INFO:         deprecation: 2.1.0
2024-05-28 15:01:41,407:INFO:              xxhash: 3.4.1
2024-05-28 15:01:41,407:INFO:           wurlitzer: 3.1.0
2024-05-28 15:01:41,407:INFO:PyCaret optional dependencies:
2024-05-28 15:01:41,407:INFO:                shap: Not installed
2024-05-28 15:01:41,407:INFO:           interpret: Not installed
2024-05-28 15:01:41,407:INFO:                umap: 0.5.5
2024-05-28 15:01:41,407:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 15:01:41,407:INFO:  explainerdashboard: Not installed
2024-05-28 15:01:41,407:INFO:             autoviz: Not installed
2024-05-28 15:01:41,407:INFO:           fairlearn: Not installed
2024-05-28 15:01:41,407:INFO:          deepchecks: Not installed
2024-05-28 15:01:41,407:INFO:             xgboost: 2.0.3
2024-05-28 15:01:41,407:INFO:            catboost: 1.2.5
2024-05-28 15:01:41,407:INFO:              kmodes: 0.12.2
2024-05-28 15:01:41,408:INFO:             mlxtend: 0.23.1
2024-05-28 15:01:41,408:INFO:       statsforecast: Not installed
2024-05-28 15:01:41,408:INFO:        tune_sklearn: Not installed
2024-05-28 15:01:41,408:INFO:                 ray: Not installed
2024-05-28 15:01:41,408:INFO:            hyperopt: Not installed
2024-05-28 15:01:41,408:INFO:              optuna: Not installed
2024-05-28 15:01:41,408:INFO:               skopt: Not installed
2024-05-28 15:01:41,408:INFO:              mlflow: 2.13.0
2024-05-28 15:01:41,408:INFO:              gradio: Not installed
2024-05-28 15:01:41,408:INFO:             fastapi: Not installed
2024-05-28 15:01:41,408:INFO:             uvicorn: Not installed
2024-05-28 15:01:41,408:INFO:              m2cgen: Not installed
2024-05-28 15:01:41,408:INFO:           evidently: Not installed
2024-05-28 15:01:41,408:INFO:               fugue: Not installed
2024-05-28 15:01:41,408:INFO:           streamlit: 1.35.0
2024-05-28 15:01:41,408:INFO:             prophet: Not installed
2024-05-28 15:01:41,408:INFO:None
2024-05-28 15:01:41,409:INFO:Set up data.
2024-05-28 15:01:41,419:INFO:Set up folding strategy.
2024-05-28 15:01:41,420:INFO:Set up train/test split.
2024-05-28 15:01:41,436:INFO:Set up index.
2024-05-28 15:01:41,437:INFO:Assigning column types.
2024-05-28 15:01:41,440:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 15:01:41,527:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,575:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:41,575:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:41,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,640:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,673:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:41,673:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:41,673:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 15:01:41,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,815:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:41,820:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:41,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 15:01:41,952:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:41,956:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:41,957:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 15:01:42,050:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:42,053:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:42,145:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:42,149:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:42,151:INFO:Preparing preprocessing pipeline...
2024-05-28 15:01:42,152:INFO:Set up simple imputation.
2024-05-28 15:01:42,157:INFO:Set up encoding of ordinal features.
2024-05-28 15:01:42,159:INFO:Set up encoding of categorical features.
2024-05-28 15:01:42,159:INFO:Set up removing multicollinearity.
2024-05-28 15:01:42,159:INFO:Set up imbalanced handling.
2024-05-28 15:01:42,291:INFO:Finished creating preprocessing pipeline.
2024-05-28 15:01:42,332:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 15:01:42,333:INFO:Creating final display dataframe.
2024-05-28 15:01:42,748:INFO:Setup _display_container:                     Description             Value
0                    Session id              8351
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 11)
5   Transformed train set shape         (768, 11)
6    Transformed test set shape         (268, 11)
7               Ignore features                 3
8              Numeric features                 5
9          Categorical features                 3
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              9ceb
2024-05-28 15:01:42,753:INFO:                    Description             Value
2024-05-28 15:01:42,753:INFO:0                    Session id              8351
2024-05-28 15:01:42,754:INFO:1                        Target          Survived
2024-05-28 15:01:42,754:INFO:2                   Target type            Binary
2024-05-28 15:01:42,754:INFO:3           Original data shape         (891, 12)
2024-05-28 15:01:42,754:INFO:4        Transformed data shape        (1036, 11)
2024-05-28 15:01:42,754:INFO:5   Transformed train set shape         (768, 11)
2024-05-28 15:01:42,754:INFO:6    Transformed test set shape         (268, 11)
2024-05-28 15:01:42,754:INFO:7               Ignore features                 3
2024-05-28 15:01:42,754:INFO:8              Numeric features                 5
2024-05-28 15:01:42,754:INFO:9          Categorical features                 3
2024-05-28 15:01:42,754:INFO:10     Rows with missing values             79.5%
2024-05-28 15:01:42,754:INFO:11                   Preprocess              True
2024-05-28 15:01:42,754:INFO:12              Imputation type            simple
2024-05-28 15:01:42,754:INFO:13           Numeric imputation              mean
2024-05-28 15:01:42,754:INFO:14       Categorical imputation              mode
2024-05-28 15:01:42,754:INFO:15     Maximum one-hot encoding                25
2024-05-28 15:01:42,754:INFO:16              Encoding method              None
2024-05-28 15:01:42,755:INFO:17     Remove multicollinearity              True
2024-05-28 15:01:42,755:INFO:18  Multicollinearity threshold               0.9
2024-05-28 15:01:42,755:INFO:19                Fix imbalance              True
2024-05-28 15:01:42,755:INFO:20         Fix imbalance method             SMOTE
2024-05-28 15:01:42,755:INFO:21               Fold Generator   StratifiedKFold
2024-05-28 15:01:42,755:INFO:22                  Fold Number                10
2024-05-28 15:01:42,755:INFO:23                     CPU Jobs                -1
2024-05-28 15:01:42,755:INFO:24                      Use GPU             False
2024-05-28 15:01:42,755:INFO:25               Log Experiment             False
2024-05-28 15:01:42,755:INFO:26              Experiment Name  clf-default-name
2024-05-28 15:01:42,755:INFO:27                          USI              9ceb
2024-05-28 15:01:42,856:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:42,873:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:43,256:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 15:01:43,273:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 15:01:43,277:INFO:setup() successfully completed in 1.91s...............
2024-05-28 15:01:43,290:INFO:Initializing compare_models()
2024-05-28 15:01:43,291:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 15:01:43,292:INFO:Checking exceptions
2024-05-28 15:01:43,299:INFO:Preparing display monitor
2024-05-28 15:01:43,299:WARNING:Processing:   0%|                                                                      | 0/69 [00:00<?, ?it/s]
2024-05-28 15:01:43,305:INFO:Initializing Logistic Regression
2024-05-28 15:01:43,305:INFO:Total runtime is 9.216864903767903e-05 minutes
2024-05-28 15:01:43,306:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:43,306:INFO:Initializing create_model()
2024-05-28 15:01:43,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:43,307:INFO:Checking exceptions
2024-05-28 15:01:43,307:INFO:Importing libraries
2024-05-28 15:01:43,307:INFO:Copying training dataset
2024-05-28 15:01:43,307:INFO:Defining folds
2024-05-28 15:01:43,307:INFO:Declaring metric variables
2024-05-28 15:01:43,307:INFO:Importing untrained model
2024-05-28 15:01:43,307:INFO:Logistic Regression Imported successfully
2024-05-28 15:01:43,307:INFO:Starting cross validation
2024-05-28 15:01:43,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:45,021:INFO:Calculating mean and std
2024-05-28 15:01:45,021:WARNING:Processing:   7%|####4                                                         | 5/69 [00:01<00:22,  2.90it/s]
2024-05-28 15:01:45,021:INFO:Creating metrics dataframe
2024-05-28 15:01:45,023:INFO:Uploading results into container
2024-05-28 15:01:45,024:INFO:Uploading model into container now
2024-05-28 15:01:45,024:INFO:_master_model_container: 1
2024-05-28 15:01:45,024:INFO:_display_container: 2
2024-05-28 15:01:45,025:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8351, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 15:01:45,025:INFO:create_model() successfully completed......................................
2024-05-28 15:01:45,218:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:45,218:INFO:Creating metrics dataframe
2024-05-28 15:01:45,218:INFO:Initializing K Neighbors Classifier
2024-05-28 15:01:45,218:INFO:Total runtime is 0.03197021881739299 minutes
2024-05-28 15:01:45,218:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:45,218:INFO:Initializing create_model()
2024-05-28 15:01:45,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:45,218:INFO:Checking exceptions
2024-05-28 15:01:45,218:INFO:Importing libraries
2024-05-28 15:01:45,218:INFO:Copying training dataset
2024-05-28 15:01:45,218:WARNING:Processing:  10%|######2                                                       | 7/69 [00:01<00:15,  3.92it/s]
2024-05-28 15:01:45,218:INFO:Defining folds
2024-05-28 15:01:45,218:INFO:Declaring metric variables
2024-05-28 15:01:45,218:INFO:Importing untrained model
2024-05-28 15:01:45,218:INFO:K Neighbors Classifier Imported successfully
2024-05-28 15:01:45,218:INFO:Starting cross validation
2024-05-28 15:01:45,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:45,517:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,531:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,569:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,754:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,774:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,785:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,795:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,944:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,959:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:45,979:INFO:Calculating mean and std
2024-05-28 15:01:45,979:WARNING:Processing:  13%|########                                                      | 9/69 [00:02<00:17,  3.36it/s]
2024-05-28 15:01:45,979:INFO:Creating metrics dataframe
2024-05-28 15:01:45,979:INFO:Uploading results into container
2024-05-28 15:01:45,979:INFO:Uploading model into container now
2024-05-28 15:01:45,979:INFO:_master_model_container: 2
2024-05-28 15:01:45,979:INFO:_display_container: 2
2024-05-28 15:01:45,979:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 15:01:45,979:INFO:create_model() successfully completed......................................
2024-05-28 15:01:46,145:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:46,145:INFO:Creating metrics dataframe
2024-05-28 15:01:46,145:INFO:Initializing Naive Bayes
2024-05-28 15:01:46,145:INFO:Total runtime is 0.04743184645970663 minutes
2024-05-28 15:01:46,145:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:46,145:INFO:Initializing create_model()
2024-05-28 15:01:46,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:46,145:INFO:Checking exceptions
2024-05-28 15:01:46,145:INFO:Importing libraries
2024-05-28 15:01:46,145:INFO:Copying training dataset
2024-05-28 15:01:46,161:WARNING:Processing:  16%|#########7                                                   | 11/69 [00:02<00:13,  4.35it/s]
2024-05-28 15:01:46,161:INFO:Defining folds
2024-05-28 15:01:46,161:INFO:Declaring metric variables
2024-05-28 15:01:46,161:INFO:Importing untrained model
2024-05-28 15:01:46,161:INFO:Naive Bayes Imported successfully
2024-05-28 15:01:46,161:INFO:Starting cross validation
2024-05-28 15:01:46,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:46,383:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,383:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,383:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,393:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,593:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,593:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,593:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,616:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,744:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,747:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:46,770:INFO:Calculating mean and std
2024-05-28 15:01:46,770:WARNING:Processing:  19%|###########4                                                 | 13/69 [00:03<00:14,  3.94it/s]
2024-05-28 15:01:46,770:INFO:Creating metrics dataframe
2024-05-28 15:01:46,770:INFO:Uploading results into container
2024-05-28 15:01:46,770:INFO:Uploading model into container now
2024-05-28 15:01:46,770:INFO:_master_model_container: 3
2024-05-28 15:01:46,770:INFO:_display_container: 2
2024-05-28 15:01:46,770:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 15:01:46,770:INFO:create_model() successfully completed......................................
2024-05-28 15:01:46,926:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:46,926:INFO:Creating metrics dataframe
2024-05-28 15:01:46,942:INFO:Initializing Decision Tree Classifier
2024-05-28 15:01:46,942:INFO:Total runtime is 0.060701696077982585 minutes
2024-05-28 15:01:46,942:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:46,942:INFO:Initializing create_model()
2024-05-28 15:01:46,942:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:46,942:INFO:Checking exceptions
2024-05-28 15:01:46,942:INFO:Importing libraries
2024-05-28 15:01:46,942:INFO:Copying training dataset
2024-05-28 15:01:46,942:WARNING:Processing:  22%|#############2                                               | 15/69 [00:03<00:10,  4.97it/s]
2024-05-28 15:01:46,942:INFO:Defining folds
2024-05-28 15:01:46,942:INFO:Declaring metric variables
2024-05-28 15:01:46,942:INFO:Importing untrained model
2024-05-28 15:01:46,942:INFO:Decision Tree Classifier Imported successfully
2024-05-28 15:01:46,942:INFO:Starting cross validation
2024-05-28 15:01:46,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:47,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,262:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,293:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,297:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,572:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,576:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,576:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,606:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,824:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:47,852:INFO:Calculating mean and std
2024-05-28 15:01:47,852:WARNING:Processing:  25%|###############                                              | 17/69 [00:04<00:14,  3.58it/s]
2024-05-28 15:01:47,853:INFO:Creating metrics dataframe
2024-05-28 15:01:47,855:INFO:Uploading results into container
2024-05-28 15:01:47,856:INFO:Uploading model into container now
2024-05-28 15:01:47,857:INFO:_master_model_container: 4
2024-05-28 15:01:47,857:INFO:_display_container: 2
2024-05-28 15:01:47,858:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8351, splitter='best')
2024-05-28 15:01:47,859:INFO:create_model() successfully completed......................................
2024-05-28 15:01:48,044:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:48,044:INFO:Creating metrics dataframe
2024-05-28 15:01:48,048:INFO:Initializing SVM - Linear Kernel
2024-05-28 15:01:48,048:INFO:Total runtime is 0.07914015452067058 minutes
2024-05-28 15:01:48,049:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:48,049:INFO:Initializing create_model()
2024-05-28 15:01:48,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:48,050:INFO:Checking exceptions
2024-05-28 15:01:48,050:INFO:Importing libraries
2024-05-28 15:01:48,050:INFO:Copying training dataset
2024-05-28 15:01:48,057:WARNING:Processing:  28%|################7                                            | 19/69 [00:04<00:11,  4.44it/s]
2024-05-28 15:01:48,057:INFO:Defining folds
2024-05-28 15:01:48,057:INFO:Declaring metric variables
2024-05-28 15:01:48,058:INFO:Importing untrained model
2024-05-28 15:01:48,058:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 15:01:48,058:INFO:Starting cross validation
2024-05-28 15:01:48,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:48,651:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:01:49,023:INFO:Calculating mean and std
2024-05-28 15:01:49,023:WARNING:Processing:  30%|##################5                                          | 21/69 [00:05<00:14,  3.29it/s]
2024-05-28 15:01:49,023:INFO:Creating metrics dataframe
2024-05-28 15:01:49,023:INFO:Uploading results into container
2024-05-28 15:01:49,023:INFO:Uploading model into container now
2024-05-28 15:01:49,023:INFO:_master_model_container: 5
2024-05-28 15:01:49,023:INFO:_display_container: 2
2024-05-28 15:01:49,023:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8351, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 15:01:49,023:INFO:create_model() successfully completed......................................
2024-05-28 15:01:49,219:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:49,220:INFO:Creating metrics dataframe
2024-05-28 15:01:49,221:INFO:Initializing Ridge Classifier
2024-05-28 15:01:49,221:INFO:Total runtime is 0.09868749777475994 minutes
2024-05-28 15:01:49,221:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:49,221:INFO:Initializing create_model()
2024-05-28 15:01:49,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:49,221:INFO:Checking exceptions
2024-05-28 15:01:49,221:INFO:Importing libraries
2024-05-28 15:01:49,221:INFO:Copying training dataset
2024-05-28 15:01:49,221:WARNING:Processing:  33%|####################3                                        | 23/69 [00:05<00:11,  4.14it/s]
2024-05-28 15:01:49,221:INFO:Defining folds
2024-05-28 15:01:49,221:INFO:Declaring metric variables
2024-05-28 15:01:49,221:INFO:Importing untrained model
2024-05-28 15:01:49,221:INFO:Ridge Classifier Imported successfully
2024-05-28 15:01:49,221:INFO:Starting cross validation
2024-05-28 15:01:49,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:50,044:INFO:Calculating mean and std
2024-05-28 15:01:50,045:WARNING:Processing:  36%|######################1                                      | 25/69 [00:06<00:12,  3.41it/s]
2024-05-28 15:01:50,045:INFO:Creating metrics dataframe
2024-05-28 15:01:50,047:INFO:Uploading results into container
2024-05-28 15:01:50,049:INFO:Uploading model into container now
2024-05-28 15:01:50,049:INFO:_master_model_container: 6
2024-05-28 15:01:50,049:INFO:_display_container: 2
2024-05-28 15:01:50,050:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8351, solver='auto',
                tol=0.0001)
2024-05-28 15:01:50,050:INFO:create_model() successfully completed......................................
2024-05-28 15:01:50,299:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:50,300:INFO:Creating metrics dataframe
2024-05-28 15:01:50,306:INFO:Initializing Random Forest Classifier
2024-05-28 15:01:50,306:INFO:Total runtime is 0.11678057909011841 minutes
2024-05-28 15:01:50,306:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:50,317:INFO:Initializing create_model()
2024-05-28 15:01:50,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:50,317:INFO:Checking exceptions
2024-05-28 15:01:50,317:INFO:Importing libraries
2024-05-28 15:01:50,317:INFO:Copying training dataset
2024-05-28 15:01:50,317:WARNING:Processing:  39%|#######################8                                     | 27/69 [00:07<00:10,  4.07it/s]
2024-05-28 15:01:50,317:INFO:Defining folds
2024-05-28 15:01:50,317:INFO:Declaring metric variables
2024-05-28 15:01:50,317:INFO:Importing untrained model
2024-05-28 15:01:50,317:INFO:Random Forest Classifier Imported successfully
2024-05-28 15:01:50,334:INFO:Starting cross validation
2024-05-28 15:01:50,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:51,169:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:51,201:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:51,311:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:51,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,032:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,113:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,132:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,435:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,706:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,757:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:01:52,777:INFO:Calculating mean and std
2024-05-28 15:01:52,777:WARNING:Processing:  42%|#########################6                                   | 29/69 [00:09<00:21,  1.84it/s]
2024-05-28 15:01:52,777:INFO:Creating metrics dataframe
2024-05-28 15:01:52,777:INFO:Uploading results into container
2024-05-28 15:01:52,777:INFO:Uploading model into container now
2024-05-28 15:01:52,777:INFO:_master_model_container: 7
2024-05-28 15:01:52,777:INFO:_display_container: 2
2024-05-28 15:01:52,777:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8351, verbose=0,
                       warm_start=False)
2024-05-28 15:01:52,777:INFO:create_model() successfully completed......................................
2024-05-28 15:01:52,948:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:52,963:INFO:Creating metrics dataframe
2024-05-28 15:01:52,963:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 15:01:52,963:INFO:Total runtime is 0.1610651691754659 minutes
2024-05-28 15:01:52,963:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:52,963:INFO:Initializing create_model()
2024-05-28 15:01:52,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:52,963:INFO:Checking exceptions
2024-05-28 15:01:52,963:INFO:Importing libraries
2024-05-28 15:01:52,963:INFO:Copying training dataset
2024-05-28 15:01:52,963:WARNING:Processing:  45%|###########################4                                 | 31/69 [00:09<00:15,  2.46it/s]
2024-05-28 15:01:52,963:INFO:Defining folds
2024-05-28 15:01:52,963:INFO:Declaring metric variables
2024-05-28 15:01:52,963:INFO:Importing untrained model
2024-05-28 15:01:52,963:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 15:01:52,963:INFO:Starting cross validation
2024-05-28 15:01:52,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:53,115:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,115:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,125:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,155:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,381:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,410:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,434:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,434:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,669:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 15:01:53,864:INFO:Calculating mean and std
2024-05-28 15:01:53,864:WARNING:Processing:  48%|#############################1                               | 33/69 [00:10<00:15,  2.38it/s]
2024-05-28 15:01:53,864:INFO:Creating metrics dataframe
2024-05-28 15:01:53,864:INFO:Uploading results into container
2024-05-28 15:01:53,864:INFO:Uploading model into container now
2024-05-28 15:01:53,864:INFO:_master_model_container: 8
2024-05-28 15:01:53,864:INFO:_display_container: 2
2024-05-28 15:01:53,864:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 15:01:53,864:INFO:create_model() successfully completed......................................
2024-05-28 15:01:54,140:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:54,141:INFO:Creating metrics dataframe
2024-05-28 15:01:54,148:INFO:Initializing Ada Boost Classifier
2024-05-28 15:01:54,148:INFO:Total runtime is 0.1808132489522298 minutes
2024-05-28 15:01:54,148:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:54,148:INFO:Initializing create_model()
2024-05-28 15:01:54,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:54,148:INFO:Checking exceptions
2024-05-28 15:01:54,149:INFO:Importing libraries
2024-05-28 15:01:54,149:INFO:Copying training dataset
2024-05-28 15:01:54,154:WARNING:Processing:  51%|##############################9                              | 35/69 [00:10<00:11,  2.96it/s]
2024-05-28 15:01:54,155:INFO:Defining folds
2024-05-28 15:01:54,155:INFO:Declaring metric variables
2024-05-28 15:01:54,155:INFO:Importing untrained model
2024-05-28 15:01:54,155:INFO:Ada Boost Classifier Imported successfully
2024-05-28 15:01:54,156:INFO:Starting cross validation
2024-05-28 15:01:54,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:54,320:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,320:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,336:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,356:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,815:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,840:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,850:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:54,896:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:55,339:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:55,342:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 15:01:55,592:INFO:Calculating mean and std
2024-05-28 15:01:55,592:WARNING:Processing:  54%|################################7                            | 37/69 [00:12<00:14,  2.21it/s]
2024-05-28 15:01:55,592:INFO:Creating metrics dataframe
2024-05-28 15:01:55,592:INFO:Uploading results into container
2024-05-28 15:01:55,592:INFO:Uploading model into container now
2024-05-28 15:01:55,592:INFO:_master_model_container: 9
2024-05-28 15:01:55,592:INFO:_display_container: 2
2024-05-28 15:01:55,592:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8351)
2024-05-28 15:01:55,592:INFO:create_model() successfully completed......................................
2024-05-28 15:01:55,762:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:55,762:INFO:Creating metrics dataframe
2024-05-28 15:01:55,765:INFO:Initializing Gradient Boosting Classifier
2024-05-28 15:01:55,766:INFO:Total runtime is 0.20777004957199097 minutes
2024-05-28 15:01:55,766:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:55,766:INFO:Initializing create_model()
2024-05-28 15:01:55,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:55,766:INFO:Checking exceptions
2024-05-28 15:01:55,766:INFO:Importing libraries
2024-05-28 15:01:55,766:INFO:Copying training dataset
2024-05-28 15:01:55,771:WARNING:Processing:  57%|##################################4                          | 39/69 [00:12<00:10,  2.91it/s]
2024-05-28 15:01:55,771:INFO:Defining folds
2024-05-28 15:01:55,771:INFO:Declaring metric variables
2024-05-28 15:01:55,771:INFO:Importing untrained model
2024-05-28 15:01:55,772:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 15:01:55,772:INFO:Starting cross validation
2024-05-28 15:01:55,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:57,765:INFO:Calculating mean and std
2024-05-28 15:01:57,766:WARNING:Processing:  59%|####################################2                        | 41/69 [00:14<00:15,  1.85it/s]
2024-05-28 15:01:57,766:INFO:Creating metrics dataframe
2024-05-28 15:01:57,771:INFO:Uploading results into container
2024-05-28 15:01:57,772:INFO:Uploading model into container now
2024-05-28 15:01:57,772:INFO:_master_model_container: 10
2024-05-28 15:01:57,773:INFO:_display_container: 2
2024-05-28 15:01:57,774:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 15:01:57,774:INFO:create_model() successfully completed......................................
2024-05-28 15:01:58,060:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:58,060:INFO:Creating metrics dataframe
2024-05-28 15:01:58,060:INFO:Initializing Linear Discriminant Analysis
2024-05-28 15:01:58,060:INFO:Total runtime is 0.24601558049519856 minutes
2024-05-28 15:01:58,060:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:58,060:INFO:Initializing create_model()
2024-05-28 15:01:58,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:58,060:INFO:Checking exceptions
2024-05-28 15:01:58,060:INFO:Importing libraries
2024-05-28 15:01:58,060:INFO:Copying training dataset
2024-05-28 15:01:58,077:WARNING:Processing:  62%|######################################                       | 43/69 [00:14<00:11,  2.36it/s]
2024-05-28 15:01:58,077:INFO:Defining folds
2024-05-28 15:01:58,077:INFO:Declaring metric variables
2024-05-28 15:01:58,077:INFO:Importing untrained model
2024-05-28 15:01:58,077:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 15:01:58,077:INFO:Starting cross validation
2024-05-28 15:01:58,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:01:59,098:INFO:Calculating mean and std
2024-05-28 15:01:59,098:WARNING:Processing:  65%|#######################################7                     | 45/69 [00:15<00:10,  2.22it/s]
2024-05-28 15:01:59,098:INFO:Creating metrics dataframe
2024-05-28 15:01:59,098:INFO:Uploading results into container
2024-05-28 15:01:59,098:INFO:Uploading model into container now
2024-05-28 15:01:59,098:INFO:_master_model_container: 11
2024-05-28 15:01:59,098:INFO:_display_container: 2
2024-05-28 15:01:59,098:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 15:01:59,098:INFO:create_model() successfully completed......................................
2024-05-28 15:01:59,391:INFO:SubProcess create_model() end ==================================
2024-05-28 15:01:59,392:INFO:Creating metrics dataframe
2024-05-28 15:01:59,398:INFO:Initializing Extra Trees Classifier
2024-05-28 15:01:59,398:INFO:Total runtime is 0.26830800771713254 minutes
2024-05-28 15:01:59,399:INFO:SubProcess create_model() called ==================================
2024-05-28 15:01:59,399:INFO:Initializing create_model()
2024-05-28 15:01:59,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:01:59,400:INFO:Checking exceptions
2024-05-28 15:01:59,400:INFO:Importing libraries
2024-05-28 15:01:59,400:INFO:Copying training dataset
2024-05-28 15:01:59,406:WARNING:Processing:  68%|#########################################5                   | 47/69 [00:16<00:07,  2.77it/s]
2024-05-28 15:01:59,406:INFO:Defining folds
2024-05-28 15:01:59,406:INFO:Declaring metric variables
2024-05-28 15:01:59,407:INFO:Importing untrained model
2024-05-28 15:01:59,407:INFO:Extra Trees Classifier Imported successfully
2024-05-28 15:01:59,409:INFO:Starting cross validation
2024-05-28 15:01:59,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:02:00,166:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:00,166:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:00,314:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:00,362:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:00,759:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,018:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,062:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,087:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,578:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,748:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:01,790:INFO:Calculating mean and std
2024-05-28 15:02:01,792:WARNING:Processing:  71%|###########################################3                 | 49/69 [00:18<00:12,  1.64it/s]
2024-05-28 15:02:01,792:INFO:Creating metrics dataframe
2024-05-28 15:02:01,796:INFO:Uploading results into container
2024-05-28 15:02:01,796:INFO:Uploading model into container now
2024-05-28 15:02:01,796:INFO:_master_model_container: 12
2024-05-28 15:02:01,796:INFO:_display_container: 2
2024-05-28 15:02:01,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8351, verbose=0,
                     warm_start=False)
2024-05-28 15:02:01,796:INFO:create_model() successfully completed......................................
2024-05-28 15:02:02,010:INFO:SubProcess create_model() end ==================================
2024-05-28 15:02:02,010:INFO:Creating metrics dataframe
2024-05-28 15:02:02,015:INFO:Initializing Extreme Gradient Boosting
2024-05-28 15:02:02,016:INFO:Total runtime is 0.3119372884432474 minutes
2024-05-28 15:02:02,016:INFO:SubProcess create_model() called ==================================
2024-05-28 15:02:02,016:INFO:Initializing create_model()
2024-05-28 15:02:02,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:02:02,017:INFO:Checking exceptions
2024-05-28 15:02:02,017:INFO:Importing libraries
2024-05-28 15:02:02,017:INFO:Copying training dataset
2024-05-28 15:02:02,025:WARNING:Processing:  74%|#############################################                | 51/69 [00:18<00:08,  2.16it/s]
2024-05-28 15:02:02,025:INFO:Defining folds
2024-05-28 15:02:02,025:INFO:Declaring metric variables
2024-05-28 15:02:02,025:INFO:Importing untrained model
2024-05-28 15:02:02,027:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 15:02:02,027:INFO:Starting cross validation
2024-05-28 15:02:02,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:02:02,461:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,469:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,471:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,474:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,872:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,882:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,892:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:02,892:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:03,171:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:03,181:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:03,221:INFO:Calculating mean and std
2024-05-28 15:02:03,221:WARNING:Processing:  77%|##############################################8              | 53/69 [00:19<00:08,  1.99it/s]
2024-05-28 15:02:03,221:INFO:Creating metrics dataframe
2024-05-28 15:02:03,221:INFO:Uploading results into container
2024-05-28 15:02:03,221:INFO:Uploading model into container now
2024-05-28 15:02:03,221:INFO:_master_model_container: 13
2024-05-28 15:02:03,221:INFO:_display_container: 2
2024-05-28 15:02:03,221:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 15:02:03,221:INFO:create_model() successfully completed......................................
2024-05-28 15:02:03,386:INFO:SubProcess create_model() end ==================================
2024-05-28 15:02:03,386:INFO:Creating metrics dataframe
2024-05-28 15:02:03,402:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 15:02:03,402:INFO:Total runtime is 0.33503672679265334 minutes
2024-05-28 15:02:03,402:INFO:SubProcess create_model() called ==================================
2024-05-28 15:02:03,402:INFO:Initializing create_model()
2024-05-28 15:02:03,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:02:03,402:INFO:Checking exceptions
2024-05-28 15:02:03,402:INFO:Importing libraries
2024-05-28 15:02:03,402:INFO:Copying training dataset
2024-05-28 15:02:03,402:WARNING:Processing:  80%|################################################6            | 55/69 [00:20<00:05,  2.64it/s]
2024-05-28 15:02:03,402:INFO:Defining folds
2024-05-28 15:02:03,402:INFO:Declaring metric variables
2024-05-28 15:02:03,402:INFO:Importing untrained model
2024-05-28 15:02:03,402:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 15:02:03,402:INFO:Starting cross validation
2024-05-28 15:02:03,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:02:04,771:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:04,797:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:05,329:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:05,400:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:06,489:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:06,558:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:07,222:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:07,536:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:07,553:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:07,581:INFO:Calculating mean and std
2024-05-28 15:02:07,581:WARNING:Processing:  83%|##################################################3          | 57/69 [00:24<00:10,  1.12it/s]
2024-05-28 15:02:07,581:INFO:Creating metrics dataframe
2024-05-28 15:02:07,604:INFO:Uploading results into container
2024-05-28 15:02:07,605:INFO:Uploading model into container now
2024-05-28 15:02:07,608:INFO:_master_model_container: 14
2024-05-28 15:02:07,610:INFO:_display_container: 2
2024-05-28 15:02:07,613:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8351, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 15:02:07,615:INFO:create_model() successfully completed......................................
2024-05-28 15:02:07,843:INFO:SubProcess create_model() end ==================================
2024-05-28 15:02:07,843:INFO:Creating metrics dataframe
2024-05-28 15:02:07,860:INFO:Initializing CatBoost Classifier
2024-05-28 15:02:07,860:INFO:Total runtime is 0.40934401353200267 minutes
2024-05-28 15:02:07,860:INFO:SubProcess create_model() called ==================================
2024-05-28 15:02:07,860:INFO:Initializing create_model()
2024-05-28 15:02:07,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:02:07,860:INFO:Checking exceptions
2024-05-28 15:02:07,860:INFO:Importing libraries
2024-05-28 15:02:07,860:INFO:Copying training dataset
2024-05-28 15:02:07,860:WARNING:Processing:  86%|####################################################1        | 59/69 [00:24<00:06,  1.50it/s]
2024-05-28 15:02:07,860:INFO:Defining folds
2024-05-28 15:02:07,860:INFO:Declaring metric variables
2024-05-28 15:02:07,860:INFO:Importing untrained model
2024-05-28 15:02:07,860:INFO:CatBoost Classifier Imported successfully
2024-05-28 15:02:07,860:INFO:Starting cross validation
2024-05-28 15:02:07,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:02:15,398:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:15,627:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:15,979:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:16,495:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:25,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:25,667:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:25,908:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:26,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:52,896:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:52,971:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:53,029:INFO:Calculating mean and std
2024-05-28 15:02:53,034:WARNING:Processing:  88%|#####################################################9       | 61/69 [01:09<00:57,  7.24s/it]
2024-05-28 15:02:53,034:INFO:Creating metrics dataframe
2024-05-28 15:02:53,040:INFO:Uploading results into container
2024-05-28 15:02:53,041:INFO:Uploading model into container now
2024-05-28 15:02:53,042:INFO:_master_model_container: 15
2024-05-28 15:02:53,043:INFO:_display_container: 2
2024-05-28 15:02:53,043:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCBCEC290>
2024-05-28 15:02:53,043:INFO:create_model() successfully completed......................................
2024-05-28 15:02:53,401:INFO:SubProcess create_model() end ==================================
2024-05-28 15:02:53,402:INFO:Creating metrics dataframe
2024-05-28 15:02:53,413:INFO:Initializing Dummy Classifier
2024-05-28 15:02:53,418:INFO:Total runtime is 1.1686429580052693 minutes
2024-05-28 15:02:53,418:INFO:SubProcess create_model() called ==================================
2024-05-28 15:02:53,419:INFO:Initializing create_model()
2024-05-28 15:02:53,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCAC9F390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:02:53,419:INFO:Checking exceptions
2024-05-28 15:02:53,420:INFO:Importing libraries
2024-05-28 15:02:53,420:INFO:Copying training dataset
2024-05-28 15:02:53,440:WARNING:Processing:  91%|#######################################################6     | 63/69 [01:10<00:30,  5.13s/it]
2024-05-28 15:02:53,440:INFO:Defining folds
2024-05-28 15:02:53,440:INFO:Declaring metric variables
2024-05-28 15:02:53,440:INFO:Importing untrained model
2024-05-28 15:02:53,440:INFO:Dummy Classifier Imported successfully
2024-05-28 15:02:53,440:INFO:Starting cross validation
2024-05-28 15:02:53,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 15:02:53,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:53,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:53,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:53,857:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:53,857:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:53,859:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:53,872:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:53,886:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,358:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,366:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,370:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,388:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,394:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,402:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,420:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,836:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,849:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,866:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 15:02:54,882:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 15:02:54,910:INFO:Calculating mean and std
2024-05-28 15:02:54,915:WARNING:Processing:  94%|#########################################################4   | 65/69 [01:11<00:15,  3.81s/it]
2024-05-28 15:02:54,915:INFO:Creating metrics dataframe
2024-05-28 15:02:54,915:INFO:Uploading results into container
2024-05-28 15:02:54,915:INFO:Uploading model into container now
2024-05-28 15:02:54,915:INFO:_master_model_container: 16
2024-05-28 15:02:54,915:INFO:_display_container: 2
2024-05-28 15:02:54,915:INFO:DummyClassifier(constant=None, random_state=8351, strategy='prior')
2024-05-28 15:02:54,915:INFO:create_model() successfully completed......................................
2024-05-28 15:02:55,215:INFO:SubProcess create_model() end ==================================
2024-05-28 15:02:55,215:INFO:Creating metrics dataframe
2024-05-28 15:02:55,215:WARNING:Processing:  97%|###########################################################2 | 67/69 [01:11<00:05,  2.71s/it]
2024-05-28 15:02:55,215:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 15:02:55,230:INFO:Initializing create_model()
2024-05-28 15:02:55,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 15:02:55,233:INFO:Checking exceptions
2024-05-28 15:02:55,233:INFO:Importing libraries
2024-05-28 15:02:55,233:INFO:Copying training dataset
2024-05-28 15:02:55,247:INFO:Defining folds
2024-05-28 15:02:55,247:INFO:Declaring metric variables
2024-05-28 15:02:55,248:INFO:Importing untrained model
2024-05-28 15:02:55,248:INFO:Declaring custom model
2024-05-28 15:02:55,250:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 15:02:55,254:INFO:Cross validation set to False
2024-05-28 15:02:55,254:INFO:Fitting Model
2024-05-28 15:02:56,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 15:02:56,125:INFO:create_model() successfully completed......................................
2024-05-28 15:02:56,383:WARNING:Processing: 100%|#############################################################| 69/69 [01:13<00:00,  2.08s/it]
2024-05-28 15:02:56,384:WARNING:                                                                                                              
2024-05-28 15:02:56,407:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2024-05-28 15:02:56,408:INFO:gbc          Gradient Boosting Classifier    0.8346  0.8685  0.7569  0.8050   
2024-05-28 15:02:56,408:INFO:catboost              CatBoost Classifier    0.8329  0.0000  0.7277  0.8208   
2024-05-28 15:02:56,408:INFO:xgboost         Extreme Gradient Boosting    0.8313  0.0000  0.7696  0.7867   
2024-05-28 15:02:56,408:INFO:lightgbm  Light Gradient Boosting Machine    0.8250  0.0000  0.7571  0.7867   
2024-05-28 15:02:56,408:INFO:rf               Random Forest Classifier    0.8233  0.0000  0.7275  0.8029   
2024-05-28 15:02:56,408:INFO:et                 Extra Trees Classifier    0.8072  0.0000  0.7279  0.7668   
2024-05-28 15:02:56,408:INFO:ridge                    Ridge Classifier    0.8042  0.8456  0.7659  0.7426   
2024-05-28 15:02:56,409:INFO:lda          Linear Discriminant Analysis    0.7994  0.8437  0.7701  0.7301   
2024-05-28 15:02:56,409:INFO:lr                    Logistic Regression    0.7865  0.8481  0.7618  0.7115   
2024-05-28 15:02:56,409:INFO:ada                  Ada Boost Classifier    0.7832  0.8139  0.7491  0.7101   
2024-05-28 15:02:56,409:INFO:dt               Decision Tree Classifier    0.7736  0.0000  0.7236  0.6970   
2024-05-28 15:02:56,409:INFO:nb                            Naive Bayes    0.7400  0.0000  0.5649  0.7019   
2024-05-28 15:02:56,409:INFO:qda       Quadratic Discriminant Analysis    0.7320  0.7496  0.6389  0.6577   
2024-05-28 15:02:56,409:INFO:knn                K Neighbors Classifier    0.7288  0.0000  0.7112  0.6332   
2024-05-28 15:02:56,409:INFO:svm                   SVM - Linear Kernel    0.6650  0.7894  0.6748  0.5603   
2024-05-28 15:02:56,409:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000   
2024-05-28 15:02:56,409:INFO:
2024-05-28 15:02:56,409:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-05-28 15:02:56,409:INFO:gbc       0.7734  0.6445  0.6511     0.199  
2024-05-28 15:02:56,410:INFO:catboost  0.7630  0.6365  0.6461     4.517  
2024-05-28 15:02:56,410:INFO:xgboost   0.7717  0.6391  0.6453     0.119  
2024-05-28 15:02:56,410:INFO:lightgbm  0.7648  0.6265  0.6333     0.416  
2024-05-28 15:02:56,410:INFO:rf        0.7536  0.6180  0.6287     0.244  
2024-05-28 15:02:56,410:INFO:et        0.7396  0.5878  0.5951     0.238  
2024-05-28 15:02:56,410:INFO:ridge     0.7496  0.5896  0.5944     0.081  
2024-05-28 15:02:56,410:INFO:lda       0.7461  0.5810  0.5852     0.102  
2024-05-28 15:02:56,410:INFO:lr        0.7318  0.5555  0.5607     0.170  
2024-05-28 15:02:56,410:INFO:ada       0.7219  0.5459  0.5532     0.143  
2024-05-28 15:02:56,410:INFO:dt        0.7050  0.5221  0.5274     0.089  
2024-05-28 15:02:56,410:INFO:nb        0.6232  0.4289  0.4367     0.061  
2024-05-28 15:02:56,410:INFO:qda       0.6375  0.4271  0.4364     0.090  
2024-05-28 15:02:56,411:INFO:knn       0.6670  0.4401  0.4453     0.075  
2024-05-28 15:02:56,412:INFO:svm       0.5665  0.3218  0.3511     0.096  
2024-05-28 15:02:56,412:INFO:dummy     0.0000  0.0000  0.0000     0.146  
2024-05-28 15:02:56,412:INFO:_master_model_container: 16
2024-05-28 15:02:56,412:INFO:_display_container: 2
2024-05-28 15:02:56,412:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 15:02:56,412:INFO:compare_models() successfully completed......................................
2024-05-28 15:02:56,485:INFO:Initializing save_model()
2024-05-28 15:02:56,486:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 15:02:56,486:INFO:Adding model into prep_pipe
2024-05-28 15:02:56,531:INFO:Transformation Pipeline and Model Successfully Saved
2024-05-28 15:02:56,531:INFO:best_model.pkl saved in current working directory
2024-05-28 15:02:56,580:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=8351, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-05-28 15:02:56,580:INFO:save_model() successfully completed......................................
2024-05-28 15:02:56,895:INFO:Initializing plot_model()
2024-05-28 15:02:56,895:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 15:02:56,895:INFO:Checking exceptions
2024-05-28 15:02:56,895:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 15:02:56,918:INFO:Preloading libraries
2024-05-28 15:02:56,930:INFO:Copying training dataset
2024-05-28 15:02:56,930:INFO:Plot type: auc
2024-05-28 15:02:57,762:INFO:Fitting Model
2024-05-28 15:02:57,762:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-05-28 15:02:57,763:INFO:Scoring test/hold-out set
2024-05-28 15:02:57,797:INFO:Saving 'AUC.png'
2024-05-28 15:02:58,366:INFO:Visual Rendered Successfully
2024-05-28 15:02:58,605:INFO:plot_model() successfully completed......................................
2024-05-28 15:02:58,606:INFO:Initializing plot_model()
2024-05-28 15:02:58,607:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 15:02:58,607:INFO:Checking exceptions
2024-05-28 15:02:58,607:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 15:02:58,611:INFO:Preloading libraries
2024-05-28 15:02:58,611:INFO:Copying training dataset
2024-05-28 15:02:58,611:INFO:Plot type: confusion_matrix
2024-05-28 15:02:58,758:INFO:Fitting Model
2024-05-28 15:02:58,758:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-05-28 15:02:58,758:INFO:Scoring test/hold-out set
2024-05-28 15:02:58,795:INFO:Saving 'Confusion Matrix.png'
2024-05-28 15:02:59,022:INFO:Visual Rendered Successfully
2024-05-28 15:02:59,243:INFO:plot_model() successfully completed......................................
2024-05-28 15:02:59,243:INFO:Initializing plot_model()
2024-05-28 15:02:59,243:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BCA6B7810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8351, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-05-28 15:02:59,243:INFO:Checking exceptions
2024-05-28 15:02:59,243:INFO:Soft dependency imported: streamlit: 1.35.0
2024-05-28 15:02:59,243:INFO:Preloading libraries
2024-05-28 15:02:59,271:INFO:Copying training dataset
2024-05-28 15:02:59,271:INFO:Plot type: feature
2024-05-28 15:02:59,271:WARNING:No coef_ found. Trying feature_importances_
2024-05-28 15:02:59,328:INFO:Saving 'Feature Importance.png'
2024-05-28 15:02:59,595:INFO:Visual Rendered Successfully
2024-05-28 15:02:59,794:INFO:plot_model() successfully completed......................................
