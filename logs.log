2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:51:47,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:52:40,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:23,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 13:54:55,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:04:48,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:05:13,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:07:11,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:08:30,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:09:57,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:11:32,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:20,320:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'S'')
  warnings.warn(

2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:13:27,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:22,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:15:49,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:08,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:20:18,247:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'S'')
  warnings.warn(

2024-05-28 14:20:53,618:INFO:PyCaret ClassificationExperiment
2024-05-28 14:20:53,618:INFO:Logging name: clf-default-name
2024-05-28 14:20:53,618:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:20:53,618:INFO:version 3.3.1
2024-05-28 14:20:53,618:INFO:Initializing setup()
2024-05-28 14:20:53,619:INFO:self.USI: 12d8
2024-05-28 14:20:53,619:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:20:53,619:INFO:Checking environment
2024-05-28 14:20:53,619:INFO:python_version: 3.11.9
2024-05-28 14:20:53,619:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:20:53,620:INFO:machine: AMD64
2024-05-28 14:20:53,632:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:20:53,651:INFO:Memory: svmem(total=8469606400, available=1824501760, percent=78.5, used=6645104640, free=1824501760)
2024-05-28 14:20:53,651:INFO:Physical Core: 2
2024-05-28 14:20:53,651:INFO:Logical Core: 4
2024-05-28 14:20:53,651:INFO:Checking libraries
2024-05-28 14:20:53,651:INFO:System:
2024-05-28 14:20:53,651:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:20:53,652:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:20:53,652:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:20:53,652:INFO:PyCaret required dependencies:
2024-05-28 14:20:53,881:INFO:                 pip: 24.0
2024-05-28 14:20:53,881:INFO:          setuptools: 70.0.0
2024-05-28 14:20:53,881:INFO:             pycaret: 3.3.1
2024-05-28 14:20:53,881:INFO:             IPython: 8.24.0
2024-05-28 14:20:53,881:INFO:          ipywidgets: 8.1.2
2024-05-28 14:20:53,881:INFO:                tqdm: 4.66.4
2024-05-28 14:20:53,881:INFO:               numpy: 1.26.4
2024-05-28 14:20:53,881:INFO:              pandas: 2.1.4
2024-05-28 14:20:53,881:INFO:              jinja2: 3.1.4
2024-05-28 14:20:53,881:INFO:               scipy: 1.11.4
2024-05-28 14:20:53,881:INFO:              joblib: 1.3.2
2024-05-28 14:20:53,881:INFO:             sklearn: 1.4.2
2024-05-28 14:20:53,881:INFO:                pyod: 1.1.3
2024-05-28 14:20:53,881:INFO:            imblearn: 0.12.2
2024-05-28 14:20:53,881:INFO:   category_encoders: 2.6.3
2024-05-28 14:20:53,881:INFO:            lightgbm: 4.3.0
2024-05-28 14:20:53,881:INFO:               numba: 0.58.1
2024-05-28 14:20:53,881:INFO:            requests: 2.32.2
2024-05-28 14:20:53,881:INFO:          matplotlib: 3.7.5
2024-05-28 14:20:53,881:INFO:          scikitplot: 0.3.7
2024-05-28 14:20:53,881:INFO:         yellowbrick: 1.5
2024-05-28 14:20:53,881:INFO:              plotly: 5.22.0
2024-05-28 14:20:53,881:INFO:    plotly-resampler: Not installed
2024-05-28 14:20:53,881:INFO:             kaleido: 0.2.1
2024-05-28 14:20:53,897:INFO:           schemdraw: 0.15
2024-05-28 14:20:53,897:INFO:         statsmodels: 0.14.2
2024-05-28 14:20:53,897:INFO:              sktime: 0.26.0
2024-05-28 14:20:53,897:INFO:               tbats: 1.1.3
2024-05-28 14:20:53,898:INFO:            pmdarima: 2.0.4
2024-05-28 14:20:53,898:INFO:              psutil: 5.9.8
2024-05-28 14:20:53,898:INFO:          markupsafe: 2.1.5
2024-05-28 14:20:53,898:INFO:             pickle5: Not installed
2024-05-28 14:20:53,898:INFO:         cloudpickle: 3.0.0
2024-05-28 14:20:53,898:INFO:         deprecation: 2.1.0
2024-05-28 14:20:53,898:INFO:              xxhash: 3.4.1
2024-05-28 14:20:53,898:INFO:           wurlitzer: 3.1.0
2024-05-28 14:20:53,898:INFO:PyCaret optional dependencies:
2024-05-28 14:20:53,998:INFO:                shap: Not installed
2024-05-28 14:20:53,998:INFO:           interpret: Not installed
2024-05-28 14:20:53,998:INFO:                umap: 0.5.5
2024-05-28 14:20:53,998:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:20:53,998:INFO:  explainerdashboard: Not installed
2024-05-28 14:20:53,998:INFO:             autoviz: Not installed
2024-05-28 14:20:53,998:INFO:           fairlearn: Not installed
2024-05-28 14:20:53,998:INFO:          deepchecks: Not installed
2024-05-28 14:20:53,998:INFO:             xgboost: 2.0.3
2024-05-28 14:20:53,998:INFO:            catboost: 1.2.5
2024-05-28 14:20:53,998:INFO:              kmodes: 0.12.2
2024-05-28 14:20:53,998:INFO:             mlxtend: 0.23.1
2024-05-28 14:20:53,998:INFO:       statsforecast: Not installed
2024-05-28 14:20:53,998:INFO:        tune_sklearn: Not installed
2024-05-28 14:20:53,998:INFO:                 ray: Not installed
2024-05-28 14:20:53,998:INFO:            hyperopt: Not installed
2024-05-28 14:20:53,998:INFO:              optuna: Not installed
2024-05-28 14:20:53,998:INFO:               skopt: Not installed
2024-05-28 14:20:53,998:INFO:              mlflow: 2.13.0
2024-05-28 14:20:53,998:INFO:              gradio: Not installed
2024-05-28 14:20:53,998:INFO:             fastapi: Not installed
2024-05-28 14:20:53,998:INFO:             uvicorn: Not installed
2024-05-28 14:20:53,998:INFO:              m2cgen: Not installed
2024-05-28 14:20:53,998:INFO:           evidently: Not installed
2024-05-28 14:20:53,998:INFO:               fugue: Not installed
2024-05-28 14:20:53,998:INFO:           streamlit: 1.35.0
2024-05-28 14:20:53,998:INFO:             prophet: Not installed
2024-05-28 14:20:53,998:INFO:None
2024-05-28 14:20:53,998:INFO:Set up data.
2024-05-28 14:20:54,021:INFO:Set up folding strategy.
2024-05-28 14:20:54,021:INFO:Set up train/test split.
2024-05-28 14:20:54,032:INFO:Set up index.
2024-05-28 14:20:54,032:INFO:Assigning column types.
2024-05-28 14:20:54,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:20:54,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,165:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,165:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,431:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,448:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:20:54,498:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,532:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,532:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,581:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:20:54,614:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,631:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,631:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:20:54,714:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,714:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,814:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:54,814:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:54,814:INFO:Preparing preprocessing pipeline...
2024-05-28 14:20:54,830:INFO:Set up simple imputation.
2024-05-28 14:20:54,830:INFO:Set up encoding of ordinal features.
2024-05-28 14:20:54,830:INFO:Set up encoding of categorical features.
2024-05-28 14:20:54,830:INFO:Set up imbalanced handling.
2024-05-28 14:20:55,030:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:20:55,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:20:55,064:INFO:Creating final display dataframe.
2024-05-28 14:20:55,914:INFO:Setup _display_container:                     Description             Value
0                    Session id              7313
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              12d8
2024-05-28 14:20:56,043:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:56,046:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:56,173:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:20:56,176:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:20:56,179:INFO:setup() successfully completed in 2.58s...............
2024-05-28 14:20:56,187:INFO:Initializing compare_models()
2024-05-28 14:20:56,187:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:20:56,187:INFO:Checking exceptions
2024-05-28 14:20:56,197:INFO:Preparing display monitor
2024-05-28 14:20:56,197:INFO:Initializing Logistic Regression
2024-05-28 14:20:56,197:INFO:Total runtime is 0.0 minutes
2024-05-28 14:20:56,197:INFO:SubProcess create_model() called ==================================
2024-05-28 14:20:56,197:INFO:Initializing create_model()
2024-05-28 14:20:56,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:20:56,206:INFO:Checking exceptions
2024-05-28 14:20:56,207:INFO:Importing libraries
2024-05-28 14:20:56,207:INFO:Copying training dataset
2024-05-28 14:20:56,219:INFO:Defining folds
2024-05-28 14:20:56,219:INFO:Declaring metric variables
2024-05-28 14:20:56,220:INFO:Importing untrained model
2024-05-28 14:20:56,221:INFO:Logistic Regression Imported successfully
2024-05-28 14:20:56,222:INFO:Starting cross validation
2024-05-28 14:20:56,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:08,331:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,351:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,536:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:08,903:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,059:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,269:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,588:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,636:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,652:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:21:09,752:INFO:Calculating mean and std
2024-05-28 14:21:09,752:INFO:Creating metrics dataframe
2024-05-28 14:21:09,752:INFO:Uploading results into container
2024-05-28 14:21:09,752:INFO:Uploading model into container now
2024-05-28 14:21:09,752:INFO:_master_model_container: 1
2024-05-28 14:21:09,752:INFO:_display_container: 2
2024-05-28 14:21:09,752:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:21:09,752:INFO:create_model() successfully completed......................................
2024-05-28 14:21:10,008:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:10,008:INFO:Creating metrics dataframe
2024-05-28 14:21:10,013:INFO:Initializing K Neighbors Classifier
2024-05-28 14:21:10,013:INFO:Total runtime is 0.23027323484420775 minutes
2024-05-28 14:21:10,014:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:10,014:INFO:Initializing create_model()
2024-05-28 14:21:10,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:10,015:INFO:Checking exceptions
2024-05-28 14:21:10,015:INFO:Importing libraries
2024-05-28 14:21:10,015:INFO:Copying training dataset
2024-05-28 14:21:10,025:INFO:Defining folds
2024-05-28 14:21:10,025:INFO:Declaring metric variables
2024-05-28 14:21:10,026:INFO:Importing untrained model
2024-05-28 14:21:10,027:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:21:10,027:INFO:Starting cross validation
2024-05-28 14:21:10,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:10,501:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,509:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,586:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,940:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,943:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,946:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:10,954:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,248:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,257:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,288:INFO:Calculating mean and std
2024-05-28 14:21:11,290:INFO:Creating metrics dataframe
2024-05-28 14:21:11,293:INFO:Uploading results into container
2024-05-28 14:21:11,294:INFO:Uploading model into container now
2024-05-28 14:21:11,295:INFO:_master_model_container: 2
2024-05-28 14:21:11,295:INFO:_display_container: 2
2024-05-28 14:21:11,296:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:21:11,296:INFO:create_model() successfully completed......................................
2024-05-28 14:21:11,500:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:11,500:INFO:Creating metrics dataframe
2024-05-28 14:21:11,517:INFO:Initializing Naive Bayes
2024-05-28 14:21:11,517:INFO:Total runtime is 0.2553425033887227 minutes
2024-05-28 14:21:11,517:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:11,517:INFO:Initializing create_model()
2024-05-28 14:21:11,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:11,517:INFO:Checking exceptions
2024-05-28 14:21:11,517:INFO:Importing libraries
2024-05-28 14:21:11,517:INFO:Copying training dataset
2024-05-28 14:21:11,517:INFO:Defining folds
2024-05-28 14:21:11,517:INFO:Declaring metric variables
2024-05-28 14:21:11,517:INFO:Importing untrained model
2024-05-28 14:21:11,517:INFO:Naive Bayes Imported successfully
2024-05-28 14:21:11,517:INFO:Starting cross validation
2024-05-28 14:21:11,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:11,853:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,864:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,899:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:11,943:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,186:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,192:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,227:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,305:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,531:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:12,562:INFO:Calculating mean and std
2024-05-28 14:21:12,562:INFO:Creating metrics dataframe
2024-05-28 14:21:12,567:INFO:Uploading results into container
2024-05-28 14:21:12,567:INFO:Uploading model into container now
2024-05-28 14:21:12,567:INFO:_master_model_container: 3
2024-05-28 14:21:12,567:INFO:_display_container: 2
2024-05-28 14:21:12,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:21:12,567:INFO:create_model() successfully completed......................................
2024-05-28 14:21:12,815:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:12,816:INFO:Creating metrics dataframe
2024-05-28 14:21:12,819:INFO:Initializing Decision Tree Classifier
2024-05-28 14:21:12,819:INFO:Total runtime is 0.2770451704661051 minutes
2024-05-28 14:21:12,819:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:12,820:INFO:Initializing create_model()
2024-05-28 14:21:12,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:12,820:INFO:Checking exceptions
2024-05-28 14:21:12,820:INFO:Importing libraries
2024-05-28 14:21:12,820:INFO:Copying training dataset
2024-05-28 14:21:12,826:INFO:Defining folds
2024-05-28 14:21:12,826:INFO:Declaring metric variables
2024-05-28 14:21:12,827:INFO:Importing untrained model
2024-05-28 14:21:12,827:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:21:12,828:INFO:Starting cross validation
2024-05-28 14:21:12,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:13,155:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,172:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,182:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,193:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,200:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,207:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,207:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,533:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,537:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,537:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:13,798:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:13,819:INFO:Calculating mean and std
2024-05-28 14:21:13,820:INFO:Creating metrics dataframe
2024-05-28 14:21:13,822:INFO:Uploading results into container
2024-05-28 14:21:13,823:INFO:Uploading model into container now
2024-05-28 14:21:13,823:INFO:_master_model_container: 4
2024-05-28 14:21:13,823:INFO:_display_container: 2
2024-05-28 14:21:13,824:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7313, splitter='best')
2024-05-28 14:21:13,824:INFO:create_model() successfully completed......................................
2024-05-28 14:21:13,995:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:13,995:INFO:Creating metrics dataframe
2024-05-28 14:21:14,001:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:21:14,001:INFO:Total runtime is 0.2967338760693868 minutes
2024-05-28 14:21:14,001:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:14,001:INFO:Initializing create_model()
2024-05-28 14:21:14,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:14,002:INFO:Checking exceptions
2024-05-28 14:21:14,002:INFO:Importing libraries
2024-05-28 14:21:14,002:INFO:Copying training dataset
2024-05-28 14:21:14,008:INFO:Defining folds
2024-05-28 14:21:14,008:INFO:Declaring metric variables
2024-05-28 14:21:14,008:INFO:Importing untrained model
2024-05-28 14:21:14,009:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:21:14,009:INFO:Starting cross validation
2024-05-28 14:21:14,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:14,764:INFO:Calculating mean and std
2024-05-28 14:21:14,765:INFO:Creating metrics dataframe
2024-05-28 14:21:14,768:INFO:Uploading results into container
2024-05-28 14:21:14,769:INFO:Uploading model into container now
2024-05-28 14:21:14,769:INFO:_master_model_container: 5
2024-05-28 14:21:14,769:INFO:_display_container: 2
2024-05-28 14:21:14,770:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:21:14,770:INFO:create_model() successfully completed......................................
2024-05-28 14:21:14,954:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:14,955:INFO:Creating metrics dataframe
2024-05-28 14:21:14,960:INFO:Initializing Ridge Classifier
2024-05-28 14:21:14,960:INFO:Total runtime is 0.31272000074386597 minutes
2024-05-28 14:21:14,960:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:14,961:INFO:Initializing create_model()
2024-05-28 14:21:14,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:14,961:INFO:Checking exceptions
2024-05-28 14:21:14,961:INFO:Importing libraries
2024-05-28 14:21:14,961:INFO:Copying training dataset
2024-05-28 14:21:14,971:INFO:Defining folds
2024-05-28 14:21:14,971:INFO:Declaring metric variables
2024-05-28 14:21:14,971:INFO:Importing untrained model
2024-05-28 14:21:14,972:INFO:Ridge Classifier Imported successfully
2024-05-28 14:21:14,972:INFO:Starting cross validation
2024-05-28 14:21:14,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:15,859:INFO:Calculating mean and std
2024-05-28 14:21:15,859:INFO:Creating metrics dataframe
2024-05-28 14:21:15,865:INFO:Uploading results into container
2024-05-28 14:21:15,866:INFO:Uploading model into container now
2024-05-28 14:21:15,867:INFO:_master_model_container: 6
2024-05-28 14:21:15,867:INFO:_display_container: 2
2024-05-28 14:21:15,868:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7313, solver='auto',
                tol=0.0001)
2024-05-28 14:21:15,868:INFO:create_model() successfully completed......................................
2024-05-28 14:21:16,070:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:16,070:INFO:Creating metrics dataframe
2024-05-28 14:21:16,073:INFO:Initializing Random Forest Classifier
2024-05-28 14:21:16,074:INFO:Total runtime is 0.33129642804463705 minutes
2024-05-28 14:21:16,074:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:16,074:INFO:Initializing create_model()
2024-05-28 14:21:16,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:16,075:INFO:Checking exceptions
2024-05-28 14:21:16,075:INFO:Importing libraries
2024-05-28 14:21:16,075:INFO:Copying training dataset
2024-05-28 14:21:16,080:INFO:Defining folds
2024-05-28 14:21:16,080:INFO:Declaring metric variables
2024-05-28 14:21:16,081:INFO:Importing untrained model
2024-05-28 14:21:16,082:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:21:16,082:INFO:Starting cross validation
2024-05-28 14:21:16,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:16,741:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:16,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,767:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:16,769:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,824:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:16,834:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,532:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,545:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,570:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,729:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,733:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:17,752:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:17,763:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,363:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:18,376:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,403:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:18,415:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:18,433:INFO:Calculating mean and std
2024-05-28 14:21:18,435:INFO:Creating metrics dataframe
2024-05-28 14:21:18,437:INFO:Uploading results into container
2024-05-28 14:21:18,438:INFO:Uploading model into container now
2024-05-28 14:21:18,439:INFO:_master_model_container: 7
2024-05-28 14:21:18,439:INFO:_display_container: 2
2024-05-28 14:21:18,439:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7313, verbose=0,
                       warm_start=False)
2024-05-28 14:21:18,440:INFO:create_model() successfully completed......................................
2024-05-28 14:21:18,728:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:18,728:INFO:Creating metrics dataframe
2024-05-28 14:21:18,728:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:21:18,728:INFO:Total runtime is 0.375517737865448 minutes
2024-05-28 14:21:18,728:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:18,743:INFO:Initializing create_model()
2024-05-28 14:21:18,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:18,745:INFO:Checking exceptions
2024-05-28 14:21:18,745:INFO:Importing libraries
2024-05-28 14:21:18,745:INFO:Copying training dataset
2024-05-28 14:21:18,745:INFO:Defining folds
2024-05-28 14:21:18,745:INFO:Declaring metric variables
2024-05-28 14:21:18,761:INFO:Importing untrained model
2024-05-28 14:21:18,762:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:21:18,763:INFO:Starting cross validation
2024-05-28 14:21:18,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:19,028:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,068:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,120:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,134:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,194:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,371:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,411:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,467:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,477:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,486:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,670:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,671:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:21:19,747:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:19,768:INFO:Calculating mean and std
2024-05-28 14:21:19,770:INFO:Creating metrics dataframe
2024-05-28 14:21:19,773:INFO:Uploading results into container
2024-05-28 14:21:19,774:INFO:Uploading model into container now
2024-05-28 14:21:19,774:INFO:_master_model_container: 8
2024-05-28 14:21:19,774:INFO:_display_container: 2
2024-05-28 14:21:19,775:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:21:19,775:INFO:create_model() successfully completed......................................
2024-05-28 14:21:19,971:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:19,972:INFO:Creating metrics dataframe
2024-05-28 14:21:19,975:INFO:Initializing Ada Boost Classifier
2024-05-28 14:21:19,975:INFO:Total runtime is 0.39630001386006675 minutes
2024-05-28 14:21:19,975:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:19,975:INFO:Initializing create_model()
2024-05-28 14:21:19,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:19,976:INFO:Checking exceptions
2024-05-28 14:21:19,976:INFO:Importing libraries
2024-05-28 14:21:19,976:INFO:Copying training dataset
2024-05-28 14:21:19,981:INFO:Defining folds
2024-05-28 14:21:19,982:INFO:Declaring metric variables
2024-05-28 14:21:19,982:INFO:Importing untrained model
2024-05-28 14:21:19,982:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:21:19,982:INFO:Starting cross validation
2024-05-28 14:21:19,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:20,174:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,177:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,196:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,254:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,256:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,259:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,284:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,431:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,431:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,445:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,473:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,526:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,546:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,579:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,711:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:21:20,793:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,797:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:20,818:INFO:Calculating mean and std
2024-05-28 14:21:20,819:INFO:Creating metrics dataframe
2024-05-28 14:21:20,821:INFO:Uploading results into container
2024-05-28 14:21:20,822:INFO:Uploading model into container now
2024-05-28 14:21:20,822:INFO:_master_model_container: 9
2024-05-28 14:21:20,823:INFO:_display_container: 2
2024-05-28 14:21:20,823:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7313)
2024-05-28 14:21:20,823:INFO:create_model() successfully completed......................................
2024-05-28 14:21:20,999:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:20,999:INFO:Creating metrics dataframe
2024-05-28 14:21:21,004:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:21:21,005:INFO:Total runtime is 0.41347586313883467 minutes
2024-05-28 14:21:21,005:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:21,006:INFO:Initializing create_model()
2024-05-28 14:21:21,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:21,006:INFO:Checking exceptions
2024-05-28 14:21:21,006:INFO:Importing libraries
2024-05-28 14:21:21,006:INFO:Copying training dataset
2024-05-28 14:21:21,014:INFO:Defining folds
2024-05-28 14:21:21,014:INFO:Declaring metric variables
2024-05-28 14:21:21,014:INFO:Importing untrained model
2024-05-28 14:21:21,015:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:21:21,016:INFO:Starting cross validation
2024-05-28 14:21:21,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:21,562:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,574:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,577:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:21,597:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,023:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,030:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,038:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,358:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,358:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,367:INFO:Calculating mean and std
2024-05-28 14:21:22,367:INFO:Creating metrics dataframe
2024-05-28 14:21:22,367:INFO:Uploading results into container
2024-05-28 14:21:22,367:INFO:Uploading model into container now
2024-05-28 14:21:22,367:INFO:_master_model_container: 10
2024-05-28 14:21:22,367:INFO:_display_container: 2
2024-05-28 14:21:22,367:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:21:22,367:INFO:create_model() successfully completed......................................
2024-05-28 14:21:22,541:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:22,541:INFO:Creating metrics dataframe
2024-05-28 14:21:22,544:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:21:22,544:INFO:Total runtime is 0.43912605047225955 minutes
2024-05-28 14:21:22,545:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:22,545:INFO:Initializing create_model()
2024-05-28 14:21:22,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:22,545:INFO:Checking exceptions
2024-05-28 14:21:22,545:INFO:Importing libraries
2024-05-28 14:21:22,545:INFO:Copying training dataset
2024-05-28 14:21:22,551:INFO:Defining folds
2024-05-28 14:21:22,551:INFO:Declaring metric variables
2024-05-28 14:21:22,551:INFO:Importing untrained model
2024-05-28 14:21:22,551:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:21:22,552:INFO:Starting cross validation
2024-05-28 14:21:22,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:22,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,818:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,831:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:22,865:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,162:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,174:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,181:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,188:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,541:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,560:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:23,581:INFO:Calculating mean and std
2024-05-28 14:21:23,581:INFO:Creating metrics dataframe
2024-05-28 14:21:23,581:INFO:Uploading results into container
2024-05-28 14:21:23,581:INFO:Uploading model into container now
2024-05-28 14:21:23,581:INFO:_master_model_container: 11
2024-05-28 14:21:23,581:INFO:_display_container: 2
2024-05-28 14:21:23,581:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:21:23,581:INFO:create_model() successfully completed......................................
2024-05-28 14:21:23,771:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:23,771:INFO:Creating metrics dataframe
2024-05-28 14:21:23,775:INFO:Initializing Extra Trees Classifier
2024-05-28 14:21:23,775:INFO:Total runtime is 0.45964737733205163 minutes
2024-05-28 14:21:23,775:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:23,775:INFO:Initializing create_model()
2024-05-28 14:21:23,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:23,775:INFO:Checking exceptions
2024-05-28 14:21:23,775:INFO:Importing libraries
2024-05-28 14:21:23,775:INFO:Copying training dataset
2024-05-28 14:21:23,781:INFO:Defining folds
2024-05-28 14:21:23,781:INFO:Declaring metric variables
2024-05-28 14:21:23,781:INFO:Importing untrained model
2024-05-28 14:21:23,782:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:21:23,782:INFO:Starting cross validation
2024-05-28 14:21:23,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:24,400:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,404:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:24,554:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,197:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,214:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,417:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,442:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,792:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,840:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:25,861:INFO:Calculating mean and std
2024-05-28 14:21:25,862:INFO:Creating metrics dataframe
2024-05-28 14:21:25,864:INFO:Uploading results into container
2024-05-28 14:21:25,865:INFO:Uploading model into container now
2024-05-28 14:21:25,865:INFO:_master_model_container: 12
2024-05-28 14:21:25,865:INFO:_display_container: 2
2024-05-28 14:21:25,866:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7313, verbose=0,
                     warm_start=False)
2024-05-28 14:21:25,866:INFO:create_model() successfully completed......................................
2024-05-28 14:21:26,037:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:26,037:INFO:Creating metrics dataframe
2024-05-28 14:21:26,042:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:21:26,042:INFO:Total runtime is 0.49743057092030846 minutes
2024-05-28 14:21:26,042:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:26,042:INFO:Initializing create_model()
2024-05-28 14:21:26,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:26,042:INFO:Checking exceptions
2024-05-28 14:21:26,042:INFO:Importing libraries
2024-05-28 14:21:26,043:INFO:Copying training dataset
2024-05-28 14:21:26,049:INFO:Defining folds
2024-05-28 14:21:26,049:INFO:Declaring metric variables
2024-05-28 14:21:26,049:INFO:Importing untrained model
2024-05-28 14:21:26,050:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:21:26,051:INFO:Starting cross validation
2024-05-28 14:21:26,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:26,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,522:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,525:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,884:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,905:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,915:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,915:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,925:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:26,948:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:26,957:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,146:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:27,156:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:27,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:27,198:INFO:Calculating mean and std
2024-05-28 14:21:27,198:INFO:Creating metrics dataframe
2024-05-28 14:21:27,198:INFO:Uploading results into container
2024-05-28 14:21:27,198:INFO:Uploading model into container now
2024-05-28 14:21:27,198:INFO:_master_model_container: 13
2024-05-28 14:21:27,198:INFO:_display_container: 2
2024-05-28 14:21:27,205:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:21:27,206:INFO:create_model() successfully completed......................................
2024-05-28 14:21:27,389:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:27,389:INFO:Creating metrics dataframe
2024-05-28 14:21:27,394:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:21:27,394:INFO:Total runtime is 0.5199484070142111 minutes
2024-05-28 14:21:27,395:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:27,395:INFO:Initializing create_model()
2024-05-28 14:21:27,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:27,396:INFO:Checking exceptions
2024-05-28 14:21:27,396:INFO:Importing libraries
2024-05-28 14:21:27,396:INFO:Copying training dataset
2024-05-28 14:21:27,403:INFO:Defining folds
2024-05-28 14:21:27,403:INFO:Declaring metric variables
2024-05-28 14:21:27,403:INFO:Importing untrained model
2024-05-28 14:21:27,404:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:21:27,405:INFO:Starting cross validation
2024-05-28 14:21:27,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:28,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,007:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,017:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,017:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,027:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,312:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,322:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,524:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,534:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,541:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,550:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,563:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:28,829:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:28,847:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,015:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:29,021:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:29,025:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:29,050:INFO:Calculating mean and std
2024-05-28 14:21:29,052:INFO:Creating metrics dataframe
2024-05-28 14:21:29,056:INFO:Uploading results into container
2024-05-28 14:21:29,056:INFO:Uploading model into container now
2024-05-28 14:21:29,057:INFO:_master_model_container: 14
2024-05-28 14:21:29,057:INFO:_display_container: 2
2024-05-28 14:21:29,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:21:29,058:INFO:create_model() successfully completed......................................
2024-05-28 14:21:29,285:INFO:SubProcess create_model() end ==================================
2024-05-28 14:21:29,285:INFO:Creating metrics dataframe
2024-05-28 14:21:29,285:INFO:Initializing CatBoost Classifier
2024-05-28 14:21:29,285:INFO:Total runtime is 0.5514812151590983 minutes
2024-05-28 14:21:29,285:INFO:SubProcess create_model() called ==================================
2024-05-28 14:21:29,285:INFO:Initializing create_model()
2024-05-28 14:21:29,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:21:29,285:INFO:Checking exceptions
2024-05-28 14:21:29,285:INFO:Importing libraries
2024-05-28 14:21:29,285:INFO:Copying training dataset
2024-05-28 14:21:29,302:INFO:Defining folds
2024-05-28 14:21:29,303:INFO:Declaring metric variables
2024-05-28 14:21:29,303:INFO:Importing untrained model
2024-05-28 14:21:29,303:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:21:29,303:INFO:Starting cross validation
2024-05-28 14:21:29,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:21:38,394:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,395:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:38,601:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,612:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:21:38,696:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:21:38,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:04,663:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:04,679:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:04,895:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:04,908:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:05,390:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:05,406:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:05,631:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:05,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:11,435:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:11,442:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:11,464:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 5220, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 2400, in _fit
    self._train(
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\catboost\core.py", line 1780, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4833, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4882, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-28 14:22:11,464:INFO:Calculating mean and std
2024-05-28 14:22:11,468:INFO:Creating metrics dataframe
2024-05-28 14:22:11,468:INFO:Uploading results into container
2024-05-28 14:22:11,468:INFO:Uploading model into container now
2024-05-28 14:22:11,468:INFO:_master_model_container: 15
2024-05-28 14:22:11,468:INFO:_display_container: 2
2024-05-28 14:22:11,468:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BC3ECE550>
2024-05-28 14:22:11,468:INFO:create_model() successfully completed......................................
2024-05-28 14:22:11,718:INFO:SubProcess create_model() end ==================================
2024-05-28 14:22:11,718:INFO:Creating metrics dataframe
2024-05-28 14:22:11,718:INFO:Initializing Dummy Classifier
2024-05-28 14:22:11,718:INFO:Total runtime is 1.2586904684702556 minutes
2024-05-28 14:22:11,718:INFO:SubProcess create_model() called ==================================
2024-05-28 14:22:11,718:INFO:Initializing create_model()
2024-05-28 14:22:11,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCA471350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:22:11,718:INFO:Checking exceptions
2024-05-28 14:22:11,718:INFO:Importing libraries
2024-05-28 14:22:11,718:INFO:Copying training dataset
2024-05-28 14:22:11,748:INFO:Defining folds
2024-05-28 14:22:11,748:INFO:Declaring metric variables
2024-05-28 14:22:11,749:INFO:Importing untrained model
2024-05-28 14:22:11,751:INFO:Dummy Classifier Imported successfully
2024-05-28 14:22:11,752:INFO:Starting cross validation
2024-05-28 14:22:11,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:22:12,112:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,116:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,118:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,127:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,133:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,145:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,161:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,518:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,528:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,551:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,559:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,568:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,573:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,951:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,958:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:22:12,970:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:12,976:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:22:13,000:INFO:Calculating mean and std
2024-05-28 14:22:13,000:INFO:Creating metrics dataframe
2024-05-28 14:22:13,000:INFO:Uploading results into container
2024-05-28 14:22:13,000:INFO:Uploading model into container now
2024-05-28 14:22:13,000:INFO:_master_model_container: 16
2024-05-28 14:22:13,000:INFO:_display_container: 2
2024-05-28 14:22:13,000:INFO:DummyClassifier(constant=None, random_state=7313, strategy='prior')
2024-05-28 14:22:13,000:INFO:create_model() successfully completed......................................
2024-05-28 14:22:13,250:INFO:SubProcess create_model() end ==================================
2024-05-28 14:22:13,250:INFO:Creating metrics dataframe
2024-05-28 14:22:13,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:22:13,267:INFO:Initializing create_model()
2024-05-28 14:22:13,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BB89E8550>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:22:13,267:INFO:Checking exceptions
2024-05-28 14:22:13,267:INFO:Importing libraries
2024-05-28 14:22:13,267:INFO:Copying training dataset
2024-05-28 14:22:13,290:INFO:Defining folds
2024-05-28 14:22:13,290:INFO:Declaring metric variables
2024-05-28 14:22:13,290:INFO:Importing untrained model
2024-05-28 14:22:13,291:INFO:Declaring custom model
2024-05-28 14:22:13,291:INFO:Logistic Regression Imported successfully
2024-05-28 14:22:13,294:INFO:Cross validation set to False
2024-05-28 14:22:13,295:INFO:Fitting Model
2024-05-28 14:22:13,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:22:13,950:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:22:13,950:INFO:create_model() successfully completed......................................
2024-05-28 14:22:14,249:INFO:_master_model_container: 16
2024-05-28 14:22:14,249:INFO:_display_container: 2
2024-05-28 14:22:14,265:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:22:14,266:INFO:compare_models() successfully completed......................................
2024-05-28 14:22:14,349:INFO:Initializing save_model()
2024-05-28 14:22:14,349:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:22:14,349:INFO:Adding model into prep_pipe
2024-05-28 14:22:14,390:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:22:14,457:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7313,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:22:14,458:INFO:save_model() successfully completed......................................
2024-05-28 14:23:56,227:INFO:PyCaret ClassificationExperiment
2024-05-28 14:23:56,228:INFO:Logging name: clf-default-name
2024-05-28 14:23:56,228:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-28 14:23:56,228:INFO:version 3.3.1
2024-05-28 14:23:56,228:INFO:Initializing setup()
2024-05-28 14:23:56,228:INFO:self.USI: 20f8
2024-05-28 14:23:56,230:INFO:self._variable_keys: {'memory', 'html_param', 'data', 'log_plots_param', 'y', 'n_jobs_param', 'fold_generator', 'fold_shuffle_param', 'fix_imbalance', 'exp_id', 'X', 'gpu_param', 'X_test', 'y_train', 'target_param', 'y_test', 'is_multiclass', '_available_plots', 'X_train', 'USI', 'seed', 'gpu_n_jobs_param', 'logging_param', 'idx', 'exp_name_log', 'pipeline', '_ml_usecase', 'fold_groups_param'}
2024-05-28 14:23:56,230:INFO:Checking environment
2024-05-28 14:23:56,231:INFO:python_version: 3.11.9
2024-05-28 14:23:56,232:INFO:python_build: ('main', 'Apr 19 2024 18:27:10')
2024-05-28 14:23:56,232:INFO:machine: AMD64
2024-05-28 14:23:56,232:INFO:platform: Windows-10-10.0.19045-SP0
2024-05-28 14:23:56,232:INFO:Memory: svmem(total=8469606400, available=1309298688, percent=84.5, used=7160307712, free=1309298688)
2024-05-28 14:23:56,232:INFO:Physical Core: 2
2024-05-28 14:23:56,232:INFO:Logical Core: 4
2024-05-28 14:23:56,232:INFO:Checking libraries
2024-05-28 14:23:56,232:INFO:System:
2024-05-28 14:23:56,232:INFO:    python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:27:10) [MSC v.1938 64 bit (AMD64)]
2024-05-28 14:23:56,232:INFO:executable: C:\Users\Conor\anaconda3\envs\datasci-env\python.exe
2024-05-28 14:23:56,232:INFO:   machine: Windows-10-10.0.19045-SP0
2024-05-28 14:23:56,232:INFO:PyCaret required dependencies:
2024-05-28 14:23:56,232:INFO:                 pip: 24.0
2024-05-28 14:23:56,232:INFO:          setuptools: 70.0.0
2024-05-28 14:23:56,232:INFO:             pycaret: 3.3.1
2024-05-28 14:23:56,232:INFO:             IPython: 8.24.0
2024-05-28 14:23:56,232:INFO:          ipywidgets: 8.1.2
2024-05-28 14:23:56,232:INFO:                tqdm: 4.66.4
2024-05-28 14:23:56,232:INFO:               numpy: 1.26.4
2024-05-28 14:23:56,232:INFO:              pandas: 2.1.4
2024-05-28 14:23:56,232:INFO:              jinja2: 3.1.4
2024-05-28 14:23:56,232:INFO:               scipy: 1.11.4
2024-05-28 14:23:56,232:INFO:              joblib: 1.3.2
2024-05-28 14:23:56,232:INFO:             sklearn: 1.4.2
2024-05-28 14:23:56,232:INFO:                pyod: 1.1.3
2024-05-28 14:23:56,232:INFO:            imblearn: 0.12.2
2024-05-28 14:23:56,232:INFO:   category_encoders: 2.6.3
2024-05-28 14:23:56,232:INFO:            lightgbm: 4.3.0
2024-05-28 14:23:56,232:INFO:               numba: 0.58.1
2024-05-28 14:23:56,232:INFO:            requests: 2.32.2
2024-05-28 14:23:56,232:INFO:          matplotlib: 3.7.5
2024-05-28 14:23:56,232:INFO:          scikitplot: 0.3.7
2024-05-28 14:23:56,232:INFO:         yellowbrick: 1.5
2024-05-28 14:23:56,232:INFO:              plotly: 5.22.0
2024-05-28 14:23:56,232:INFO:    plotly-resampler: Not installed
2024-05-28 14:23:56,232:INFO:             kaleido: 0.2.1
2024-05-28 14:23:56,232:INFO:           schemdraw: 0.15
2024-05-28 14:23:56,232:INFO:         statsmodels: 0.14.2
2024-05-28 14:23:56,232:INFO:              sktime: 0.26.0
2024-05-28 14:23:56,232:INFO:               tbats: 1.1.3
2024-05-28 14:23:56,232:INFO:            pmdarima: 2.0.4
2024-05-28 14:23:56,232:INFO:              psutil: 5.9.8
2024-05-28 14:23:56,232:INFO:          markupsafe: 2.1.5
2024-05-28 14:23:56,232:INFO:             pickle5: Not installed
2024-05-28 14:23:56,232:INFO:         cloudpickle: 3.0.0
2024-05-28 14:23:56,232:INFO:         deprecation: 2.1.0
2024-05-28 14:23:56,232:INFO:              xxhash: 3.4.1
2024-05-28 14:23:56,232:INFO:           wurlitzer: 3.1.0
2024-05-28 14:23:56,232:INFO:PyCaret optional dependencies:
2024-05-28 14:23:56,232:INFO:                shap: Not installed
2024-05-28 14:23:56,232:INFO:           interpret: Not installed
2024-05-28 14:23:56,232:INFO:                umap: 0.5.5
2024-05-28 14:23:56,232:INFO:     ydata_profiling: 0.0.dev0
2024-05-28 14:23:56,232:INFO:  explainerdashboard: Not installed
2024-05-28 14:23:56,232:INFO:             autoviz: Not installed
2024-05-28 14:23:56,232:INFO:           fairlearn: Not installed
2024-05-28 14:23:56,232:INFO:          deepchecks: Not installed
2024-05-28 14:23:56,232:INFO:             xgboost: 2.0.3
2024-05-28 14:23:56,232:INFO:            catboost: 1.2.5
2024-05-28 14:23:56,232:INFO:              kmodes: 0.12.2
2024-05-28 14:23:56,232:INFO:             mlxtend: 0.23.1
2024-05-28 14:23:56,232:INFO:       statsforecast: Not installed
2024-05-28 14:23:56,247:INFO:        tune_sklearn: Not installed
2024-05-28 14:23:56,247:INFO:                 ray: Not installed
2024-05-28 14:23:56,247:INFO:            hyperopt: Not installed
2024-05-28 14:23:56,248:INFO:              optuna: Not installed
2024-05-28 14:23:56,249:INFO:               skopt: Not installed
2024-05-28 14:23:56,249:INFO:              mlflow: 2.13.0
2024-05-28 14:23:56,249:INFO:              gradio: Not installed
2024-05-28 14:23:56,249:INFO:             fastapi: Not installed
2024-05-28 14:23:56,249:INFO:             uvicorn: Not installed
2024-05-28 14:23:56,249:INFO:              m2cgen: Not installed
2024-05-28 14:23:56,249:INFO:           evidently: Not installed
2024-05-28 14:23:56,250:INFO:               fugue: Not installed
2024-05-28 14:23:56,250:INFO:           streamlit: 1.35.0
2024-05-28 14:23:56,250:INFO:             prophet: Not installed
2024-05-28 14:23:56,250:INFO:None
2024-05-28 14:23:56,250:INFO:Set up data.
2024-05-28 14:23:56,271:INFO:Set up folding strategy.
2024-05-28 14:23:56,272:INFO:Set up train/test split.
2024-05-28 14:23:56,282:INFO:Set up index.
2024-05-28 14:23:56,282:INFO:Assigning column types.
2024-05-28 14:23:56,301:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-28 14:23:56,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,548:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,565:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,742:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,746:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,748:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-28 14:23:56,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:56,891:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:56,895:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:56,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-28 14:23:57,031:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,031:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-28 14:23:57,182:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,182:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,348:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:57,366:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:57,366:INFO:Preparing preprocessing pipeline...
2024-05-28 14:23:57,366:INFO:Set up simple imputation.
2024-05-28 14:23:57,366:INFO:Set up encoding of ordinal features.
2024-05-28 14:23:57,383:INFO:Set up encoding of categorical features.
2024-05-28 14:23:57,383:INFO:Set up imbalanced handling.
2024-05-28 14:23:57,814:INFO:Finished creating preprocessing pipeline.
2024-05-28 14:23:57,881:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-05-28 14:23:57,881:INFO:Creating final display dataframe.
2024-05-28 14:23:59,374:INFO:Setup _display_container:                     Description             Value
0                    Session id               436
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape        (1036, 14)
5   Transformed train set shape         (768, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              20f8
2024-05-28 14:23:59,530:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:59,530:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:59,679:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-28 14:23:59,679:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-28 14:23:59,696:INFO:setup() successfully completed in 3.47s...............
2024-05-28 14:23:59,702:INFO:Initializing compare_models()
2024-05-28 14:23:59,702:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-05-28 14:23:59,702:INFO:Checking exceptions
2024-05-28 14:23:59,710:INFO:Preparing display monitor
2024-05-28 14:23:59,719:INFO:Initializing Logistic Regression
2024-05-28 14:23:59,720:INFO:Total runtime is 1.6645590464274088e-05 minutes
2024-05-28 14:23:59,721:INFO:SubProcess create_model() called ==================================
2024-05-28 14:23:59,722:INFO:Initializing create_model()
2024-05-28 14:23:59,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:23:59,722:INFO:Checking exceptions
2024-05-28 14:23:59,722:INFO:Importing libraries
2024-05-28 14:23:59,722:INFO:Copying training dataset
2024-05-28 14:23:59,738:INFO:Defining folds
2024-05-28 14:23:59,738:INFO:Declaring metric variables
2024-05-28 14:23:59,739:INFO:Importing untrained model
2024-05-28 14:23:59,739:INFO:Logistic Regression Imported successfully
2024-05-28 14:23:59,740:INFO:Starting cross validation
2024-05-28 14:23:59,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:00,415:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,491:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,512:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:00,551:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,744:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,745:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:24:01,841:INFO:Calculating mean and std
2024-05-28 14:24:01,841:INFO:Creating metrics dataframe
2024-05-28 14:24:01,847:INFO:Uploading results into container
2024-05-28 14:24:01,848:INFO:Uploading model into container now
2024-05-28 14:24:01,849:INFO:_master_model_container: 1
2024-05-28 14:24:01,849:INFO:_display_container: 2
2024-05-28 14:24:01,850:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:24:01,850:INFO:create_model() successfully completed......................................
2024-05-28 14:24:01,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:01,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:24:02,077:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:02,077:INFO:Creating metrics dataframe
2024-05-28 14:24:02,077:INFO:Initializing K Neighbors Classifier
2024-05-28 14:24:02,077:INFO:Total runtime is 0.03929454485575359 minutes
2024-05-28 14:24:02,077:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:02,093:INFO:Initializing create_model()
2024-05-28 14:24:02,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:02,093:INFO:Checking exceptions
2024-05-28 14:24:02,093:INFO:Importing libraries
2024-05-28 14:24:02,093:INFO:Copying training dataset
2024-05-28 14:24:02,100:INFO:Defining folds
2024-05-28 14:24:02,101:INFO:Declaring metric variables
2024-05-28 14:24:02,101:INFO:Importing untrained model
2024-05-28 14:24:02,101:INFO:K Neighbors Classifier Imported successfully
2024-05-28 14:24:02,102:INFO:Starting cross validation
2024-05-28 14:24:02,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:02,505:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,514:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,846:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,935:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:02,969:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,235:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,266:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,284:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,308:INFO:Calculating mean and std
2024-05-28 14:24:03,310:INFO:Creating metrics dataframe
2024-05-28 14:24:03,310:INFO:Uploading results into container
2024-05-28 14:24:03,310:INFO:Uploading model into container now
2024-05-28 14:24:03,310:INFO:_master_model_container: 2
2024-05-28 14:24:03,310:INFO:_display_container: 2
2024-05-28 14:24:03,310:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-28 14:24:03,310:INFO:create_model() successfully completed......................................
2024-05-28 14:24:03,521:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:03,521:INFO:Creating metrics dataframe
2024-05-28 14:24:03,526:INFO:Initializing Naive Bayes
2024-05-28 14:24:03,526:INFO:Total runtime is 0.06344113349914551 minutes
2024-05-28 14:24:03,526:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:03,526:INFO:Initializing create_model()
2024-05-28 14:24:03,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:03,526:INFO:Checking exceptions
2024-05-28 14:24:03,526:INFO:Importing libraries
2024-05-28 14:24:03,526:INFO:Copying training dataset
2024-05-28 14:24:03,526:INFO:Defining folds
2024-05-28 14:24:03,526:INFO:Declaring metric variables
2024-05-28 14:24:03,526:INFO:Importing untrained model
2024-05-28 14:24:03,526:INFO:Naive Bayes Imported successfully
2024-05-28 14:24:03,526:INFO:Starting cross validation
2024-05-28 14:24:03,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:03,845:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,845:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,871:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:03,902:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,176:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,219:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,225:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,242:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,490:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,512:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:04,543:INFO:Calculating mean and std
2024-05-28 14:24:04,544:INFO:Creating metrics dataframe
2024-05-28 14:24:04,548:INFO:Uploading results into container
2024-05-28 14:24:04,549:INFO:Uploading model into container now
2024-05-28 14:24:04,550:INFO:_master_model_container: 3
2024-05-28 14:24:04,550:INFO:_display_container: 2
2024-05-28 14:24:04,550:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-28 14:24:04,551:INFO:create_model() successfully completed......................................
2024-05-28 14:24:04,756:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:04,757:INFO:Creating metrics dataframe
2024-05-28 14:24:04,758:INFO:Initializing Decision Tree Classifier
2024-05-28 14:24:04,758:INFO:Total runtime is 0.0839883844057719 minutes
2024-05-28 14:24:04,758:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:04,758:INFO:Initializing create_model()
2024-05-28 14:24:04,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:04,758:INFO:Checking exceptions
2024-05-28 14:24:04,758:INFO:Importing libraries
2024-05-28 14:24:04,758:INFO:Copying training dataset
2024-05-28 14:24:04,758:INFO:Defining folds
2024-05-28 14:24:04,758:INFO:Declaring metric variables
2024-05-28 14:24:04,758:INFO:Importing untrained model
2024-05-28 14:24:04,758:INFO:Decision Tree Classifier Imported successfully
2024-05-28 14:24:04,758:INFO:Starting cross validation
2024-05-28 14:24:04,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:05,164:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,185:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,185:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,196:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,217:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,598:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,613:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,618:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,626:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,636:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,644:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,662:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,926:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,935:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,940:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:05,951:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:05,967:INFO:Calculating mean and std
2024-05-28 14:24:05,967:INFO:Creating metrics dataframe
2024-05-28 14:24:05,967:INFO:Uploading results into container
2024-05-28 14:24:05,967:INFO:Uploading model into container now
2024-05-28 14:24:05,967:INFO:_master_model_container: 4
2024-05-28 14:24:05,967:INFO:_display_container: 2
2024-05-28 14:24:05,973:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=436, splitter='best')
2024-05-28 14:24:05,973:INFO:create_model() successfully completed......................................
2024-05-28 14:24:06,185:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:06,185:INFO:Creating metrics dataframe
2024-05-28 14:24:06,191:INFO:Initializing SVM - Linear Kernel
2024-05-28 14:24:06,191:INFO:Total runtime is 0.10786227385203045 minutes
2024-05-28 14:24:06,191:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:06,191:INFO:Initializing create_model()
2024-05-28 14:24:06,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:06,191:INFO:Checking exceptions
2024-05-28 14:24:06,191:INFO:Importing libraries
2024-05-28 14:24:06,191:INFO:Copying training dataset
2024-05-28 14:24:06,191:INFO:Defining folds
2024-05-28 14:24:06,191:INFO:Declaring metric variables
2024-05-28 14:24:06,191:INFO:Importing untrained model
2024-05-28 14:24:06,191:INFO:SVM - Linear Kernel Imported successfully
2024-05-28 14:24:06,191:INFO:Starting cross validation
2024-05-28 14:24:06,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:06,984:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:07,020:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:07,297:INFO:Calculating mean and std
2024-05-28 14:24:07,299:INFO:Creating metrics dataframe
2024-05-28 14:24:07,303:INFO:Uploading results into container
2024-05-28 14:24:07,304:INFO:Uploading model into container now
2024-05-28 14:24:07,306:INFO:_master_model_container: 5
2024-05-28 14:24:07,306:INFO:_display_container: 2
2024-05-28 14:24:07,307:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=436, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-28 14:24:07,307:INFO:create_model() successfully completed......................................
2024-05-28 14:24:07,506:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:07,506:INFO:Creating metrics dataframe
2024-05-28 14:24:07,506:INFO:Initializing Ridge Classifier
2024-05-28 14:24:07,506:INFO:Total runtime is 0.1297842303911845 minutes
2024-05-28 14:24:07,506:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:07,506:INFO:Initializing create_model()
2024-05-28 14:24:07,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:07,506:INFO:Checking exceptions
2024-05-28 14:24:07,506:INFO:Importing libraries
2024-05-28 14:24:07,506:INFO:Copying training dataset
2024-05-28 14:24:07,533:INFO:Defining folds
2024-05-28 14:24:07,533:INFO:Declaring metric variables
2024-05-28 14:24:07,534:INFO:Importing untrained model
2024-05-28 14:24:07,534:INFO:Ridge Classifier Imported successfully
2024-05-28 14:24:07,535:INFO:Starting cross validation
2024-05-28 14:24:07,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:08,778:INFO:Calculating mean and std
2024-05-28 14:24:08,780:INFO:Creating metrics dataframe
2024-05-28 14:24:08,784:INFO:Uploading results into container
2024-05-28 14:24:08,785:INFO:Uploading model into container now
2024-05-28 14:24:08,786:INFO:_master_model_container: 6
2024-05-28 14:24:08,786:INFO:_display_container: 2
2024-05-28 14:24:08,786:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=436, solver='auto',
                tol=0.0001)
2024-05-28 14:24:08,787:INFO:create_model() successfully completed......................................
2024-05-28 14:24:09,006:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:09,006:INFO:Creating metrics dataframe
2024-05-28 14:24:09,023:INFO:Initializing Random Forest Classifier
2024-05-28 14:24:09,023:INFO:Total runtime is 0.1550586263338725 minutes
2024-05-28 14:24:09,023:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:09,023:INFO:Initializing create_model()
2024-05-28 14:24:09,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:09,023:INFO:Checking exceptions
2024-05-28 14:24:09,023:INFO:Importing libraries
2024-05-28 14:24:09,023:INFO:Copying training dataset
2024-05-28 14:24:09,023:INFO:Defining folds
2024-05-28 14:24:09,023:INFO:Declaring metric variables
2024-05-28 14:24:09,023:INFO:Importing untrained model
2024-05-28 14:24:09,039:INFO:Random Forest Classifier Imported successfully
2024-05-28 14:24:09,040:INFO:Starting cross validation
2024-05-28 14:24:09,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:10,063:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,152:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,238:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,240:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,249:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:10,813:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:10,823:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:11,497:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:11,516:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:11,539:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:11,883:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,140:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,150:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,665:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,668:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:12,678:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:12,699:INFO:Calculating mean and std
2024-05-28 14:24:12,701:INFO:Creating metrics dataframe
2024-05-28 14:24:12,705:INFO:Uploading results into container
2024-05-28 14:24:12,706:INFO:Uploading model into container now
2024-05-28 14:24:12,707:INFO:_master_model_container: 7
2024-05-28 14:24:12,707:INFO:_display_container: 2
2024-05-28 14:24:12,708:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=436, verbose=0,
                       warm_start=False)
2024-05-28 14:24:12,709:INFO:create_model() successfully completed......................................
2024-05-28 14:24:12,969:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:12,969:INFO:Creating metrics dataframe
2024-05-28 14:24:12,975:INFO:Initializing Quadratic Discriminant Analysis
2024-05-28 14:24:12,975:INFO:Total runtime is 0.22093560695648196 minutes
2024-05-28 14:24:12,976:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:12,976:INFO:Initializing create_model()
2024-05-28 14:24:12,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:12,977:INFO:Checking exceptions
2024-05-28 14:24:12,977:INFO:Importing libraries
2024-05-28 14:24:12,977:INFO:Copying training dataset
2024-05-28 14:24:12,987:INFO:Defining folds
2024-05-28 14:24:12,988:INFO:Declaring metric variables
2024-05-28 14:24:12,988:INFO:Importing untrained model
2024-05-28 14:24:12,989:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-28 14:24:12,989:INFO:Starting cross validation
2024-05-28 14:24:12,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:13,345:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,355:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,355:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,375:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,449:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,478:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:13,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,717:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,737:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:13,746:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,024:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,040:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-28 14:24:14,123:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,166:INFO:Calculating mean and std
2024-05-28 14:24:14,168:INFO:Creating metrics dataframe
2024-05-28 14:24:14,171:INFO:Uploading results into container
2024-05-28 14:24:14,172:INFO:Uploading model into container now
2024-05-28 14:24:14,173:INFO:_master_model_container: 8
2024-05-28 14:24:14,173:INFO:_display_container: 2
2024-05-28 14:24:14,174:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-28 14:24:14,174:INFO:create_model() successfully completed......................................
2024-05-28 14:24:14,398:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:14,398:INFO:Creating metrics dataframe
2024-05-28 14:24:14,414:INFO:Initializing Ada Boost Classifier
2024-05-28 14:24:14,414:INFO:Total runtime is 0.24492205381393434 minutes
2024-05-28 14:24:14,418:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:14,419:INFO:Initializing create_model()
2024-05-28 14:24:14,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:14,419:INFO:Checking exceptions
2024-05-28 14:24:14,419:INFO:Importing libraries
2024-05-28 14:24:14,420:INFO:Copying training dataset
2024-05-28 14:24:14,426:INFO:Defining folds
2024-05-28 14:24:14,426:INFO:Declaring metric variables
2024-05-28 14:24:14,427:INFO:Importing untrained model
2024-05-28 14:24:14,428:INFO:Ada Boost Classifier Imported successfully
2024-05-28 14:24:14,428:INFO:Starting cross validation
2024-05-28 14:24:14,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:14,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,653:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,677:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,704:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,750:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,757:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,767:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,797:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:14,960:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,963:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,982:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:14,989:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,045:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,057:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,073:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,085:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,206:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,206:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-28 14:24:15,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,267:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:15,287:INFO:Calculating mean and std
2024-05-28 14:24:15,287:INFO:Creating metrics dataframe
2024-05-28 14:24:15,287:INFO:Uploading results into container
2024-05-28 14:24:15,287:INFO:Uploading model into container now
2024-05-28 14:24:15,287:INFO:_master_model_container: 9
2024-05-28 14:24:15,287:INFO:_display_container: 2
2024-05-28 14:24:15,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=436)
2024-05-28 14:24:15,287:INFO:create_model() successfully completed......................................
2024-05-28 14:24:15,458:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:15,458:INFO:Creating metrics dataframe
2024-05-28 14:24:15,474:INFO:Initializing Gradient Boosting Classifier
2024-05-28 14:24:15,474:INFO:Total runtime is 0.26258054574330647 minutes
2024-05-28 14:24:15,474:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:15,474:INFO:Initializing create_model()
2024-05-28 14:24:15,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:15,474:INFO:Checking exceptions
2024-05-28 14:24:15,474:INFO:Importing libraries
2024-05-28 14:24:15,474:INFO:Copying training dataset
2024-05-28 14:24:15,474:INFO:Defining folds
2024-05-28 14:24:15,474:INFO:Declaring metric variables
2024-05-28 14:24:15,474:INFO:Importing untrained model
2024-05-28 14:24:15,474:INFO:Gradient Boosting Classifier Imported successfully
2024-05-28 14:24:15,474:INFO:Starting cross validation
2024-05-28 14:24:15,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:16,135:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:16,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,020:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,084:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:17,116:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:23,693:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:23,856:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:25,122:INFO:Calculating mean and std
2024-05-28 14:24:25,162:INFO:Creating metrics dataframe
2024-05-28 14:24:25,465:INFO:Uploading results into container
2024-05-28 14:24:25,471:INFO:Uploading model into container now
2024-05-28 14:24:25,480:INFO:_master_model_container: 10
2024-05-28 14:24:25,481:INFO:_display_container: 2
2024-05-28 14:24:25,487:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=436, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-28 14:24:25,490:INFO:create_model() successfully completed......................................
2024-05-28 14:24:28,479:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:28,482:INFO:Creating metrics dataframe
2024-05-28 14:24:28,668:INFO:Initializing Linear Discriminant Analysis
2024-05-28 14:24:28,671:INFO:Total runtime is 0.482520318031311 minutes
2024-05-28 14:24:28,727:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:28,733:INFO:Initializing create_model()
2024-05-28 14:24:28,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:28,738:INFO:Checking exceptions
2024-05-28 14:24:28,740:INFO:Importing libraries
2024-05-28 14:24:28,742:INFO:Copying training dataset
2024-05-28 14:24:29,076:INFO:Defining folds
2024-05-28 14:24:29,080:INFO:Declaring metric variables
2024-05-28 14:24:29,084:INFO:Importing untrained model
2024-05-28 14:24:29,089:INFO:Linear Discriminant Analysis Imported successfully
2024-05-28 14:24:29,096:INFO:Starting cross validation
2024-05-28 14:24:29,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:35,141:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,164:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,175:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:35,178:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,604:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,642:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,677:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:36,725:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:37,909:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:37,972:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:38,010:INFO:Calculating mean and std
2024-05-28 14:24:38,066:INFO:Creating metrics dataframe
2024-05-28 14:24:38,072:INFO:Uploading results into container
2024-05-28 14:24:38,075:INFO:Uploading model into container now
2024-05-28 14:24:38,076:INFO:_master_model_container: 11
2024-05-28 14:24:38,077:INFO:_display_container: 2
2024-05-28 14:24:38,078:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-28 14:24:38,078:INFO:create_model() successfully completed......................................
2024-05-28 14:24:38,581:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:38,581:INFO:Creating metrics dataframe
2024-05-28 14:24:38,598:INFO:Initializing Extra Trees Classifier
2024-05-28 14:24:38,598:INFO:Total runtime is 0.6479743560155232 minutes
2024-05-28 14:24:38,599:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:38,601:INFO:Initializing create_model()
2024-05-28 14:24:38,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:38,601:INFO:Checking exceptions
2024-05-28 14:24:38,602:INFO:Importing libraries
2024-05-28 14:24:38,602:INFO:Copying training dataset
2024-05-28 14:24:38,642:INFO:Defining folds
2024-05-28 14:24:38,642:INFO:Declaring metric variables
2024-05-28 14:24:38,643:INFO:Importing untrained model
2024-05-28 14:24:38,645:INFO:Extra Trees Classifier Imported successfully
2024-05-28 14:24:38,646:INFO:Starting cross validation
2024-05-28 14:24:38,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:40,990:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:40,995:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:41,010:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:41,249:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,806:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,832:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,860:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:42,867:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:42,871:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:42,891:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:43,434:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,897:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,910:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:43,928:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:43,971:INFO:Calculating mean and std
2024-05-28 14:24:43,974:INFO:Creating metrics dataframe
2024-05-28 14:24:43,979:INFO:Uploading results into container
2024-05-28 14:24:43,981:INFO:Uploading model into container now
2024-05-28 14:24:43,982:INFO:_master_model_container: 12
2024-05-28 14:24:43,982:INFO:_display_container: 2
2024-05-28 14:24:43,984:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=436, verbose=0,
                     warm_start=False)
2024-05-28 14:24:43,984:INFO:create_model() successfully completed......................................
2024-05-28 14:24:44,276:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:44,276:INFO:Creating metrics dataframe
2024-05-28 14:24:44,292:INFO:Initializing Extreme Gradient Boosting
2024-05-28 14:24:44,292:INFO:Total runtime is 0.7428793827692667 minutes
2024-05-28 14:24:44,293:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:44,294:INFO:Initializing create_model()
2024-05-28 14:24:44,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:44,294:INFO:Checking exceptions
2024-05-28 14:24:44,294:INFO:Importing libraries
2024-05-28 14:24:44,295:INFO:Copying training dataset
2024-05-28 14:24:44,313:INFO:Defining folds
2024-05-28 14:24:44,313:INFO:Declaring metric variables
2024-05-28 14:24:44,314:INFO:Importing untrained model
2024-05-28 14:24:44,316:INFO:Extreme Gradient Boosting Imported successfully
2024-05-28 14:24:44,317:INFO:Starting cross validation
2024-05-28 14:24:44,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:44,923:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,926:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,932:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,952:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:44,964:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:44,983:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,583:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,604:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,622:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,645:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,661:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:45,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:45,681:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,151:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:46,169:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,194:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:46,209:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:46,235:INFO:Calculating mean and std
2024-05-28 14:24:46,237:INFO:Creating metrics dataframe
2024-05-28 14:24:46,244:INFO:Uploading results into container
2024-05-28 14:24:46,246:INFO:Uploading model into container now
2024-05-28 14:24:46,247:INFO:_master_model_container: 13
2024-05-28 14:24:46,247:INFO:_display_container: 2
2024-05-28 14:24:46,250:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-05-28 14:24:46,250:INFO:create_model() successfully completed......................................
2024-05-28 14:24:46,559:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:46,560:INFO:Creating metrics dataframe
2024-05-28 14:24:46,569:INFO:Initializing Light Gradient Boosting Machine
2024-05-28 14:24:46,570:INFO:Total runtime is 0.7808470646540323 minutes
2024-05-28 14:24:46,570:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:46,571:INFO:Initializing create_model()
2024-05-28 14:24:46,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:46,572:INFO:Checking exceptions
2024-05-28 14:24:46,572:INFO:Importing libraries
2024-05-28 14:24:46,573:INFO:Copying training dataset
2024-05-28 14:24:46,592:INFO:Defining folds
2024-05-28 14:24:46,592:INFO:Declaring metric variables
2024-05-28 14:24:46,593:INFO:Importing untrained model
2024-05-28 14:24:46,594:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-28 14:24:46,595:INFO:Starting cross validation
2024-05-28 14:24:46,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:47,820:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,827:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,835:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:47,839:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:47,857:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:47,876:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:48,399:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:48,421:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:48,974:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,050:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,052:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,064:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,089:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,112:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,662:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,678:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,950:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,958:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:49,977:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:49,988:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:50,005:INFO:Calculating mean and std
2024-05-28 14:24:50,005:INFO:Creating metrics dataframe
2024-05-28 14:24:50,005:INFO:Uploading results into container
2024-05-28 14:24:50,005:INFO:Uploading model into container now
2024-05-28 14:24:50,005:INFO:_master_model_container: 14
2024-05-28 14:24:50,005:INFO:_display_container: 2
2024-05-28 14:24:50,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=436, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-28 14:24:50,005:INFO:create_model() successfully completed......................................
2024-05-28 14:24:50,287:INFO:SubProcess create_model() end ==================================
2024-05-28 14:24:50,287:INFO:Creating metrics dataframe
2024-05-28 14:24:50,310:INFO:Initializing CatBoost Classifier
2024-05-28 14:24:50,310:INFO:Total runtime is 0.8431777556737263 minutes
2024-05-28 14:24:50,310:INFO:SubProcess create_model() called ==================================
2024-05-28 14:24:50,311:INFO:Initializing create_model()
2024-05-28 14:24:50,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:24:50,311:INFO:Checking exceptions
2024-05-28 14:24:50,311:INFO:Importing libraries
2024-05-28 14:24:50,312:INFO:Copying training dataset
2024-05-28 14:24:50,321:INFO:Defining folds
2024-05-28 14:24:50,321:INFO:Declaring metric variables
2024-05-28 14:24:50,321:INFO:Importing untrained model
2024-05-28 14:24:50,321:INFO:CatBoost Classifier Imported successfully
2024-05-28 14:24:50,321:INFO:Starting cross validation
2024-05-28 14:24:50,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:24:59,467:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,495:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,596:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,620:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,664:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,700:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:24:59,930:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:24:59,930:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,523:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,543:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,640:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,650:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,773:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,792:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:08,949:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:08,957:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,669:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:14,685:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,689:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:14,702:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:14,716:INFO:Calculating mean and std
2024-05-28 14:25:14,719:INFO:Creating metrics dataframe
2024-05-28 14:25:14,724:INFO:Uploading results into container
2024-05-28 14:25:14,726:INFO:Uploading model into container now
2024-05-28 14:25:14,727:INFO:_master_model_container: 15
2024-05-28 14:25:14,727:INFO:_display_container: 2
2024-05-28 14:25:14,728:INFO:<catboost.core.CatBoostClassifier object at 0x0000023BCC201B90>
2024-05-28 14:25:14,728:INFO:create_model() successfully completed......................................
2024-05-28 14:25:14,985:INFO:SubProcess create_model() end ==================================
2024-05-28 14:25:14,985:INFO:Creating metrics dataframe
2024-05-28 14:25:15,003:INFO:Initializing Dummy Classifier
2024-05-28 14:25:15,004:INFO:Total runtime is 1.2547542572021484 minutes
2024-05-28 14:25:15,004:INFO:SubProcess create_model() called ==================================
2024-05-28 14:25:15,005:INFO:Initializing create_model()
2024-05-28 14:25:15,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023BCBD529D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:25:15,005:INFO:Checking exceptions
2024-05-28 14:25:15,005:INFO:Importing libraries
2024-05-28 14:25:15,005:INFO:Copying training dataset
2024-05-28 14:25:15,017:INFO:Defining folds
2024-05-28 14:25:15,017:INFO:Declaring metric variables
2024-05-28 14:25:15,018:INFO:Importing untrained model
2024-05-28 14:25:15,018:INFO:Dummy Classifier Imported successfully
2024-05-28 14:25:15,019:INFO:Starting cross validation
2024-05-28 14:25:15,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-28 14:25:15,384:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,390:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,401:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,430:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,436:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,700:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,705:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,709:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,710:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,714:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,721:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,738:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:15,764:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:15,994:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:16,008:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:16,012:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-05-28 14:25:16,029:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-28 14:25:16,047:INFO:Calculating mean and std
2024-05-28 14:25:16,049:INFO:Creating metrics dataframe
2024-05-28 14:25:16,054:INFO:Uploading results into container
2024-05-28 14:25:16,055:INFO:Uploading model into container now
2024-05-28 14:25:16,056:INFO:_master_model_container: 16
2024-05-28 14:25:16,056:INFO:_display_container: 2
2024-05-28 14:25:16,056:INFO:DummyClassifier(constant=None, random_state=436, strategy='prior')
2024-05-28 14:25:16,056:INFO:create_model() successfully completed......................................
2024-05-28 14:25:16,317:INFO:SubProcess create_model() end ==================================
2024-05-28 14:25:16,317:INFO:Creating metrics dataframe
2024-05-28 14:25:16,317:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-05-28 14:25:16,334:INFO:Initializing create_model()
2024-05-28 14:25:16,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023BC3E73D90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-28 14:25:16,335:INFO:Checking exceptions
2024-05-28 14:25:16,336:INFO:Importing libraries
2024-05-28 14:25:16,337:INFO:Copying training dataset
2024-05-28 14:25:16,349:INFO:Defining folds
2024-05-28 14:25:16,350:INFO:Declaring metric variables
2024-05-28 14:25:16,350:INFO:Importing untrained model
2024-05-28 14:25:16,350:INFO:Declaring custom model
2024-05-28 14:25:16,352:INFO:Logistic Regression Imported successfully
2024-05-28 14:25:16,356:INFO:Cross validation set to False
2024-05-28 14:25:16,356:INFO:Fitting Model
2024-05-28 14:25:17,049:WARNING:C:\Users\Conor\anaconda3\envs\datasci-env\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-05-28 14:25:17,049:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:25:17,049:INFO:create_model() successfully completed......................................
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:17,353:INFO:_master_model_container: 16
2024-05-28 14:25:17,353:INFO:_display_container: 2
2024-05-28 14:25:17,354:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-28 14:25:17,355:INFO:compare_models() successfully completed......................................
2024-05-28 14:25:17,449:INFO:Initializing save_model()
2024-05-28 14:25:17,449:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=436, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=Data pipeline & best_model , prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Conor\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-28 14:25:17,449:INFO:Adding model into prep_pipe
2024-05-28 14:25:17,499:INFO:Data pipeline & best_model .pkl saved in current working directory
2024-05-28 14:25:17,599:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=436,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-28 14:25:17,599:INFO:save_model() successfully completed......................................
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:25:34,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-28 14:26:04,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
